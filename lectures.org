#+TITLE: MATH3405 Differential Geometry - UQ
#+AUTHOR: Paul Bryan
#+EMAIL: pabryan@gmail.com

#+SETUPFILE: ~/.emacs.d/org-templates/bibliography.org

#+LaTeX_HEADER: \input{local_definitions}

# #+OPTIONS: H:2 toc:nil date:nil
# #+LaTeX_CLASS: article

#+OPTIONS: H:2 toc:t
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [presentation]
#+BEAMER_THEME: Boadilla
#+LaTeX_HEADER: \AtBeginSection[]{\begin{frame}\frametitle{Table of Contents}\tableofcontents[currentsection]\end{frame}}

# Hide solution by default
#+LaTeX_HEADER: \RenewEnviron{soln}{}

* Timetable							   :noexport:

| Week     | Mon                                  | Wed                                | Fri                                     |
|----------+--------------------------------------+------------------------------------+-----------------------------------------|
| 7 04/09  | Recap of regular curves and surfaces | Orientation and Gauss Map          | SFF and Shape                           |
| 8 11/09  | SFF and Shape                        | Geodesic and Normal Curvature      | Principal Curvatures, MC and GC         |
| 9 18/09  | Local Taylor Approx                  | Isometries and Instrinsic Geometry | Isometries and Instrinsic Geometry      |
| 25/09    | *Mid-Semester*                       | *Mid-Semester*                     | *Mid-Semester*                          |
| 10 02/10 | *Holiday*                            | *Bonus*: Minimal Surfaces          | *Bonus*: Conformal Geometry and maps    |
| 11 09/10 | Theorema Egregium                    | Theorema Egregium                  | Vector Fields and Covariant Derivatives |
| 12 16/10 | Parallel Transport and Geodesics     | Gauss-Bonnet (local)               | Gauss-Bonnet (local)                    |
| 13 23/10 | Gauss-Bonnet (global)                | Global Geometry                    | *Catch Up*                              |
|          |                                      |                                    |                                         |

* Lectures
** MATH3405 Differential Geometry: Week 7
*** Lecture 7.1: Recap on Regular Curves and Surfaces
    :PROPERTIES:
    :Ref: Chapters 1 and 2
    :END:
**** Regular Curves

#+BEGIN_definition
A /regular, parametrised curve/ is a \(C^1\) function
\[
\gamma : I \to \RR^2 \text{ or } \RR^3
\]
where \(I = (a, b) \subseteq \RR\) is an open interval and such that \(\gamma'(t) \ne 0\) for all \(t \in I\).
#+END_definition

\pause

***** Picture
   :PROPERTIES:
   :BEAMER_col: 1
   :END:

[[file:img/regular_curve.png]]

**** Arc length

#+BEGIN_definition
\[
s(t) = \int_{t_0}^t \abs{\gamma'(u)} du
\]
for any choice of fixed \(t_0 \in I = (a, b)\).
#+END_definition

Satisfies \(\partial_t s(t) = \abs{\gamma'(t)} \ne 0\) and so is invertible: \(t = t(s)\).

\pause

***** Arc Length Parametrisation

\[
\gamma(s) = \gamma(t(s)), s \in \left(-\int_a^{t_0} \abs{\gamma'(u)} du, \int_{t_0}^b \abs{\gamma'(u)} du\right) = (s(a), s(b)).
\]

\pause

Satisfies
\[
\abs{\partial_s \gamma(s)} = \abs{\frac{dt}{ds} (s) \gamma'(t(s))} = \frac{1}{\abs{\gamma'}} \abs{\gamma'} = 1.
\]

**** Geometric Interpretation of Arc length

Partition \(I = (a, b)\) into
\[
t_0 = a < t_1 < \cdots < t_k = b.
\]

\pause

****** Length as Riemann Sum

\[
L[\gamma] = \lim_{k\to\infty} \sum_{i=1}^k \frac{\abs{\gamma(t_i) - \gamma(t_{i-1})}}{t_i - t_{i-1}} (t_i - t_{i-1}) = \int_a^b \abs{\gamma'(t)} dt.
\]

\pause

****** Shortest Path

Straight lines are shortest!
\[
\abs{\gamma(t_2) - \gamma(t_1)} \leq \int_{t_1}^{t_2} \abs{\gamma'(t)} dt = L(\gamma)
\]

\pause

**** Curvature and Torsion

***** Unit Tangent, Normal, Bi-Normal
Let
\[
T = \partial_s \gamma, \quad N = \frac{\partial_s T}{\abs{\partial_s T}}, \quad B = T \times N.
\]

\pause

***** Frenet-Serret Equations
****** Text

:PROPERTIES:
:BEAMER_col: 0.5
:END:


#+BEGIN_latex
\[
\partial_s
\begin{pmatrix}
T \\
N \\
B
\end{pmatrix}
=
\begin{pmatrix}
0 & \kappa & 0 \\
-\kappa & 0 & -\tau \\
0 & \tau & 0
\end{pmatrix}
\begin{pmatrix}
T \\
N \\
B
\end{pmatrix}
\]
#+END_latex

\pause

****** Picture

:PROPERTIES:
:BEAMER_col: 0.5
:END:

[[file:img/frenet_serret.png]]

**** Curvature of Plane Curves
***** Curvature

In the plane: Let \(N = e^{i\pi/2} \cdot T\) (complex multiplication!) and
\[
\kappa = \ip{\partial_s T}{N}.
\]
\(\partial_s T = \kappa N\): \(\kappa > 0\) if \(\partial_s T\) points in the direction \(N\), \(\kappa < 0\) for \(-N\).

\pause

/Note/: Opposite orientation (clockwise) obtained by setting \(N = e^{-i\pi/2} \cdot T\). \(\kappa\) changes sign but \(\kappa N\) is invariant.

\pause

***** Picture
   :PROPERTIES:
   :BEAMER_col: 1
   :END:

[[file:img/plane_curvature.png]]

**** Regular Surfaces

#+BEGIN_definition
A regular surface, \(S \subseteq \RR^3\) is subset of \(\RR^3\) such that there exists smooth /local parametrisations/ \(\varphi_{\alpha} : U_{\alpha} \subseteq \RR^2 \to \RR^3\) satisfying for each \(\alpha\),

1. \(S = \union_{\alpha} V_{\alpha}\) where \(V_{\alpha} = \varphi_{\alpha}(U_{\alpha})\),
2. \(\varphi_{\alpha}\) is a homeomorphism onto it's image \(V_{\alpha} = \varphi_{\alpha} (U_{\alpha})\)
3. \(d\varphi_{\alpha}|_x : \RR^2 \to \RR^3\) is injective for each \(x \in U_{\alpha}\).
#+END_definition

\pause

***** Picture
   :PROPERTIES:
   :BEAMER_col: 1
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .9\textwidth :height .4\textheight
[[file:img/regular_surface.png]]
#+END_center

**** Change of Parameters

The third condition implies that for each $\alpha,\beta$, the /change of parameters/
\[
\tau_{\alpha\beta} = \varphi_{\alpha}^{-1} \circ \varphi_{\beta} : \varphi_{\beta}^{-1} (V_{\alpha}) \subseteq \RR^2 \to \varphi_{\alpha}^{-1} (V_{\beta}) \subseteq \RR^2
\]
is a *diffeomorphism*.

That is, \(\tau_{\alpha\beta}\) is smooth with a smooth inverse. The inverse is in fact \(\tau_{\beta\alpha}\).

\pause

# - We could replace condition three, with the condition that \(\tau_{\alpha\beta}\) is smooth.

\pause

***** Picture
   :PROPERTIES:
   :BEAMER_col: 1
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/change_of_param.png]]
#+END_center

**** Key Property of Change of Parameters

Recall \(\tau_{\alpha\beta}\) is a diffeomorphism.

*Fact*:
  \[
  \Phi_{\alpha\beta} : f \in C^{\infty}(\varphi_{\alpha}^{-1} (V_{\beta}), \RR) \mapsto f \circ \tau_{\alpha\beta} \in C^{\infty}(\varphi_{\beta}^{-1} (V_{\alpha}), \RR)
  \]
  is a bijection.

\pause

***** Calculus is diffeomorphism invariant!

Therefore, $\Phi_{\alpha\beta}$ establishes a one-to-one correspondence of smooth functions in one parametrisation with smooth functions in another parametrisation.
**** Smooth Maps
\[
f : \RR \to S, \quad f : S \to \RR, \quad f : S \to S', \dots
\]

\pause

For example, \(f : S \to S'\) is smooth if 
\[
\psi \circ f \circ \phi^{-1} : \phi[f^{-1}[Z] \cap V] \subseteq U \subseteq \RR^2 \to W \subseteq \RR^2
\]
is smooth for every pair of local parametrisations
\[
\phi : U \to V \subseteq S, \quad \psi : W \to Z \subset S'
\]

**** Tangent Plane

#+BEGIN_definition
Let \(x \in S\). The tangent plane $T_x S$ to $S$ at $x$ consists of all the vectors $X \in \RR^3$, based at $x$ and tangent to $S$.
#+END_definition

\pause

Equivalent Descriptions

- Velocity vectors: \(T_x S = \{\gamma'(0) | \gamma : I \to S, \gamma(0) = x\}\) \pause
- Image of the differential: \(T_x S = \{d\varphi_0 (X) | \varphi : U \to S, \varphi(0) = x\}\)

\pause

***** Picture
   :PROPERTIES:
   :BEAMER_col: 1
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .9\textwidth :height .4\textheight
[[file:img/tangent_plane.png]]
#+END_center

**** The Differential

#+BEGIN_definition
Let \(f : S \to S'\) be a smooth map. The differential, \(df_x\) of \(f\) at \(x \in S\) is the linear map
#+BEGIN_latex
\[
\begin{split}
df_x : T_x S &\to T_{f(x)} S' \\
\gamma'(0) &\mapsto (f \circ \gamma)'(0).
\end{split}
\]
#+END_latex
#+END_definition

\pause

***** Coordinate Description

Let \(F(u, v) = \psi^{-1} \circ f \circ \varphi (u, v) = (F_1(u, v), F_2 (u, v))\) with \(x = f(u_0, v_0)\):
\[
df_x = \begin{pmatrix}
\frac{\partial F_1}{\partial u}(v_0, u_0) & \frac{\partial F_1}{\partial v}(v_0, u_0) \\
\frac{\partial F_2}{\partial u}(v_0, u_0) & \frac{\partial F_2}{\partial v}(v_0, u_0)
\end{pmatrix}
\]
**** Metric (First Fundamental Form)

#+BEGIN_definition
The metric \(g\) on \(S\) is an inner product \(g_x\) at each point \(x \in S\) defined for tangent vectors \(V = \gamma'(0)\), \(W = \sigma'(0)\) \(\in T_x S\) by\pause
\[
g_x(V, W) = \ip{\gamma'(0)}{\sigma'(0)}_{\RR^3}.
\]
#+END_definition

\pause

- First Fundamental Form: \(I(V) = g(V, V) = \abs{\gamma'(0)}^2\).

\pause

Equivalently
#+BEGIN_latex
\[
\begin{split}
g(V, W) &= \ip{c_1 \frac{\partial \varphi}{\partial x_1} + c_2 \frac{\partial \varphi}{\partial x_2}}{d_1 \frac{\partial \varphi}{\partial x_1} + d_2 \frac{\partial \varphi}{\partial x_2}} \\
&= c_1 d_1 \ip{\frac{\partial \varphi}{\partial x_1}}{\frac{\partial \varphi}{\partial x_1}} + c_2 d_2 \ip{\frac{\partial \varphi}{\partial x_2}}{\frac{\partial \varphi}{\partial x_2}} + (c_1d_2 + c_2 d_1) \ip{\frac{\partial \varphi}{\partial x_1}}{\frac{\partial \varphi}{\partial x_2}} \\
&= c_1 d_1 E + c_2 d_2 G + (c_1 d_2 + c_2 d_1) F.
\end{split}
\]
#+END_latex

**** Geometry
***** Length and Angle of Tangent Vectors

- Length: \(\abs{V} = \sqrt{(g(V, V))}\),
- Angle: \(\cos \theta = \frac{g(V, W)}{\abs{V}\abs{W}}\).

\pause

***** Arc Length and Area
- Curve length: \(L(\gamma) = \int_a^b \abs{\gamma'(t)} dt\),
- Area: \(A(R) = \int_R \sqrt{\det g}\).

*** Lecture 7.2: Orientation and Gauss Map
**** Orientation of Euclidean Space

#+BEGIN_definition
An orientation on \(\RR^n\) is an equivalence class of /ordered/ bases \(\mathcal{E} = \{e_1, \cdots, e_n\}\) where \(\mathcal{E} \sim \mathcal{F}\) if the change of basis matrix \(A_{\mathcal{E}\mathcal{F}}\) has positive determinant.
#+END_definition

\pause

Since \(\det \left(A_{\mathcal{E}\mathcal{F}} A_{\mathcal{F}\mathcal{G}}\right) = \det \left(A_{\mathcal{E}\mathcal{F}}\right) \det\left(A_{\mathcal{F}\mathcal{G}}\right)\), we do indeed have an equivalence relation, and there are /precisely two equivalence classes/.

\pause

\begin{example}
Compute the change of basis from \(\mathcal{E} = \{e_1, e_2\}\) to \(\{e_1, e_1 + e_2\}, \quad \{e_1, -e_2\}, \quad \{e_2, e_1\}.\)
\end{example}

\pause

\begin{example}
Right hand orientation: \(\{e_1, e_2, e_3\}, \{e_1, e_3, -e_2\}, \dots\)

Left hand orientation: \(\{e_2, e_1, e_3\}, \{e_1, -e_2, e_3\}, \dots\)
\end{example}

**** Orientation preserving and reversing linear maps

Choose an orientation \(\mathcal{O} = \{e_1, \cdots, e_n\}\) on \(\RR^n\).

#+BEGIN_definition
An /invertible/ linear map \(T : \RR^n \to \RR^n\) is orientation preserving if \(T(\mathcal{O}) = \mathcal{O}\). That is, if
\[
\det \begin{pmatrix}
T(e_1), \cdots, T(e_n)
\end{pmatrix}
= \det \begin{pmatrix}
e_1, \cdots, e_n
\end{pmatrix}
\]
or equivalently if \(\det T > 0\).
#+END_definition

\pause

\begin{example}
\[
\text{Preserving:} \quad
T = \begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}, \quad
T = \begin{pmatrix}
1 & 1 \\
1 & 0
\end{pmatrix}, \quad
T = \begin{pmatrix}
2 & 1 \\
3 & 5
\end{pmatrix}.
\]
\[
\text{Reversing:} \quad
T = \begin{pmatrix}
1 & 0 \\
0 & -1
\end{pmatrix}, \quad
T = \begin{pmatrix}
0 & 1 \\
1 & 0
\end{pmatrix}, \quad
T = \begin{pmatrix}
2 & 1 \\
3 & 1
\end{pmatrix}.
\]
\end{example}

**** Orientation of the tangent plane
***** Tangent Plane Orientations
****** Text
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:

Local parametrisation: \(\varphi : U \to S\).
\[
\left\{\frac{\partial \varphi}{\partial u}, \frac{\partial \varphi}{\partial v}\right\}, \quad \left\{\frac{\partial \varphi}{\partial v}, \frac{\partial \varphi}{\partial u}\right\}
\]
****** Picture
      :PROPERTIES:
      :BEAMER_col: 0.5
      :END:

#+BEGIN_center
#+ATTR_LATEX: :width .9\textwidth :height .4\textheight
[[file:img/oriented_tangent_plane.png]]
#+END_center

\pause
***** Definition
The orientation induced by \(\varphi\) is /compatible/ with the orientation induced by \(\psi\) if \(\det d(\psi \circ \phi^{-1}) > 0\).
\pause
A regular surface, \(S\) is /orientable/ if there is a cover \(\varphi_{\alpha} : U_{\alpha} \to S\) such that \(\det(\tau_{\alpha\beta}) > 0\) for all \(\alpha, \beta\).

**** Examples

- The sphere is orientable
- The \mobius{} strip is /not/ orientable
- Graphs, are orientable
- Inverse images of regular point are orientable
- Surfaces of revolution may or may not be orientable

**** Orientation of surfaces

#+BEGIN_theorem
A surface \(S\) is orientable if and only if there is a differentiable field, \(N\) of unit normal vectors. That is, if and only there exists a differentiable map \(N : S \to \RR^3\) such that \(\abs{N(x)} = 1\) for all \(x \in S\) and such that \(N(x) \perp X\) for all $X \in T_x S$.
#+END_theorem

\pause

*Remember there are precisely two orientations!*

\pause

There are two possible unit normal fields, \(N\) and \(-N\). Choosing an orientation is equivalent to choosing a normal field.

\pause

- The proof of the theorem follows from the following lemma:

#+BEGIN_lemma
Let \(\varphi (u, v) : U \subseteq \RR^2 \to S\) and \(\psi (s, t) : V \subseteq \RR^2 \to S\) be local parametrisations. Then
\[
\partial_u \varphi \times \partial_v \varphi = \left[\det d(\psi^{-1} \circ \varphi)\right] \partial_s \psi \times \partial_t \psi.
\]
#+END_lemma

**** Gauss Map

#+BEGIN_definition
 An orientable surface \(S\) along with a choice of orientation is called an /oriented surface/.
#+END_definition

\pause

#+BEGIN_definition
Let \(S\) be an oriented surface. The /Gauss Map/ is the unit normal map
\[
x \in S \mapsto N(x) \in \sphere^2 = \{X \in \RR^3 : \|X\| = 1\}.
\]
#+END_definition

\pause

With respect to a local parametrisation
\[
N = \frac{\partial_u \varphi \times \partial_v \varphi}{\abs{\partial_u \varphi \times \partial_v \varphi}}.
\]

**** Examples

***** Sphere:

\[
S = \{x^2 + y^2 + z^2 = 1\}, \quad N(p) = p
\]

\pause

***** Graph:
\[
S = \{(x, y, f(x, y))\}, \quad N(x, y, f(x)) = \frac{1}{\sqrt{1 + f_x^2 + f_y^2}} (-f_x, -f_y, 1).
\]

\pause

***** Inverse image of regular point

\[
S = \{F^{-1}(c)\}, \quad N(p) = \frac{\nabla F(p)}{|\nabla F(p)|}.
\]

*** Lecture 7.3: Curvature
**** Weingarten Shape Operator

#+BEGIN_definition
The /Weingarten/ or /Shape/ Operator at \(p \in S\) is the linear map
\[
\mathcal{W} = -dN_p : T_p S \to T_p S.
\]
#+END_definition

\pause

Note that $N : S \to \sphere^2$ so that $dN_p : T_p S \to T_{N(p)} \sphere^2$. But by definition
\[
N(p) \perp T_p S
\]
\pause
On the sphere, \(N_{\sphere^2} (p) = p\) and hence
\[
N(p) \perp T_{N(p)} \sphere^2.
\]
\pause

Therefore, \(T_{N(p)} \sphere^2\) is parallel to \(T_p S\) so we may /identify/ them.

**** Examples
***** Plane

\[
S = \{a x + by + c z = 0\}
\]
\[
N(p) = (a, b, c)
\]
\[
dN_p \equiv 0
\]

\pause
***** Sphere

\[
S = \sphere^2 = \{x^2 + y^2 + z^2 = 1\}
\]
\[
N(p) = p
\]
\[
dN_p = \operatorname{Id}.
\]

**** Examples
***** Cylinder

\[
C = \{x^2 + y^2 = 1, -1 < z < 1\}
\]
\[
N(p) = \pi_{(x,y)} (p): N(x, y, z) = (x, y, 0).
\]
\[
dN_p = \pi_{x,y}
\]

\pause

Tangent vectors at \(p = (\cos \theta, \sin \theta, z_0)\):
\[
X = (-\sin\theta, \cos\theta, 0), \quad Y = (0, 0, 1)
\]

\pause

\begin{align*}
dN_{p} X &= \left.\frac{d}{dt}\right|_{t=0} N(\cos (\theta + t), \sin (\theta + t), z) = X \\
dN_{p} Y &= \left.\frac{d}{dt}\right|_{t=0} N(\cos \theta, \sin \theta , z + t) = 0.
\end{align*}

**** Interpretation of \(\mathcal{W}\)
***** Curvature of a plane curve

\[
\kappa = \ip{\partial_s T}{N} = - \ip{T}{\partial_s N}
\]
Measures the change of \(T\), or equivalently, \(N\) along the curve.

\pause

***** Curvature of a surface

- For surfaces \(T_p S\) is /two-dimensional/.

- \(\mathcal{W}(V) = -dN(V)\) measures change of \(N\) in the direction \(V\):
  \pause

  Let \(\gamma\) be a curve with \(\gamma(0) = p\), and \(V = \gamma'(0)\). Then
  \[
  dN_p (V) = \partial_t|_{t=0} N(\gamma(t)) = \text{ deviation of \(N\) along the curve \(\gamma\)}.
  \]
\pause
- Thus \(dN\) is measures how the surface is curved in two-dimensions.
** MATH3405 Differential Geometry: Week 8
*** Lecture 8.1: Geodesic and Normal Curvature
**** Geodesic and normal Curvature

- Let \(\gamma : I \to S\) be a curve on \(S\), \(p = \gamma(0)\), \(V = \gamma'(0) \in T_p S\). \pause

- *Note*: The normal (in \(\RR^3\)) \(n_{\RR^3}\) to \(\gamma\) may be tangent to \(S\), or may be normal to \(S\), or some linear combination thereof. \pause

- As a curve in \(\RR^3\), \(\gamma\) may have curvature, \(\kappa_{\RR^3} \ne 0\) simply because \(S\) has curvature! \pause

#+BEGIN_definition
The /normal curvature/ of \(\gamma\) is the part of the curvature normal to \(S\):
\[
\kappa_N = \ip{\kappa n_{\RR^3}}{N}.
\] \pause
The geodesic curvature vector, \(\overrightarrow{\kappa}_S\) (along \(S\)) is the projection of the curvature vector \(\kappa_{\RR^3} n_{\RR^3}\) onto the tangent plane:
\[
\overrightarrow{\kappa}_S = \pi_{T_p S} (\kappa_{\RR^3} n_{\RR^3}) = \kappa_{\RR^3} n_{\RR^3} - \ip{\kappa_{\RR^3} n_{\RR^3}}{N} N.
\] \pause
Let \(n_S \in T_p S\) be such that \(n_S \perp \gamma'(0)\) and \(\{\gamma'(0), n_S\}\) has positive orientation. The geodesic curvature is \(\kappa_S = \ip{\overrightarrow{\kappa}_S}{n_S}\).
#+END_definition

**** Example

Cylinder: \(C = \{x^2 + y^2 = 1, -1 < z < 1\}, \quad  N(x, y, z) = (x, y, 0).\)

***** Text
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

\begin{align*}
\gamma(t) &= (\cos t, \sin t, z_0) \\
\gamma'(t) &= (-\sin t, \cos t, 0) \\
\gamma''(t) &= (-\cos t, - \sin, 0).
\end{align*}
\[
N(\gamma(t)) = (\cos t, \sin t, 0), n_S(\gamma(t)) = (0, 0, 1).
\]
\[
\kappa_{\RR^3} =  \kappa_{N} = 1, \kappa_{S} = 0.
\]

\pause

***** Picture
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/cylinderandcircle.png]]
#+END_center

**** Example

Cylinder: \(C = \{x^2 + y^2 = 1, -1 < z < 1\}, \quad  N(x, y, z) = (x, y, 0).\)

***** Text
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

\begin{align*}
\gamma(t) &= (1, 0, t) \\
\gamma'(t) &= (0, 0, 1) \\
\gamma''(t) &= (0, 0, 0).
\end{align*}
\[
N(\gamma(t)) = (1, 0, 0), n_S(\gamma(t)) = (0, 1, 0).
\]
\[
\kappa_{\RR^3} = \kappa_{N} = \kappa_{S} = 0.
\]

\pause

***** Picture
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/cylinderandline.png]]
#+END_center

**** Example

Cylinder: \(C = \{x^2 + y^2 = 1, -1 < z < 1\}, \quad  N(x, y, z) = (x, y, 0).\)

***** Text
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

\begin{align*}
\gamma(t) &= (\cos t, \sin t, t) \\
\gamma'(t) &= (-\sin t, \cos t, 1) \\
\gamma''(t) &= (-\cos t, - \sin, 0).
\end{align*}
\[
N(\gamma(t)) = (\cos t, \sin t, 0), n_S(\gamma(t)) = (0, 0, 1).
\]
\[
\kappa_{\RR^3} =  \kappa_{N} = 1, \kappa_{S} = 0.
\]

\pause

***** Picture
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/cylinderandhelix.png]]
#+END_center

**** Example

Cylinder: \(C = \{x^2 + y^2 = 1, -1 < z < 1\}, \quad  N(x, y, z) = (x, y, 0).\)

***** Text
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

\begin{align*}
\gamma(t) &= (\cos(\cos t), \sin(\cos t), \sin t) \\
\gamma'(t) &= (\sin(\cos t) \sin t, ) \\
\gamma''(t) &= (-\cos t, - \sin, 0).
\end{align*}
\[
N(\gamma(t)) = (\cos t, \sin t, 0), n_S(\gamma(t)) = (0, 0, 1).
\]
\[
\kappa_{\RR^3} =  \kappa_{N} = ?, \kappa_{S} = 1.
\]

\pause

***** Picture
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/cylinderandflatcircle.png]]
#+END_center

**** Example

#+BEGIN_latex
\[
\begin{split}
\kappa_{\RR^3} &= \frac{1}{{\left({\left| \cos\left(\cos\left(t\right)\right) \sin\left(t\right) \right|}^{2} + {\left| \sin\left(t\right) \sin\left(\cos\left(t\right)\right) \right|}^{2} + {\left| \cos\left(t\right) \right|}^{2}\right)}^{\frac{3}{2}}} \times \\
& \quad \sqrt{} \left| -{\left(\cos\left(\cos\left(t\right)\right) \sin\left(t\right)^{2} - \cos\left(t\right) \sin\left(\cos\left(t\right)\right)\right)} \cos\left(\cos\left(t\right)\right) \sin\left(t\right) \right. \\
&\quad {\left. - {\left(\sin\left(t\right)^{2} \sin\left(\cos\left(t\right)\right) + \cos\left(t\right) \cos\left(\cos\left(t\right)\right)\right)} \sin\left(t\right) \sin\left(\cos\left(t\right)\right) \right|}^{2} \\
&\quad + \left| \cos\left(\cos\left(t\right)\right) \sin\left(t\right)^{2}\right. \\
&\quad {\left. + {\left(\sin\left(t\right)^{2} \sin\left(\cos\left(t\right)\right) + \cos\left(t\right) \cos\left(\cos\left(t\right)\right)\right)} \cos\left(t\right) \right|}^{2} \\
&\quad + \left| \sin\left(t\right)^{2} \sin\left(\cos\left(t\right)\right) \right. \\
&\quad {\left.- {\left(\cos\left(\cos\left(t\right)\right) \sin\left(t\right)^{2} - \cos\left(t\right) \sin\left(\cos\left(t\right)\right)\right)} \cos\left(t\right) \right|}^{2}
\end{split}
\]
#+END_latex

*** Lecture 8.2: Curvature and the Second Fundamental Form
**** Dependence of normal curvature on direction

#+BEGIN_theorem
Let \(\gamma, \sigma : I \to S\) with \(\gamma(t_0) = \sigma(t_0)\) and \(\gamma'(t_0) = \sigma'(t_0)\) for some \(t_0 \in I\). Then
\[
\kappa_N(\gamma) (t_0) = \kappa_N(\sigma) (t_0).
\]
That is, the normal curvature \(\kappa_N\) depends only the tangent vector \(V = \gamma'(t_0) = \sigma'(t_0)\) at the point \(p = \gamma(t_0) = \sigma(t_0)\).
#+END_theorem

\pause

/Note/: Both \(\kappa_{\RR^3}\) and \(\kappa_S\) also depend on \(\gamma''(t_0)\) (resp. \(\sigma''(t_0)\)) and so /will in general differ/ for \(\gamma\) and \(\sigma\) if \(\gamma''(t_0) \ne \sigma''(t_0)\).

\pause

Thus \(\kappa_N\) measures the curvature of \(S\) itself in the direction \(V\) independently of the choice of curve \(\gamma, \sigma\).

\pause

Whereas \(\kappa_S\) measures the "left-over" curvature of \(\gamma\) after removing the curvature of \(S\) itself.

**** Proof of Theorem

We will show that
\[
\kappa_N = -\ip{dN(\gamma')}{\gamma'}.
\]

\pause

Let \(\gamma\) be parametrised by arc-length, \(s\). Then
\[
\kappa_{\RR^3} n_{\RR^3} = \gamma''.
\]

\pause

Therefore,
\[
\kappa_N = \ip{\kappa_{\RR^3} n_{\RR^3}}{N} = \ip{\gamma''}{N}.
\]

\pause

On the other hand, since \(\ip{\gamma'}{N} = 0\) we have
\[
0 = \partial_s \ip{\gamma'}{N} = \ip{\gamma''}{N} + \ip{\gamma'}{dN(\gamma')}.
\]

\pause

Hence,
\[
\kappa_N = \ip{\gamma''}{N} = - \ip{\gamma'}{dN(\gamma')}.
\]

**** The Second Fundamental Form

#+BEGIN_definition
The /second fundamental form/, or /extrinsic curvature/ of \(S\) is defined to be
\[
A(X, Y) = g(\mathcal{W}(X), Y) = \ip{\mathcal{W} (X)}{Y} = \ip{-dN(X)}{Y}
\]
for \(X, Y\) tangent vectors to \(S\).
#+END_definition

\pause

Classically, the second fundamental form is the /quadratic form/:
\[
\rm{II} (X) = A(X, X).
\]

\pause

The theorem shows that for any curve \(\gamma\) on \(S\),
\[
\kappa_N = \ip{-dN(\gamma')}{\gamma'} = A(\gamma', \gamma') = \rm{II}(\gamma').
\]

**** Spheres

***** Radius 1: \(\sphere^2 = \{x^2 + y^2 + z^2 = 1\}\)

Choose \(N(p) = - p\) (inward pointing). Then \(dN_p(X) = -X\) and
\[
A(X, Y) = \ip{-dN(X)}{Y} = \ip{X}{Y} = g(X, Y)
\]

\pause

***** Radius \(r\): \(\sphere^2(r) = \{x^2 + y^2 + z^2 = r^2\}\)

Choose \(N(p) = -\frac{1}{r}p\) Then \(dN_p(X) = -\frac{1}{r}X\) and
\[
A(X, Y) = \ip{-dN(X)}{Y} = \frac{1}{r} \ip{X}{Y} = \frac{1}{r} g(X, Y)
\]

\pause

***** Equators (Great Circles)

\(\gamma(\theta) = (r \cos(\theta), r\sin(\theta), 0)\): \(\kappa_{\RR^3} = \kappa_N = \frac{1}{r}\). \pause
\(A(\gamma', \gamma') = \frac{1}{r} g(\gamma', \gamma') =\frac{1}{r} r^2 =  r \ne \kappa_N\) *?????* \pause

\(A(\gamma', \gamma') = |\gamma'|^2 \kappa_N\) - *not arc-length!*
**** Symmetry

\onslide<1->
#+BEGIN_theorem
The second fundamental form is /symmetric/: \(A(X, Y) = A(Y, X)\). Equivalently, the Weingarten shape operator is /self-adjoint/ with respect to \(g\): \(g(\mathcal{W}(X), Y) = g(X, \mathcal{W}(Y))\).
#+END_theorem

\onslide<2->
#+BEGIN_proof
Recall \(A(X, Y) = -\ip{dN(X)}{Y}\).

Let \(\gamma(s) \in S\) be a curve with \(\gamma'(0) = X\).

Then since \(\ip{N(\gamma(s))}{Y(\gamma(s))} = 0\) we have,
#+BEGIN_latex
\[
\begin{split}
\onslide<3->{0 &= \partial_s \ip{N(\gamma(s))}{Y(\gamma(s))} \\}
\onslide<4->{&= \ip{dN(\gamma')}{Y} + \ip{N}{dY(\gamma')} \\}
\onslide<5->{&= \ip{dN(X)}{Y} + \ip{N}{dY(X)}.}
\end{split}
\]
#+END_latex

\onslide<6->Likewise \(0 = \ip{dN(Y)}{X} + \ip{N}{dX(Y)}\).
#+END_proof

**** Symmetry (proof continued)

#+BEGIN_proof
We have \(A(X, Y) =- \ip{N}{dX(Y)}\) and \(A(Y, X) = - \ip{N}{dY(X)}\).

\pause

The required result is equivalent to the statement that \(dX(Y) - dY(X)\) is tangential, since then \pause
\[
A(X, Y) - A(Y, X) = -\ip{N}{dX(Y) - dY(X)} = 0.
\]

\pause

Let's take the case, \(X = \partial_u \varphi\), \(Y = \partial_v \varphi\) in a local parametrisation \(\varphi\):

\pause

In this case,
\[
\ip{N}{dX(Y)} = \ip{N}{\partial_u \partial_v \varphi} = \ip{N}{\partial_v \partial_u \varphi} = \ip{N}{dY(X)}.
\]

\pause

The general result follows by bi-linearity of \(A\) and that \(\{\partial_u \varphi, \partial_v \varphi\}\) is a basis so \(X, Y\) are linear combinations of them. \pause *exercise!*
#+END_proof
*** Lecture 8.3: Self Adjoint Operators and Eigenvalues/vectors
**** Symmetric Bilinear Forms

#+BEGIN_definition
Let \(V\) be a real, finite dimensional vector space.

e.g. \(\RR, \RR^2, \RR^3, \cdots, \RR^n, \dots\)

\pause

A /bilinear form/ \(B\) on \(V\) is a map
\[
B : V \times V \to \RR
\]
\pause
such that for all \(c_1, c_2 \in \RR\) and \(X_1, X_2, Y \in V\):
\[
B(c_1 X_1 + c_2 X_2, Y) = c_1 B(X_1, Y) + c_2 B(X_2, Y)
\]
\pause
and
\[
B(Y, c_1 X_1 + c_2 X_2) = c_1 B(Y, X_1) + c_2 B(Y, X_2) 
\]

\pause

\(B\) is /symmetric/ if for every \(X, Y \in V\):
\[
B(X, Y) = B(Y, X).
\]
#+END_definition

**** Inner Products

#+BEGIN_definition
An /inner-product/ \(g\) is a /positive-definite/ bilinear form. That is, \(g\) is a bilinear form such that for all \(X \in V\),
\[
g(X, X) \geq 0, \quad g(X, X) = 0 \Rightarrow X = 0.
\]
#+END_definition

\pause

\begin{example}
Let \(V = \RR^2\), \(X = (x_1, x_2)\), and \(Y = (y_1, y_2)\). Define the \emph{standard} inner product:
\[
g(X, Y) = \ip{X}{Y} := x_1 y_1 + x_2 y_2.
\]
\end{example}

**** Inner Products

\begin{example}
Let \(A\) be any positive-definite, symmetric matrix. Define
\[
g(X, Y) := X^T A Y = \ip{X}{A Y}. 
\]
For example, let
\[
A = \begin{pmatrix}
2 && 1 \\
1 && 3
\end{pmatrix}.
\]
Then
\[
g(X, Y) = 2 x_1 y_1 + x_1 y_2 + x_2 y_1 + 3 x_2 y_2.
\]
\end{example}

**** Canonical Isomorphism

#+BEGIN_lemma
Let \(g\) be an inner-product on \(V\). Then \(g\) induces a linear isomorphism between the vector space \(\operatorname{Hom}(V)\) of linear transformations \(V \to V\) and the vector space \(B^2(V)\) of bilinear forms on \(V\).
#+END_lemma

\pause

The vector space structure on \(\operatorname{Hom}(V)\) is given by letting for each \(X \in V\),
\[
(c_1 T_1 + c_2 T_2) (X) := c_1 T_1(X) + c_2 T_2(X).
\]

\pause

That is, given real constants \(c_1, c_2 \in \RR\) and linear transformations \(T_1, T_2 : V \to V\), we define the linear transformation \(c_1 T_1 + c_2 T_2\) by specifying it's value for each \(X \in V\).

\pause

On the right hand side, note that \(T_1(X) \in V\) so \(c_1 (T_1(X))\) is scalar multiplication using the vector space structure on \(V\). Likewise for \(c_2 (T_2(X))\). The sum \((c_1 T_1(X)) + (c_2 T_2(X))\) is vector addition in \(V\).

\pause

The vector space structure on linear maps \(V \to V\) is defined /pointwise/.

\pause

*Exercise*: Figure out the vector space structure on bilinear forms. /Hint/: It's also defined pointwise.

**** Canonical Isomorphism

#+BEGIN_proof
Choose any basis \(\{e_1, \dots, e_n\}\) for \(V\), and write for \(X \in V\):
\[
X = X^1 e_1 + \cdots + X^n e_n.
\]

\pause

A basis for \(\operatorname{Hom}(V)\) is given by the linear transformations
\[
T^i_j (X^1e_1 + \cdots X^n e_n) = X^ie_j.
\]

\pause

A basis for \(B^2(V)\) is given by the bilinear forms
\[
B^{ij} (X^1e_1 + \cdots X^n e_n, Y^1e_1 + \cdots + Y^ne_n) = X^iY^j.
\]

\pause

Thus,
\[
\operatorname{dim} \operatorname{Hom}(V) = \operatorname{dim} B^2(V) = n^2.
\]

\pause

Thus they are isomorphic, being vector spaces of the same dimension, but something else is needed to get a /canonical/ isomorphism...
#+END_proof

**** Canonical Isomorphism

\begin{example}
Let \(e_1 = (1, 0, \dots, 0), e_2 = (0, 1, 0, \dots, 0), \dots, e_n = (0, \dots, 0, 1)\) be the standard basis for \(\RR^n\).

The isomorphism induced by the standard inner-product defined on basis elements by \(T^i_j \mapsto B^{ij}\) and then extended by linearity.
\end{example}

\pause

#+BEGIN_proof
In general, given \(T \in \operatorname{Hom}(V)\) define
\[
B_g(T) (X, Y) = g(T(X), Y).
\]

\pause

Then \(B_g(T)\) is a bilinear form.

\pause

The map
\[
B_g : T \mapsto B_g(T)
\]
is our desired isomorphism.

\pause

*exercise*: Verify linearity of the map \(B_g\).
#+END_proof

**** Canonical Isomorphism

#+BEGIN_proof
That \(B_g\) is an isomorphism follows since if \(B_g(T_1) = B_g(T_2)\), then for every \(X, Y \in V\):
\[
0 = (B_g(T_1) - B_g(T_2)) (X, Y) = g(T_1(X) - T_2(X), Y).
\]

\pause

In particular for \(Y = T_1(X) - T_2(X)\) we get that for every \(X\)
\[
0 = g(T_1(X) - T_2(X), T_1(X) - T_2(X)) \Rightarrow T_1(X) - T_2(X) = 0
\]
since \(g\) is positive-definite.

\pause

Therefore, \(B_g(T_1) = B_g(T_2) \Rightarrow T_1 = T_2\) and the map \(B_g\) is /injective/.

\pause

Since \(\operatorname{dim} \operatorname{Hom}(V) = \operatorname{dim} B^2(V) = n^2 < \infty\), the map is also surjective and hence an isomorphism.
#+END_proof

**** Self-adjoint operators

Let \(g\) be an inner-product on a finite-dimensional vector space \(V\).

\begin{definition}
A \emph{self-adjoint operator} (with respect to \(g\)) is an linear map \(T : V \to V\) such that for every \(X, Y \in V\)
\[
g(T(X), Y) = g(X, T(Y))
\]
\end{definition}

\pause

#+BEGIN_lemma
A linear map \(T : V \to V\) is self-adjoint if and only if \(B_g (T)\) is a symmetric bilinear form.
#+END_lemma

\pause

#+BEGIN_proof
*exercise*: Back of the envelope calculation directly using the definitions.
#+END_proof

**** Eigenvalues and Eigenvectors

#+BEGIN_theorem
A self adjoint operator \(T\) is /diagonalisable/. That is, there is a basis \(\{e_i\}_{i=1}^n\) of eigenvalues.
#+END_theorem

#+BEGIN_proof
Consider the case \(\operatorname{dim} V = 2\).

\pause

Let us write
\[
\abs{X}_g = \sqrt{g(X, X)}.
\]

\pause

From a basis \(\{X_1, X_2\}\) Gram-Schmidt gives an orthonormal basis:
\[
\tilde{e}_1 = \frac{X_1}{\abs{X_1}_g}, \tilde{e}_2 = \frac{X_2 - g(X_2, \tilde{e}_1)\tilde{e}_1}{\abs{X_2 - g(X_2, \tilde{e}_1)\tilde{e}_1}_g}.
\]

\pause
\[
g(\tilde{e_i}, \tilde{e_j}) = \delta_{ij} := \begin{cases}
1,& i = j \\
0,& i \ne j.
\end{cases}
\]
#+END_proof

**** Eigenvalues and Eigenvectors

#+BEGIN_proof
We may thus write
\[
\sphere^1 = \{X : g(X, X) = 1\} = \{\cos\theta \tilde{e}_1 + \sin\theta \tilde{e}_2 : \theta \in [0, 2\pi]\}.
\]

\pause

Let \(\lambda_1 = \min \{g(T(X), X) : X \in \sphere^1\}\).

\pause

The map
\[
\theta \in [0, 2\pi] \mapsto g(T(\cos\theta \tilde{e}_1 + \sin\theta \tilde{e}_2), \cos\theta \tilde{e}_1 + \sin\theta \tilde{e}_2)
\]
is continuous hence there exists a \(\theta_0 \in [0, 2\pi]\) such that
\[
\lambda_1 = g(T(\cos\theta_0 \tilde{e}_1 + \sin\theta_0 \tilde{e}_2), \cos\theta_0 \tilde{e}_1 + \sin\theta_0 \tilde{e}_2).
\]

\pause

Our desired basis is the orthonormal (why?) pair:
#+BEGIN_latex
\[
\begin{split}
e_1 &= \cos\theta_0 \tilde{e}_1 + \sin\theta_0 \tilde{e}_2 \\
e_2 &= -\sin\theta_0 \tilde{e}_1 + \cos\theta_0 \tilde{e}_2
\end{split}
\]
#+END_latex
#+END_proof

**** Eigenvalues and Eigenvectors

#+BEGIN_proof
Let us write
\[
E_1(\theta) = \cos\theta \tilde{e}_1 + \sin\theta \tilde{e}_2, \quad E_2(\theta) = -\sin\theta \tilde{e}_1 + \cos\theta \tilde{e}_2
\]
\pause
so that
\[
E_1(\theta_0) = e_1, \quad E_2(\theta_0) = e_2
\]
\pause
and
\[
E_1'(\theta) = E_2(\theta), \quad E_2'(\theta) = -E_1(\theta)
\]

#+END_proof

**** Eigenvalues and Eigenvectors

#+BEGIN_proof
By definition, \(\theta_0\) is a critical point of
\[
g(T(E_1(\theta)), E_1(\theta))
\]
\pause
hence
#+BEGIN_latex
\[
\begin{split}
0 &= \partial_{\theta}|_{\theta=\theta_0} g(T(E_1(\theta)), E_2(\theta)) \\
&= g(dT(e_2), e_1) + g(T(e_1), e_2) \\
&= g(T(e_2), e_1) + g(T(e_1), e_2).
\end{split}
\]
#+END_latex
#+END_proof

**** Eigenvalues and Eigenvectors

#+BEGIN_proof
We just obtained that
\[
g(T(e_1), e_2) = - g(e_1, T(e_2)).
\]
\pause
But \(T\) is self-adjoint and hence
\[
g(T(e_1), e_2) = g(e_1, T(e_2))
\]
\pause
Thus
\[
g(T(e_1), e_2) = - g(T(e_1), e_2) \Rightarrow g(T(e_1), e_2) = 0.
\]
\pause

Therefore \(T(e_1) \perp e_2\) and hence
\[
T(e_1) = c e_1
\]
for some \(c\) (possibly \(c = 0\) but that's okay).
#+END_proof

**** Eigenvalues and Eigenvectors

#+BEGIN_proof
Finally,
\[
c = c g(e_1, e_1) = g(c e_1, e_1) = g(T(e_1), e_1) = \lambda_1.
\]
so that
\[
T(e_1) = \lambda_1 e_1
\]
as claimed.
\pause
A similar argument gives \(T(e_2) = \lambda_2 e_2\) for some \(\lambda_2\).
\pause
In fact \(\lambda_2 = \max \{g(T(X), X) : X \in \sphere^1\}\) because: \pause
#+BEGIN_latex
\[
\begin{split}
g(T(X), X) &= g(T(X^1 e_1 + X^2 e_2), X^1e_1 + X^2 e_2) \\
&= g(X^1 \lambda_1 e_1 + X^2 \lambda_2 e_2, X^1e_1 + X^2 e_2) \\
&\underset{e_1, e_2 \text{ o/n}}{=} \lambda_1 X_1^2 + \lambda_2 X^2 \\
&\underset{\lambda_1 = \min}{\leq} \lambda_2 (X_1^2 + X_2^2) \underset{g(X, X) = 1}{=} \lambda_2.
\end{split}
\]
#+END_latex
#+END_proof

**** Remarks on Eigenvalues and Eigenvectors

- By an induction argument, and using the same ideas, one can prove the general case of \(n\) dimensions. \pause
- With respect to the basis of eigenvectors \(e_1, e_2\), \(T\) is diagonal:
  \[
  T(X^1 e_1 + X^2 e_2) = X^1T(e_1) + X^2T(e_2) = X^1 \lambda_1 e_1 + X^2 \lambda_2 e_2.
  \]
  \pause
- As a matrix
  #+BEGIN_latex
  \[
  \begin{pmatrix}
  \lambda_1 & 0 \\
  0 & \lambda_2
  \end{pmatrix}
  \begin{pmatrix}
  X^1 \\
  X^2
  \end{pmatrix}
  =
  \begin{pmatrix}
  \lambda_1 X^1 \\
  \lambda_2 X^2
  \end{pmatrix}.
  \]
  #+END_latex
**** Quadratic Forms

Let \(B\) be a symmetric bi-linear form.

\pause

Define the /quadratic form/ \(Q\):
\[
Q(X) = B(X, X).
\]

\pause

\(Q\) is quadratic in the sense that
\[
Q(cX) = B(cX, cX) = c^2 B(X, X) = c^2 Q(X).
\]

\pause

Notice that
#+BEGIN_latex
\[
\begin{split}
Q(X + Y) &= B(X + Y, X + Y) = B(X, X + Y) + B(Y, X + Y) \\
&= B(X, X) + B(X, Y) + B(Y, X) + B(Y, Y) \\
&= Q(X) + 2B(X, Y) + Q(Y)
\end{split}
\]
#+END_latex

\pause

Thus, by symmetry and bi-linearity we may recover \(B\) from \(Q\):
\[
B(X, Y) = \frac{1}{2}\left[Q(X + Y) - Q(X) - Q(Y)\right].
\]
** MATH3405 Differential Geometry: Week 9
*** Lecture 9.1: Principal, Mean and Gauss Curvatures
**** Principal curvatures and Principal Directions

#+BEGIN_definition
The /principal curvatures/ \(\kappa_1, \kappa_2\) are the eigenvalues of the Weingarten shape operator. The eigenvectors, \(e_1, e_2\) are called /principal directions/.
#+END_definition

\pause

- Note that the principal curvatures (and directions) vary from point to point, since \(dN\) varies from point to point. \pause
- From Lecture 8.2: /Curvature and the Second Fundamental Form/, we know that \(dN\) is self-adjoint. \pause
- From Lecture 8.3: /Self Adjoint Operators and Eigenvalues and Eigenvectors/ we know that \(\kappa_1,\kappa_2\) exist and that there exists an orthonormal basis \(e_1, e_2\) of eigenvectors. \pause
- With respect to \(e_1, e_2\),
\[
dN = \begin{pmatrix}
\kappa_1 & 0 \\
0 & \kappa_2
\end{pmatrix}.
\]

**** Examples

#+BEGIN_latex
\begin{example}
The sphere \(\sphere^2(r) = \{x^2 + y^2 + z^2 = r^2\}\). \pause
\begin{itemize}
\item \(dN = -\tfrac{1}{r}\operatorname{Id}\): \(\kappa_1 = \kappa_2 = \tfrac{1}{r}\). \pause
\item All directions are principal directions!
\end{itemize}
\end{example}
#+END_latex

\pause

#+BEGIN_latex
\begin{example}
The cylinder \(\mathbb{C}^2(r) = \{x^2 + y^2 = r^2\}\).
\begin{itemize}
\item \(dN = -\tfrac{1}{r} \pi_{\{z=0\}}\) \pause
\item In the local parametrisation \((r\cos\theta, r\sin\theta, z)\):
\[
dN = \begin{pmatrix}
0 & 0 \\
0 & \tfrac{1}{r}
\end{pmatrix}.
\]
\pause
\item \(\kappa_1(r, \theta) = 0\), \quad \(e_1(r, \theta) = (0, 0, 1)\). \pause
\item \(\kappa_2(r, \theta) = \frac{1}{r}\), \quad \(e_2(r, \theta) = (-\sin\theta, \cos\theta, 0)\)
\end{itemize}
\end{example}
#+END_latex

**** Mean Curvature and Gauss Curvature

#+BEGIN_definition
The /Mean Curvature/ is
\[
H := \operatorname{Tr} (\mathcal{W}) = \operatorname{Tr} (-dN) = \frac{1}{2} \left(\kappa_1 + \kappa_2\right).
\]
\pause
The /Gauss Curvature/ is
\[
K := \det(\mathcal{W}) = \det (-dN) = \kappa_1 \kappa_2.
\]
#+END_definition

\pause

***** Examples

****** Example: Plane \(\RR^2\)
       :PROPERTIES:
       :BEAMER_col: 0.3
       :END:

*Plane \(\RR^2\)*

- \(H = 0\)
- \(K = 0\).

\pause

****** Example: Sphere \(\sphere^2\)
       :PROPERTIES:
       :BEAMER_col: 0.3
       :END:

*Sphere \(\sphere^2\)*

- \(H = \frac{1}{r}\)
- \(K = \frac{1}{r^2}\).

\pause

****** Example: Cylinder \(\mathbb{C}^2(r)\)
       :PROPERTIES:
       :BEAMER_col: 0.3
       :END:

*Cylinder \(\mathbb{C}^2(r)\)*

- \(H = \frac{1}{2r}\)
- \(K = 0\).

**** Umbilic Points

#+BEGIN_theorem
A point \(p \in S\) is called /umbilic/ if \(\kappa_1 = \kappa_2\). If *every* point of a /connected/ regular surface \(S\) is umbilic, then \(S\) is entirely contained in a plane, or a sphere.
#+END_theorem

\pause

- At an umbilic point \(p\),
  \[
  dN_p = \kappa(p) \operatorname{Id}
  \]
  where \(\kappa_1(p) = \kappa_2(p) = \kappa(p)\). \pause
- Therefore, umbilic points are points where the surface curves the same way in all directions. \pause
- The basic idea is to show that \(\kappa(p) \equiv \text{constant}\).

**** Proof of Umbilic Point Theorem: \(\kappa \equiv \text{constant}\).

- With respect to a local parametrisation with \(\varphi_u = \partial_u \varphi, \varphi_v = \partial_v \varphi\):
  \[
  dN(\varphi_u) = \partial_u N, \quad dN(\varphi_v) = \partial_v N.
  \]
  \pause
- Thus \(dN = \kappa \operatorname{Id}\) gives,
  \[
  \partial_u N = \kappa \varphi_u, \quad \partial_v N = \kappa \varphi_v.
  \]
  \pause
- What's next? \pause Differentiate!
  \[
  \partial_v \partial_u N = \kappa_v \varphi_u + \kappa \partial_v \partial_u \varphi
  \]
  and
  \[
  \partial_u \partial_v N = \kappa_u \varphi_v + \kappa \partial_u \partial_v \varphi
  \]
  \pause
- Subtracting and use Claireaut's Theorem for mixed partial derivatives:
  \[
  \kappa_v \varphi_u = \kappa_u \varphi_v \Rightarrow \kappa_v = \kappa_u = 0 \Rightarrow \kappa \equiv \text{constant}
  \]
  since \(\varphi_u, \varphi_v\) are linearly independent.
**** Proof of Umbilic Point Theorem: Locally \(S \subseteq \RR^2\)

- We have
  \[
  dN \equiv 0.
  \]
  \pause
- Therefore
  \[
  \partial_u \ip{\varphi}{N} \underset{\text{prod rule}}{=} \ip{\varphi_u}{N} + \ip{\varphi}{dN(\varphi_u)} \pause \underset{dN \equiv 0}{=} \ip{\varphi_u}{N} \pause \underset{\varphi_u \text{ tang}} = 0
  \]
  \pause
  Likewise
  \[
  \partial_v \ip{\varphi}{N} = 0.
  \]
  \pause
  Therefore \(\ip{\varphi}{N} = \text{constant}\) and the points \(\varphi(u, v)\) lie in a plane.

**** Proof of Umbilic Point Theorem: Locally \(S \subseteq \sphere^2\).

- We have
  \[
  dN = \kappa \operatorname{Id}, \quad \kappa \ne 0
  \]
  \pause
- Therefore
  \[
  \partial_u \left(\varphi - \tfrac{1}{\kappa} N\right) \underset{\kappa \equiv \text{const}}{=} \varphi_u - \frac{1}{\kappa} dN(\varphi_u) \pause \underset{dN=\kappa\operatorname{Id}}{=} \varphi_u - \frac{1}{\kappa} \kappa \varphi_u = 0.
  \]
  \pause
- Likewise
  \[
  \partial_v \left(\varphi - \tfrac{1}{\kappa} N\right) = 0.
  \]
  \pause
- Therefore
  \[
  \varphi - \frac{1}{\kappa} N = y_0 \in \RR^3 \text{ is constant}.
  \]
  \pause
- and hence
  \[
  \abs{\varphi(u, v) - y_0} = \frac{1}{\abs{\kappa}} \Rightarrow \varphi(u, v) \in \sphere^2(\frac{1}{\abs{\lambda}}, y_0).
  \]

**** Proof of Umbilic Theorem: Global

- The local theorem establishes, for each local parametrisation \(\varphi\):
  #+BEGIN_latex
  \begin{align*}
  \kappa_{\varphi} &\equiv \text{constant} \\
  & \begin{cases}
  N_{\varphi} \equiv \text{const}, \ip{\varphi}{N_{\varphi}} \equiv C_{\varphi}, & \kappa_{\varphi} = 0 \Rightarrow S_{\varphi} \subseteq \RR^2(N_{\varphi}, C_{\varphi}) \\
  \varphi - \frac{1}{\kappa_{\varphi}} \equiv y_{\varphi}, & \kappa_{\varphi} \ne 0 \Rightarrow S_{\varphi} \subseteq \sphere^2(\tfrac{1}{\abs{\kappa_{\varphi}}}, y_{\varphi})
  \end{cases}
  \end{align*}
  #+END_latex
  \pause
- In any overlap of charts, \(U_{\alpha} \cap U_{\beta}\) all the constants must agree. \pause
- \(S\) connected, means for any two points \(p, q \in S\) there is a continuous path \(\gamma : [0, 1] \to S\) such that \(\gamma(0) = p\), \(\gamma(1) = q\). \pause
- Cover the image \(\gamma([0, 1])\) by local parametrisations \(\varphi_{\alpha}(U_{\alpha})\) which gives a cover of \([0, 1]\):
  \[
  \varphi_{\alpha}^{-1}(U_{\alpha})
  \]
  \pause
- \([0, 1]\) is /compact/ so there is a finite cover \(\{\varphi_i\}_{i=1}^n\). with \(p \in \varphi_1(U_1)\), \(q \in \varphi_n(U_n)\), \(U_i \cap U_{i+1} \ne \emptyset\) \pause
- Thus \(\kappa(p) = \kappa_{\varphi_1} = \kappa_{\varphi_2} = \cdots = \kappa_{\varphi_n} = \kappa(q)\). Similar for the other constants so the plane (or sphere) is globally defined. \(\qed\)
*** Lecture 9.2: Local Expressions of Curvature

**** The local shape

#+BEGIN_definition
A point \(p \in S\) is called,
- Elliptic if \(K > 0\) (\(\kappa_1\) and \(\kappa_2\) have the same sign) \pause
- Hyperbolic if  \(K < 0\) (\(\kappa_1\) and \(\kappa_2\) have the opposite sign) \pause
- Parabolic if \(K = 0\) but \(dN_p \ne 0\) (\(\kappa_1 = 0\) and \(\kappa_2 \ne 0\)) \pause
- Planar if \(dN_p = 0\) and hence \(K = 0\) (\(\kappa_1 = \kappa_2 = 0\))
#+END_definition

**** Elliptic and Hyperbolic
***** Elliptic Point
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/paraboloid.png]]
#+END_center

***** Hyperbolic Point
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/hyperbolic.png]]
#+END_center

**** Planar and Parabolic
***** Planar Point
   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/plane.png]]
#+END_center

***** Parabolic Point

   :PROPERTIES:
   :BEAMER_col: 0.5
   :END:

#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .5\textheight
[[file:img/cylinder.png]]
#+END_center

**** Local Coordinate Expressions

Let \(S\) be oriented with
\[
N = \frac{\varphi_u \times \varphi_v}{|\varphi_u \times \varphi_v|}
\]
\pause

Tangent vectors are all of the form
\[
X = \partial_t|_{t=0} \varphi(\gamma(t)) = u' \varphi_u + v' \varphi_v.
\]
where
\[
\gamma(t) = (u(t), v(t)).
\]

\pause

In this basis write, \(X = X^u \varphi_u + X^v \varphi_v\) (i.e. \(X^u = u', X^v = v'\)) and
#+BEGIN_latex
\[
dN(X) = \begin{pmatrix}
dN_{uu} & dN_{uv} \\
dN_{vu} & dN_{vv}
\end{pmatrix}
\begin{pmatrix}
X^u \\
X^v
\end{pmatrix}
\]
#+END_latex
\pause

*The matrix \(dN\) is only symmetric if \(\varphi_u, \varphi_v\) is orthonormal  with respect to \(g\)!*

**** Local Coordinate Expressions
- Remember \(\mathcal{W} = -dN\). \pause
- Mean Curvature
  \[
  H = -\frac{1}{2} (dN_{uu} + dN_{vv}).
  \]
  \pause
- Gauss Curvature
  \[
  K = dN_{uu} dN_{vv} - dN_{uv} dN_{vu}.
  \]
  \pause
- Principal Curvatures \(\kappa\): roots of the characteristic equation
  #+BEGIN_latex
  \[
  \begin{split}
  0 &= \det(-dN - \kappa \operatorname{Id}) \\
  &= -\left[\kappa^2 + (dN_{uu} + dN_{vv})\kappa + dN_{uu} dN_{vv} - dN_{uv} dN_{vu}\right].
  \end{split}
  \]
  #+END_latex
  \pause
- Characteristic equation in terms of \(H, K\):
  \[
  \kappa^2 - 2H \kappa + K = 0
  \]

**** Example: The Torus

Parametrise part of a torus by,
\[
\varphi(u, v) = ((\frac{1}{2} \cos(u) + 1)\cos (v), (\frac{1}{2} \cos(u) + 1)\sin (v), \frac{1}{2} \sin(u))
\]
\pause

#+BEGIN_latex
\begin{align*}
\varphi_u &= (-\frac{1}{2} \sin(u) \cos (v), -\frac{1}{2} sin(u) \sin (v), \frac{1}{2} \cos(v)) \\
\varphi_v &= (-(\frac{1}{2} \cos(u) + 1)\sin (v), (\frac{1}{2} \cos(u) + 1)\cos (v), 0)
\end{align*}
#+END_latex
\pause

\[
N = -(\cos(u) \cos(v), \cos(u) \sin(v), \sin(u))
\]

**** Example: The Torus

Compute \(dN\):

#+BEGIN_latex
\begin{align*}
\partial_u N &= -(-\sin(u) \cos(v), -\sin(u) \sin(v), \cos(u)) = \frac{1}{2} \varphi_u \\
\partial_v N &= -(-\cos(u) \sin(v), \cos(u) \cos(v), 0) = \frac{\cos(u)}{(\frac{1}{2} \cos(u) + 1)} \varphi_v
\end{align*}
#+END_latex

\pause

That is
#+BEGIN_latex
\[
dN = -\begin{pmatrix}
1/2 & 0 \\
0 & \frac{\cos(u)}{\frac{1}{2} \cos(u) + 1}
\end{pmatrix}
\]
#+END_latex

\pause

#+BEGIN_latex
\begin{align*}
H &= \left(\frac{1}{4} + \frac{\cos(u)}{\cos(u) + 2}\right) \\
K &= \frac{\cos(u)}{\cos(u) + 2}
\end{align*}
#+END_latex

**** Local Coordinate Expressions

Recall the metric:
#+BEGIN_latex
\[
g = \begin{pmatrix}
\abs{\varphi_u}^2 & \ip{\varphi_u}{\varphi_v} \\
\ip{\varphi_v}{\varphi_u} & \abs{\varphi_v}^2
\end{pmatrix}
=: \begin{pmatrix}
g_{uu} & g_{uv} \\
g_{vu} & g_{vv}
\end{pmatrix}.
\]
#+END_latex
\pause

Therefore
#+BEGIN_latex
\[
\begin{split}
A(X, X) &= g(-dN(X), X) \\
& = -\left[\begin{pmatrix}
dN_{uu} & dN_{uv} \\
dN_{vu} & dN_{vv}
\end{pmatrix}
\begin{pmatrix}
X^u \\
X^v
\end{pmatrix}
\right]^T
\begin{pmatrix}
g_{uu} & g_{uv} \\
g_{vu} & g_{vv}
\end{pmatrix}
\begin{pmatrix}
X^u \\
X^v
\end{pmatrix}
\\
&= (dN_{uu}g_{uu} + dN_{vu}g_{vu}) (X^u)^2 \\
&\quad + (dN_{uu} g_{uv} + dN_{vv}g_{vu}) X^u X^v \\
&\quad + (dN_{uv} g_{uv} + dN_{vv} g_{vv}) (X^v)^2.
\end{split}
\]
#+END_latex

**** Local Coordinate Expressions

On the other hand,
#+BEGIN_latex
\[
\begin{split}
A(X, X) &= A(X^u \varphi_u + X^v \varphi_v, X^u \varphi_u + X^v \varphi_v) \\
&= A(\varphi_u, \varphi_u) (X^u)^2 + 2(\varphi_u, \varphi_v) X^u X^v + A(\varphi_v, \varphi_v) (X^v)^2
\end{split}
\]
#+END_latex

\pause

In matrix form
#+BEGIN_latex
\[
\begin{split}
A(X, X) &= \begin{pmatrix}
X^u \\
X^v
\end{pmatrix}^T
\begin{pmatrix}
A_{uu} & A_{uv} \\
A_{vu} & A_{vv}
\end{pmatrix}
\begin{pmatrix}
X^u \\
X^v
\end{pmatrix}
\\
&= -\begin{pmatrix}
X^u \\
X^v
\end{pmatrix}^T
\begin{pmatrix}
dN_{uu} & dN_{uv} \\
dN_{vu} & dN_{vv}
\end{pmatrix}^T
\begin{pmatrix}
g_{uu} & g_{uv} \\
g_{vu} & g_{vv}
\end{pmatrix}
\begin{pmatrix}
X^u \\
X^v
\end{pmatrix}
\end{split}
\]
#+END_latex
**** Local Coordinate Expressions
We have
\[
A = -dN^T g.
\]

\pause

Since \(A, g\) are symmetric
\[
A = A^T = - g^T dN = - gdN
\]
or
\[
dN = -g^{-1} A.
\]

\pause

Therefore
\[
K = \det dN = \frac{\det A}{\det g} = \frac{A_{uu}A_{vv} - A_{uv}^2}{g_{uu}g_{vv} - g_{uv}^2}.
\]

**** Local Coordinate Expressions

For the torus, it was easy to write \(dN(\varphi_u)\) and \(dN(\varphi_v)\) as a linear combination of \(\varphi_u, \varphi_v\). But in general this may not be so easy.

\pause

In general we need to solve
\[
\partial_u N = dN(\varphi_u) = dN_{uu} \varphi_u + dN_{vu} \varphi_v
\]
and
\[
\partial_v N = dN(\varphi_v) = dN_{uv} \varphi_u + dN_{vv} \varphi_v
\]

for \(dN_{uu}, dN_{vu}, dN_{uv}, dN_{vv}\).

\pause

We know:
\[
\varphi_u, \varphi_v, N
\]
is a basis and we know the components in the standard basis of \(\RR^3\), e.g:
\[
\varphi_u = (\partial_u x, \partial_u y, \partial_u z) \text{ where } \varphi(u, v) = (x(u, v), y(u, v), z(u, v)).
\]

\pause

Compute the change of basis matrix!

\pause

Another approach is...

**** Local Coordinate Expressions

Recall that
\[
\det g = \abs{\varphi_u \times \varphi_v}^2
\]
so we may express \(\det g\) in terms of the derivatives of \(\varphi\).

\pause

Similarly we may express \(A\):
\[
A_{uu} = -\ip{dN(\varphi_u)}{\varphi_u} = -\partial_u \ip{N}{\varphi_u} + \ip{N}{\varphi_{uu}} = \frac{1}{|\varphi_u \times \varphi_v|}\ip{\varphi_u \times \varphi_v}{\varphi_{uu}}
\]

\pause

\[
A_{vv} = \frac{1}{|\varphi_u \times \varphi_v|}\ip{\varphi_u \times \varphi_v}{\varphi_{vv}}
\]

\[
A_{uv} = A_{vu} = \frac{1}{|\varphi_u \times \varphi_v|}\ip{\varphi_u \times \varphi_v}{\varphi_{uv}}
\]

**** Example: The Torus

Recall
\[
\varphi(u, v) = ((\frac{1}{2} \cos(u) + 1)\cos (v), (\frac{1}{2} \cos(u) + 1)\sin (v), \frac{1}{2} \sin(u))
\]
\pause

#+BEGIN_latex
\begin{align*}
\varphi_u &= (-\frac{1}{2} \sin(u) \cos (v), -\frac{1}{2} sin(u) \sin (v), \frac{1}{2} \cos(u)) \\
\varphi_v &= (-(\frac{1}{2} \cos(u) + 1)\sin (v), (\frac{1}{2} \cos(u) + 1)\cos (v), 0) \\
\varphi_{uu} &= (-\frac{1}{2} \cos(u) \cos (v), -\frac{1}{2} cos(u) \sin (v), -\frac{1}{2} \sin(u)) \\
\varphi_{vv} &= (-(\frac{1}{2} \cos(u) + 1)\cos (v), -(\frac{1}{2} \cos(u) + 1)\sin (v), 0) \\
\varphi_{uv} &= (\frac{1}{2} \sin(u) \sin (v), -\frac{1}{2} sin(u) \cos (v), 0) \\
\end{align*}
#+END_latex

\pause

*Exercise*: Check that \(K\) is as before!
*** Lecture 9.3: Minimal Surfaces
**** Minimal or Area Minimising?

#+BEGIN_definition
An /area minimising/ surface is a surface whose area is less than all other surfaces in some family (such as surfaces with the same boundary).
#+END_definition

\pause

#+BEGIN_definition
A /minimal surface/ is a /critical point/ for the area functional.
#+END_definition

\pause

The term /minimal surface/ is due to Lagrange. Unfortunately, it does not mean area-minimising as one might expect but the terminology has become standard.

\pause

Now we explain what all this means!

**** Variations 

Choose a local parametrisation \(\varphi : U \to S\). Let \(\bar{D} \subseteq U\) be a bounded domain (e.g. closed unit disc \(D(r) = \{u^2 + v^2 \leq r\}\)).

\pause

#+BEGIN_definition
A /normal variation/ of \(S\) over \(D\) is a map of the form
\[
\Phi (u, v, t) = \varphi(u, v) + t h(u, v) N(u, v) \in \RR^3
\]
where \(N\) is the normal vector to \(S\) and \(h : \bar{D} \to \RR\) is a smooth function and \(-\epsilon < t < \epsilon\) for some \(\epsilon > 0\).
#+END_definition

\pause

- For each fixed \(t_0\),
  \[
  \varphi_{t_0}(u, v) := \Phi(u, v, t_0)
  \]
  parametrises a regular surface \(S_t\): \pause \(d\varphi_t = d\varphi + t d(hN)\) is injective for small \(t\). \pause
- \(\varphi_0 = \varphi\) parametrises \(S\).

**** Variation of Area

Let us write \(D_t = \varphi_t(D)\). \pause

Recall that the area of \(D_t\) is:
\[
A(t) := \operatorname{Area}(D_t) = \int_D \sqrt{\det g_t} dudv = \int_D |\partial_u \varphi_t \times \partial_v \varphi_t| du dv.
\]

\pause

#+BEGIN_definition
The regular surface \(D_0\) is a /minimal surface/ if
\[
A'(0) = 0
\]
for every smooth function \(h : \bar{D} \to \RR\).
#+END_definition

\pause

Recall \(h\) is the /normal speed/ of the variation \(\varphi(u, v) + t h(u, v) N(u, v)\).

\pause

#+BEGIN_theorem
The regular surface \(D_0\) is minimal if and only if the mean curvature \(H = 0\).
#+END_theorem

**** Minimal Surfaces

- The previous definition and theorem says that locally (i.e. on \(\bar{D}\)) a surface is minimal if the mean curvature vanishes on \(\bar{D}\). \pause
- The mean curvature of \(D_0\) is just the mean curvature of \(S\) restricted to \(S\). \pause
- We may then make a /global/ definition of minimal surface. \pause

#+BEGIN_definition
A regular surface \(S\) is a minimal surface if \(H = 0\) everywhere on \(S\).
#+END_definition

**** Examples
- Any plane,
  \[
  P = \{p \in \RR^3 : \ip{p}{V_0} = C_0\}
  \]
  is minimal. \pause
- The sphere, cylinder and torus are *not* minimal. \pause
- The graph of a function \(f : U \subseteq \RR^2 \to \RR\) is minimal if and only if
  \[
  (1 + (f_u)^2)f_{vv} + (1 + f_v)^2 f_{uu} - 2 f_u f_v f_{uv} = 0, \quad \text{minimal surface equation}
  \]
  \pause
- Bee hives! The walls of honeycomb are minimal surfaces. \pause
- Catenoid, Helicoid \pause
- Enneper surface: Not embedded. That is, it intersects itself. \pause
- Costa's surface: Discovered in 1982 disproving the conjecture that the Plane, Helicoid and Catenoid are the only embedded minimal surfaces formed by puncturing a compact surface. Sparked of a new era of minimal surface research!

**** A Gallery of Minimal Surfaces

#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .8\textheight
[[file:img/minimal_surfaces.png]]
#+END_center

**** Proof of Theorem

Recall that
\[
\varphi_t(u, v) = \varphi(u, v) + t h(u, v) N(u, v).
\]

\pause

We have
\begin{align*}
\partial_u \varphi_t &= \partial_u \varphi + t (\partial_u h) N + t h \partial_u N \\
\partial_v \varphi_t &= \partial_v \varphi + t (\partial_v h) N + t h \partial_v N
\end{align*}

\pause

The metric is given by
#+BEGIN_latex
\[
\begin{split}
g_{uu}(t) &= \ip{\partial_u \varphi_t}{\partial_u \varphi_t} \\
&= \ip{\partial_u \varphi + t (\partial_u h) N + t h \partial_u N}{\partial_u \varphi + t (\partial_u h) N + t h \partial_u N} \\
&= g_{uu} + 2 t \left(\partial_u h \ip{\partial_u \varphi}{N} + h\ip{\partial_u \varphi}{\partial_u N}\right) + t^2 \text{ terms} \\
&= g_{uu} + 2t h A_{uu} + t^2 \text{ terms}
\end{split}
\]
#+END_latex

\pause

Plus similar expressions for \(g_{uv}(t) = g_{vu}(t)\) and \(g_{vv}(t)\).

**** Proof of Theorem

We have
\[
g(t) = g + 2t h A + t^2 \text{ terms}.
\]

\pause

Differentiating and evaluating at \(t = 0\):
\[
g'(0) = 2 h A.
\]

\pause

Recall the area is given by
\[
A(t) = \int_{\bar{D}} \sqrt{\det g(t)} du dv.
\]

\pause

Therefore
\[
A'(0) = \int \frac{1}{2 \sqrt{\det g(0)}} \partial_t|_{t=0} (\det g(t)) du dv.
\]
and we need to differentiate the determinant.

**** Proof of Theorem

Differentiating a determinant:
#+BEGIN_latex
\[
\begin{split}
\partial_t \det g(t) &= \partial_t \left[g_{uu}(t) g_{vv}(t) - g_{uv}(t)^2 \right] \\
&= g_{uu} \partial_t g_{vv} + g_{vv} \partial_t g_{uu} - 2g_{uv} \partial_t g_{uv}.
\end{split}
\]
#+END_latex

\pause

Now the clever part:
#+BEGIN_latex
\[
\begin{split}
g^{-1} \partial_t g &= \frac{1}{\det g} \begin{pmatrix}
g_{vv} & -g_{uv} \\
-g_{vu} & g_{uu}
\end{pmatrix}
\begin{pmatrix}
\partial_t g_{uu} & \partial_t g_{uv} \\
\partial_t g_{vu} & \partial_t g_{vv}
\end{pmatrix} \\
&=
\frac{1}{\det g} \begin{pmatrix}
g_{vv}\partial_t g_{uu} - g_{uv} \partial_t g_{vu} & g_{vv}\partial_t g_{uv} - g_{uv} \partial_t g_{vv} \\
-g_{vu}\partial_t g_{uu} + g_{uu} \partial_t g_{vu} & -g_{vu}\partial_t g_{uv} + g_{uu} \partial_t g_{vv}
\end{pmatrix}
\end{split}
\]
#+END_latex

\pause

#+BEGIN_latex
\[
\begin{split}
\operatorname{Trace} \left(g^{-1} \partial_t g\right) &= \frac{1}{\det g} \left(g_{uu} \partial_t g_{vv} + g_{vv} \partial_t g_{uu} - 2g_{uv} \partial_t g_{uv}\right) \\
&= \frac{1}{\det g} \partial_t \det g.
\end{split}
\]
#+END_latex

**** Proof of Theorem

So we have
\[
\partial_t \det g = \det g \operatorname{Trace} \left(g^{-1} \partial_t g\right).
\]

\pause

Thus we obtain
#+BEGIN_latex
\[
\begin{split}
A'(0) &= \int \frac{1}{2 \sqrt{\det g(0)}} \partial_t|_{t=0} (\det g(t)) du dv \\
&= \int \frac{1}{2 \sqrt{\det g(0)}} \det g(0) \operatorname{Trace} (g^{-1} (0) \partial_t|_{t=0} g) du dv \\
&= \int \frac{1}{2} \operatorname{Trace} (g^{-1} (0) g'(0)) \sqrt{\det g(0)} du dv 
\end{split}
\]
#+END_latex

**** Proof of Theorem

Recall that
\[
g'(0) = 2h A(0).
\]

\pause

Hence
\[
\frac{1}{2} \operatorname{Trace} (g^{-1}(0) g'(0)) = \frac{1}{2} \operatorname{Trace} (g^{-1}(0) 2 h A(0)) = h \operatorname{Trace} dN = -2hH.
\]

\pause

Finally we arrive at
\[
A'(0) = -2 \int_{\bar{D}} h H \sqrt{\det g} du dv.
\]

\pause

Therefore, \(\bar{D}\) is minimal if and only if for every \(h\), \(A'(0) = 0\) if and only if \(H = 0\).

\pause

For example, to show that for an arbitrary \(p\), \(H(p) = 0\) choose \(h = \rho H\) where \(\rho(p) = 1\) and \(\rho \equiv 0\) outside a small neighbourhood around \(p\).

** MATH3405 Differential Geometry: Week 10
*** Lecture 10.1: Holiday
*** Lecture 10.2: Riemannian Manifolds
**** Smooth Manifolds: Intrinsic Surfaces
#+BEGIN_definition
A set \(M\) is a (two-dimensional) /smooth manifold/ if there exists a cover \(U_{\alpha}\) of \(M\) and maps \(\varphi_{\alpha} : U_{\alpha} \to \RR^2\) such that \pause
1. each \(\varphi_{\alpha}\) is a one-to-one and onto an open set \(V_{\alpha} = \varphi_{\alpha}(U_{\alpha}) \subseteq \RR^2\), \pause
2. \(\varphi_{\alpha}(U_{\alpha} \intersect U_{\beta})\) is open, \pause
2. the transition maps
   \[
   \tau_{\alpha\beta} = \varphi_{\beta} \circ \varphi_{\alpha}^{-1} : \varphi_{\alpha}(U_{\alpha} \cap U_{\beta}) \to \varphi_{\beta} (U_{\alpha}\cap U_{\beta})
   \]
   are diffeomorphisms. That is, \(\tau_{\alpha\beta}\) is differentiable and has a differentiable inverse.
#+END_definition

\pause

- In fact, it's enough to assume that \(\tau_{\alpha\beta}\) is differentiable for each \(\alpha, \beta\) since \(\tau_{\alpha\beta}^{-1} = \tau_{\beta\alpha}\). \pause
- The maps \(\varphi_{\alpha} : U_{\alpha} \to \RR^2\) are called /charts/. \pause
- The collection of all the charts is called an /atlas/.
**** Charts on a Manifold

#+BEGIN_center
#+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/manifold_charts.png]]
#+END_center

**** Regular Surfaces are Manifolds

#+BEGIN_latex
\begin{example}
Let \(S \subset \RR^3\) be a regular surface. Then we have a cover of \(S\) by local parametrisations
\[
\psi_{\alpha} : V_{\alpha} \subseteq \RR^2 \to \RR^3.
\]
\pause
Then \(S\) is a smooth manifold with charts given by
\[
\varphi_{\alpha} = \psi_{\alpha}^{-1} : U_{\alpha} = \psi_{\alpha}(V_{\alpha}) \subseteq M \to V_{\alpha} \subseteq \RR^2.
\]
\end{example}
#+END_latex

\pause

Note that
\[
\tau_{\alpha\beta} = \varphi_{\beta} \circ \varphi_{\alpha}^{-1} = \psi_{\beta}^{-1} \circ \psi_{\alpha}
\]
is differentiable by the assumption that \(S\) is a regular surface.

**** Example: The Affine Group.

#+BEGIN_latex
\begin{example}
The affine group is the set of matrices:
\[
\mathcal{A} = \left\{\begin{pmatrix}
a & b \\
0 & 1
\end{pmatrix}
: a, b \in \RR, a > 0
\right\}
\]

\pause

It corresponds to \emph{orientation preserving affine transformations} \(\RR \to \RR\): \pause
\[
x \mapsto a x + b \rightsquigarrow \begin{pmatrix} x \\ 1 \end{pmatrix} \mapsto \begin{pmatrix} a & b \\ 0 & 1\end{pmatrix} \begin{pmatrix} x \\ 1 \end{pmatrix} = \begin{pmatrix} ax + b\\ 1 \end{pmatrix}
\]

\pause

\begin{itemize}
\item Smooth manifold with a single chart \(\varphi(A_{ij}) = (A_{11}, A_{12})\) maps bijectively with the open set \(\{(a, b) \in \RR^2 : a > 0\}\). \pause
\item Also a regular surface, being "half" a plane: \(\{(a, b, 0) \in \RR^3 : a > 0\}\).
\end{itemize}
\end{example}
#+END_latex

**** Example: Projective Space

#+BEGIN_latex
\begin{example}
Two dimensional real Projective Space, \(\mathbb{RP}^2\) is the set of lines through the origin in \(\RR^3\):
\[
\mathbb{RP}^2 = \{[V] : V \ne 0 \in \mathbb{R}^3, \quad [V] = \{\lambda V : V \ne 0\}\}.
\]

\pause

An atlas is given by three charts. The first:
\[
\begin{split}
\varphi_1 : U_1 &= \{[V] = [(V_1, V_2, V_3)] : V_1 \ne 0\} \to \RR^2 \\
[V] &\mapsto \left(\frac{V_2}{V_1}, \frac{V_3}{V_1}\right).
\end{split}
\]
This maps bijectively with $\RR^2$. Similarly $U_2$ has $V_2 \ne 0$ and $U_3$ has $V_3 \ne 0$.
\end{example}
#+END_latex

**** Example: Projective Space

#+BEGIN_latex
\begin{example}
\begin{itemize}
\item The transition map is defined on \(U_1 \cap U_2 = \{[V] : V_1, V_2 \ne 0\}\). \pause
\item Then we have
\[
\begin{split}
\varphi_1(U_1 \cap U_2) &= \{\varphi_1([V]) : V_1, V_2 \ne 0\} \\
&= \left\{\left(\frac{V_2}{V_1}, \frac{V_3}{V_1}\right) : V_1, V_2 \ne 0\right\} \\
&= \{(x, y) : x \ne 0\}.
\end{split}
\]
\pause
\item Explicitly
\[
\begin{split}
\tau_{12} : (x, y) \overset{\varphi_1^{-1}}{\mapsto} [(1, x, y)] \overset{\varphi_2}{\mapsto} (1/x, y/x)
\end{split}
\]
\pause
\item \(\tau_{12}\) is differentiable for \((x, y) \in \varphi_1(U_1 \cap U_2)\) since then \(x \ne 0\).
\end{itemize}
\end{example}
#+END_latex

**** The Tangent Space

Define an equivalence class of curves: \(\gamma \sim \sigma\) if
\[
\gamma(0) = \sigma(0)
\]
\pause and there is a chart \(\varphi : U \to \RR^2\) with \(\gamma(0) \in U\) such that
\[
(\varphi \circ \gamma)'(0) = (\varphi \circ \sigma)'(0).
\]
\pause
Write \([\gamma] = \{\sigma : \sigma \sim \gamma\}\) for the equivalence class of \(\gamma\).
\pause

#+BEGIN_latex
\begin{definition}
The tangent space, $T_x M$ to $M$ at $x$ is the equivalence class of curves through \(x\)
\[
T_x M = \{[\gamma] : \gamma(0) = x\}.
\]
\end{definition}
#+END_latex

\pause

If we choose a different chart, \(\psi\)
#+BEGIN_latex
\[
\begin{split}
(\psi \circ \gamma)'(0) &= (\psi \circ \varphi^{-1} \circ \varphi \circ \gamma)'(0) \\
&= d(\psi \circ \varphi^{-1}) \cdot (\varphi \circ \gamma)'(0) = d(\psi \circ \varphi^{-1}) \cdot (\varphi \circ \sigma)'(0) \\
&= (\psi \circ \sigma)'(0).
\end{split}
\]
#+END_latex

**** The Tangent Space of a Regular Surface

Recall that for a regular surface
\[
T_x S = \{\gamma'(0) : \gamma(0) = x\}
\]
where \(\gamma'(0)\) is the derivative at zero of \(\gamma : (-\epsilon, \epsilon) \to S \subseteq \RR^3\) as a curve in \(\RR^3\).

\pause

The new definition says tangent vectors are equivalence classes of curves \([\gamma]\) in \(S\). \pause

The definitions will be equivalent provided:

- \(\gamma'(0) = \sigma'(0)\) as vectors in \(\RR^3\) if and only if \([\gamma] = [\sigma]\).

**** The Tangent Space of a Regular Surface

Now recall that charts \(\varphi\) are just inverses of local parametrisations \(\psi\). That is \(\varphi = \psi^{-1}\). \pause

We have
\[
\gamma'(0) = \sigma'(0) \Leftrightarrow (\varphi^{-1} \circ \varphi \circ \gamma)'(0) = (\varphi^{-1} \circ \varphi \circ \sigma)'(0)
\]
\pause if and only if
\[
d(\varphi^{-1}) \cdot (\varphi \circ \gamma)'(0) = d(\varphi^{-1}) \cdot (\varphi \circ \sigma)'(0).
\]
\pause But \(\psi = \varphi^{-1}\) is a local parametrisation so that \(d(\varphi^{-1})\) injective. Therefore the last equation is equivalent to
\[
(\varphi \circ \gamma)'(0) = (\varphi \circ \sigma)'(0).
\]
\pause
That is \([\gamma] = [\sigma]\).

**** Coordinate Vector Fields

#+BEGIN_latex
\begin{definition}
With respect to chart \(\varphi\), we define \emph{coordinate vector fields}:
\[
X_u(x) = [\varphi^{-1}(\varphi(x) + (t, 0))], \quad X_v(x) = [\varphi^{-1}(\varphi(x) + (0, t))]
\]
\end{definition}
#+END_latex

\pause

- That is, \(\varphi : U \to \RR^2\) and so \(\varphi(x) \in \RR^2\). Then \(\varphi(x) + (t, 0)\) is a curve in \(\RR^2\) and
  \[
  \gamma_u(t) = \varphi^{-1}(\varphi(x) + (t, 0))
  \]
  is a curve in \(M\) with \(\gamma_u(0) = x\). \pause
- Thus \(X_u(x) = [\gamma_u]\) is a tangent vector at \(x\). \pause
- We think of \(X_u\) as \(\gamma_u'(0)\) (though strictly speaking, the derivative only makes sense in the chart).

*** Lecture 10.3: Isometries and Intrinsic Geometry
**** Riemannian Metrics

#+BEGIN_latex
\begin{definition}
A \emph{Riemannian metric} (or just metric) on \(M\) is a smooth choice, \(g_x\) of positive definite, symmetric bilinear form for each \(x \in M\).
\end{definition}
#+END_latex

\pause

There are various ways to interpret the term /smooth/ here. In the present context, perhaps the easiest way to define smooth is with respect to the coordinate vector fields: define \pause
#+BEGIN_latex
\[
\begin{split}
g_{uu}(x) &= g(X_u(x), X_u(x)), \quad g_{vv}(x) = g(X_v(x), X_v(x)) \\
g_{uv}(x) &= g(X_u(x), X_v(x)) = g(X_v(x), X_u(x)) = g_{vu}(x) .
\end{split}
\]

\pause

Then
\[
g_x = \begin{pmatrix}
g_{uu}(x) & g_{uv} (x) \\
g_{vu}(x) & g_{vv}(x)
\end{pmatrix}
\]
#+END_latex
is smooth if and only if the components, \(g_{uu}, g_{uv} = g_{vu}, g_{vv}\) are smooth functions in the chart: \(g_{uu} \circ \varphi : \RR^2 \to \RR\) is smooth etc.

**** Riemannian Geometry

We can define length, angle and area just as for regular surfaces. \pause

\[
\vert X\vert_g = \sqrt{g(X, X)}, \quad \text{length of a tangent vector}
\]
\pause
\[
\theta = \arccos\left(\frac{g(X, Y)}{|X|_g |Y|_g} \right) \quad \text{angle between tangent vectors}
\]
\pause
\[
L[\gamma] = \int_a^b |\gamma'(t) | dt \quad \text{arc-length of a curve}
\]
\pause
\[
A(R) = \int_R \sqrt{\det g} du dv \quad \text{area of a bounded region}
\]

**** Isometries

- Let \((S_1, g_1)\) and \((S_2, g_2)\) be two-dimensional Riemannian manifolds. \pause

- If you prefer, you can think of them as regular surfaces with
  \[
  g_i(X, Y) = \ip{d\varphi_i(X)}{d\varphi_i(Y)}
  \]
  in a local parametrisation with \(X = X^u \varphi_u + X^v \varphi_v\) (likewise for \(Y\)). \pause

#+BEGIN_definition
A diffeomorphism \(f : S_1 \to S_2\) is called an /isometry/ if
\[
g_2(df(X), df(Y)) = g_1(X, Y)
\]
for all tangent vectors \(X, Y\). If there is an isometry \(f : (S_1, g_1) \to (S_2, g_2)\), then \(S_1, S_2\) are called /isometric/.
#+END_definition

\pause

#+BEGIN_definition
A /local isometry/ is a diffeomorphism \(f : U_1 \to U_2\) for \(U_1 \subseteq S_1\), \(U_2 \subseteq S_2\) open sets. \(S_1\) and \(S_2\) are called /locally isometric/ if there is a cover of \(S_1\) by open sets \(U_{\alpha}\) and local isometries \(f_{\alpha} : U_{\alpha} \to V_{\alpha} \subseteq S_2\).
#+END_definition

**** Example: The Cylinder and Plane

Recall the local parametrisation of the cylinder, \(C\):
\[
\varphi(u, v) = (\cos u, \sin u, v), \quad 0 < u < 2\pi, \quad -1 < v < 1.
\]
\pause

Then \(U = \{\varphi(u, v)\} = \{(x, y, z) : x^2 + y^2 = 1, y \ne 0, -1 < z < 1\}\) is an open set. \pause

- *Claim*: \(\varphi\) is a local isometry \(P \to C\) for any plane \(P\). For example \(P = \{z = 0\}\).

**** Example: The Cylinder and Plane

The coordinate vector fields on \(P\) are:
\begin{align*}
e_u(u, v) &= \partial_t|_{t=0} (u + t, v) =(1, 0), \\
e_v(u, v) &= \partial_t|_{t=0} (u, v + t) = (0, 1).
\end{align*}

\pause

The metric on the plane is just the usual metric:
\[
g_P(X^ue_u + X^ve_v, Y^ue_u + Y^ve_v) = X^u Y^u + X^v Y^v.
\]

\pause

The cylinder metric is
#+BEGIN_latex
\[
\begin{split}
g_C(X, Y) &= \ip{X^u \varphi_u + X^v \varphi_v}{X^u \varphi_u + X^v \varphi_v} \\
&= X^u Y^u \ip{\varphi_u}{\varphi_u} + 2 X^u Y^v \ip{\varphi_u}{\varphi_v} + X^v Y^v \ip{\varphi_v}{\varphi_v} \\
&= X^u Y^u g_{uu} + 2 X^u Y^v g_{uv} + X^v Y^v g_{vv}.
\end{split}
\]
#+END_latex

**** Example: The Cylinder and Plane

For the cylinder, \(\varphi(u, v) = (\cos u, \sin u, v)\):
\begin{align*}
\varphi_u &= \partial_u \varphi = (-\sin u, \cos u, 0) \\
\varphi_v &= \partial_v \varphi = (0, 0, 1)
\end{align*}

\pause

\begin{align*}
g_{uu} &= \ip{\varphi_u}{\varphi_u} = \ip{(-\sin u, \cos u, 0)}{(-\sin u, \cos u, 0)} \\
&= \sin^2 u + \cos^2 u = 1.
\end{align*}
\pause
\[
g_{uv} = \ip{\varphi_u}{\varphi_v} = \ip{(-\sin u, \cos u, 0)}{(0, 0, 1)} = 0.
\]
\pause
\[
g_{vv} = \ip{\varphi_u}{\varphi_u} = \ip{(0, 0, 1)}{(0, 0, 1)} = 1.
\]

\pause

\[
g_C(X, Y) = X^u Y^u + X^v Y^v = g_P(X, Y).
\]

**** Example: The Cylinder and Sphere
Parametrise the sphere
\[
\varphi(u, v) = (\cos u \sin v, \sin u \sin v, \cos v).
\]
\pause

\begin{align*}
\varphi_u &= \partial_u \varphi = (-\sin u \sin v, \cos u \sin v, 0) \\
\varphi_v &= \partial_v \varphi = (\cos u \cos v, \sin u \cos v, -\sin v)
\end{align*}
\pause

\[
g_{uu} = \sin^2 v, \quad g_{uv} = 0, \quad g_{vv} = 1
\]

\pause

- Thus the map \(\varphi : P \to \sphere^2\) is /not/ an isometry. \pause

- *But*: there could be some other map that is an isometry. \pause

- Later we will see that this is not true. That is there is no local isometry between the plane and the sphere.

**** Local Coordinate Isometries

#+BEGIN_theorem
Let \((S_1, g_1)\), \((S_2, g_2)\) be regular surfaces (or Riemannian manifolds). Then \(S_1\) and \(S_2\) locally isometric if and only if there exists local parametrisations \(\varphi_i : U \to S_i\) on a common domain \(U \subset \RR^2\) such that
\[
g_1 = g_2
\]
over the common parametrisation.
#+END_theorem

\pause

The ideas is that the map
\[
f = \varphi_2 \circ \varphi_1^{-1} : \varphi_1(U) \subseteq S_1 \to S_2
\]
is a local isometry.

**** Local Coordinate Isometries

#+BEGIN_proof
Suppose that there exist such local parametrisations whose metrics agree over a common parametrisation. That is, we have \((g_1)_{uu} = (g_2)_{uu}\), hence
\[
(g_1)_{uu} = \ip{\partial_u \varphi_1}{\partial_u \varphi_1},
\]
and
\[
(g_2)_{uu} = \ip{\partial_u \varphi_2}{\partial_u \varphi_2}
\]
\pause

Then
#+BEGIN_latex
\[
\begin{split}
g_2(df(\partial_u \varphi_1), df(\partial_u \varphi_1)) &= g_2(d(\varphi_2 \circ \varphi_1^{-1}) \partial_u \varphi_1, d(\varphi_2 \circ \varphi_1^{-1}) \partial_u \varphi_1) \\
&= g_2(\partial_u \varphi_2, \partial_u \varphi_2) = (g_2)_{uu} \\
&= (g_1)_{uu} = g_1(\partial_u \varphi, \partial_u \varphi).
\end{split}
\]
#+END_latex
Likewise \((g_2)_{uv} = (g_1)_{uv}\), \((g_2)_{vv} = (g_1)_{vv}\) and we have a local isometry.
#+END_proof

**** Local Coordinate Isometries
#+BEGIN_proof
Conversely, suppose that there is a local isometry
\[
f : W \subseteq S_1 \to S_2.
\]

\pause

- Take a local parametrisations \(\varphi_1 : U \to V \subseteq W\). \pause
- Define the local parametristation, \(\varphi_2 = f \circ \varphi_1\). \pause
- Since \(f\) is a diffeomorphism, \(d\varphi_2 = df \cdot d\varphi_1\) is injective and hence \(\varphi_2\) is a local parametrisation of \(S_2\). \pause
- Then
  #+BEGIN_latex
  \[
  \begin{split}
  (g_2)_{uu} &= g_2(\partial_u \varphi_2, \partial_u \varphi_2) = g_2(df \cdot \partial_u \varphi_1, df \cdot \partial_u \varphi_1) \\
  &\underset{f \text{ isometry}}{=} g_1(\partial_u \varphi_1, \partial_u \varphi_1) \\
  &= (g_1)_{uu}.
  \end{split}
  \]
  #+END_latex
  \pause
  Similarly for \((g_2)_{uv}\) and \((g_2)_{vv}\).
#+END_proof
**** Isometries Preserve Geometry
Let \(f : (S_1, g_1) \to (S_2, g_2)\) be an isometry. \pause
- Let \(X, Y\) be tangent vectors:
  \begin{align*}
  \abs{df(X)}_{g_2} &= g_2(df(X), df(X)) = g_1(X, X) = \abs{X}_{g_1} \\
  \theta(df(X), df(Y)) &= \frac{1}{\abs{df(X)}_{g_2} \abs{df(Y)}_{g_2}} g_2(df(X), df(Y)) \\
  &= \frac{1}{\abs{X}_{g_1} \abs{Y}_{g_1}} g_1(X, Y) = \theta(X, Y).
  \end{align*}
  \pause
- For a curve \(\gamma : [a, b] \to S_1\) we have
  \[
  L[f \circ \gamma] = \int_a^b \abs{(f \circ \gamma)'}_{g_2} dt = \int_a^b \abs{df (\gamma')}_{g_2} dt = \int_a^b \abs{\gamma'}_{g_1} dt = L[\gamma].
  \]
  \pause
- For a region \(R = \varphi_1 (U) \subset S_1\):
  \[
  \text{Area}_{g_2} (f(R)) = \int_{U} \sqrt{\det g_2} du dv = \int_U \sqrt{\det g_1} du dv = \text{Area}_{g_1} (R).
  \]
**** Notes							   :noexport:
- Ref: 2.4, 4.2
- Definition of isometry
- Examples
  - cylinder, plane, sphere, \mobius{}
  - polar coordinates
  - cylinder to sphere map is not an isometry - how to prove cylinder and sphere are not isometric though? Theorema Egregium!
- Length, angle, area preserved
- Prop 1
  - metrics agree in common param = locally isometric
** MATH3405 Differential Geometry: Week 11
*** Lecture 11.1: Vector Fields and Covariant Derivatives
**** Vector Fields

#+BEGIN_definition
A /vector field/ on a regular surface is a smooth function \(X : S \to \RR^3\) such that \(X(x) \in T_x S\) for each \(x \in S\).
#+END_definition

\pause

- For a manifold \(M\), we take \(X(x) \in T_x M\) for each \(x\) and smoothness can be defined as follows: \pause

  In local coordinates (i.e. in a chart \(U\)), we may uniquely write:
  \[
  X(x) = X^u(x) e_u(x) + X^v(x) e_v(x)
  \]
  where \(e_u, e_v\) are the coordinate vector fields. \pause

  Then \(X\) is smooth if the functions \(X^u, X^v : U \to \RR\) are smooth.

**** Some Examples

#+BEGIN_latex
\begin{example}[On the cylinder]
\[
X(x, y, z) = (-y, x, 0), \quad X(z, \theta) = (-\sin \theta, \cos \theta, 0)
\]
\end{example}
#+END_latex

\pause

#+BEGIN_latex
\begin{example}[On the sphere]
\[
X(x, y, z) = (1, 0, 0) - \ip{(1, 0, 0)}{(x, y, z)} (x, y, z) = (1-x^2, -xy, -xz)
\]
\end{example}
#+END_latex

\pause

#+BEGIN_latex
\begin{example}[On a graph, \(S = \{(u, v, f(u, v))\}\)]
\[
X(u, v) = (1, 0, f_u(u, v)), \quad X(u, v) = (0, 1, f_v(u, v))
\]
\end{example}
#+END_latex

**** Directional Derivative

- Let \(X, Y : \RR^3 \to \RR^3\) be vector fields, which we may write uniquely as
  \[
  X(u) = X^x(u) e_x + X^y(u) e_y + X^z(u) e_z, \quad u = (x, y, z) \in \RR^3.
  \]
  and similarly for \(Y\).

\pause

#+BEGIN_definition
The directional derivative, \(D_X Y\) is the vector field,
#+BEGIN_latex
\[
\begin{split}
(D_X Y) (u) = &\Big[X^x(u) \partial_x Y^x(u) + X^y(u) \partial_y Y^x(u) + X^z(u) \partial_z Y^x(u)\Big] e_x \\
+ &\Big[X^x(u) \partial_x Y^y(u) + X^y(u) \partial_y Y^y(u) + X^z(u) \partial_z Y^y(u)\Big] e_y \\
+ &\Big[X^x(u) \partial_x Y^z(u) + X^y(u) \partial_y Y^z(u) + X^z(u) \partial_z Y^z(u)\Big] e_z
\end{split}
\]
#+END_latex
#+END_definition

\pause

- That is, we just differentiate the components: \(D_X Y = (D_X Y^x) e_x + (D_X Y^y) e_y + (D_X Y^z) e_z\).

**** Directional Derivative on \(\RR^2\)

- Perhaps a more familiar way to write \(D_X Y\) is as follows: \pause
- On \(\RR^2\), write \(X = (a, b)\), \(Y = (u, v)\). Then
  \[
  D_X Y = \left(a \frac{\partial u}{\partial x} + b \frac{\partial u}{\partial y}, a \frac{\partial v}{\partial x} + b \frac{\partial v}{\partial y}\right).
  \]
  \pause
- In terms of the basis \(e_x = (1, 0)\), \(e_y = (0, 1)\), this is the same as above, just with less components (4 as opposed to 9):
  \[
    D_X Y = \left(a \partial_x u + b \partial_y u\right) e_x + \left(a \partial_x v + b \partial_y v\right) e_y.
  \]

**** Directional Derivative

- We may also interpret the directional derivative as
  \[
  D_X Y = \partial_t|_{t=0} Y(\gamma(t))
  \]
  where \(\gamma'(0) = X\). \pause
- Partial Derivatives
  \[
  \partial_x f (u) = \partial_t|_{t=0} f(u + t e_x) = D_{e_x} f,
  \]
  \pause
  and
  \[
  \partial_x Y = D_{e_x} Y = \partial_x Y^x e_x + \partial_x Y^y e_y + \partial_x Y^x e_z.
  \]
  \pause

- We may think of directional derivatives as an operator on smooth functions and vector fields:
  \[
  D_X : f \mapsto D_X f, \quad D_X : Y \mapsto D_X Y
  \]

**** Notation for Vector Fields

- Since \(\partial_x f = D_{e_x} f\), we write
  \[
  e_x = \partial_x, e_y = \partial_y, e_z = \partial_z.
  \]
  and
  \[
  X = X^x \partial_x + X^y \partial_y + X^z \partial_z
  \]
  \pause
  Then
  \[
  D_X Y = \sum_{i,j=1}^3 X^i (\partial_i Y^j) \partial_j
  \]
  where \(x_1 = x, x_2 = y, x_3 = z\) and \(\partial_i = \partial_{x_i}\).
  \pause
- Einstein Summation Notation (because writing \(\sum\) is too much effort!):
  \[
  D_X Y = X^i \partial_i Y^j \partial_j
  \]
  and anytime there is an upper index repeated as a lower index, there is an implies sum:\pause For example
  \[
  X^i \partial_i = \sum_{i=1}^3 X^i \partial_i = X^1 \partial_1 + X^2 \partial_2 + X^3 \partial_3.
  \]

**** First Attempt at Directional Derivative on a Regular Surface

#+BEGIN_latex
\begin{definition}[First Attempt]
Let \(S\) be a regular surface, with \(X, Y : S \to \RR^3\) tangent vector fields. Define
\[
\nabla_X Y = D_X Y.
\]
\end{definition}
#+END_latex

\pause

#+BEGIN_latex
\begin{example}[On the Sphere]
Let \(X = (1 - x^2, -xy, -xz)\). \pause Then
\[
\begin{split}
D_X X &= \Big[(1-x^2) \partial_x - xy \partial_y -xz \partial_z\Big] \Big[(1-x^2) \partial_x - xy \partial_y -xz \partial_z\Big] \\
&= \Big[(1-x^2)(-2x)\Big]\partial_x + \Big[(1-x^2) (-y) - xy(-x)\Big]\partial_y \\
&\quad  + \Big[(1-x^2)(-z) - xz(-x)\Big] \partial_z \\
&= (2x^3 - 2x) \partial_x + (2x^2y - y) \partial_y + (2x^2z - z) \partial_z.
\end{split}
\]
\end{example}
#+END_latex

**** First Attempt at Directional Derivative on a Regular Surface

#+BEGIN_latex
\begin{example}[On the Sphere (continued)]
\begin{itemize}
\item We have \(D_X X = (2x^3 - 2x) \partial_x + (2x^2y - y) \partial_y + (2x^2z - z) \partial_z.\) \pause
\item Recall \(N(u) = (x, y, z) = x\partial_x + y \partial_y + z\partial_z\) \pause
\item But
\[
\begin{split}
\ip{D_X X}{N} &= \Big\langle(2x^3 - 2x) \partial_x + (2x^2y - y) \partial_y + (2x^2z - z) \partial_z, \\
&\quad x \partial_x + y \partial_y + z \partial_z\Big\rangle \\
&= x(2x^3 - 2x) + y(2x^2y - y) + z(2x^2 z - z) \\
&= 2x^2(x^2 + y^2 + z^2) - x^2 - (x^2 + y^2 + z^2) \\
&= x^2 - 1.
\end{split}
\]
\pause
\item Therefore \(\ip{D_X X (u)}{N(u)} = x^2 - 1 \not\equiv 0\) and hence \(D_X X\) is not tangent in general.
\end{itemize}
\end{example}
#+END_latex

**** Covariant Derivative

#+BEGIN_definition
The covariant derivative \(\nabla_X Y\) is defined by
\[
\nabla_X Y = D_X Y - \ip{D_X Y}{N}N
\]
#+END_definition
\pause

That is,
\[
\nabla_X Y = \pi_{TS} (D_X Y)
\]
is the projection of \(D_X Y\) onto the tangent space! \pause

Explicitly, we can see \(\nabla_X Y\) is tangential:
\[
\ip{\nabla_X Y}{N} = \ip{D_X Y - \ip{D_X Y}{N}N}{N} = \ip{D_X Y}{N} - \ip{D_X Y}{N} \ip{N}{N} = 0
\]
since the normal is unit length: \(\ip{N}{N} = 1\).

**** Covariant Derivative on the Sphere

On the sphere, we simply have
\[
\nabla_X Y (u) = D_X Y (u) - \ip{D_X Y(u)}{u} u.
\]
\pause

#+BEGIN_latex
\begin{example}[On the Sphere (revisited)]
For \(X = (1 - x^2, -xy, -xz)\) we have
\[
D_X X = (2x^3 - 2x) \partial_x + (2x^2y - y) \partial_y + (2x^2z - z) \partial_z.
\]
and
\[
\ip{D_X X}{N} = x^2 - 1.
\]
\end{example}
#+END_latex

**** Covariant Derivative on the Sphere

#+BEGIN_latex
\begin{example}[On the Sphere (revisited)]

Thus
\[
\begin{split}
\nabla_X X &= (2x^3 - 2x) \partial_x + (2x^2y - y) \partial_y + (2x^2z - z) \partial_z \\
&\quad - (x^2 - 1)\big[x \partial_x + y \partial_y + z \partial_z\big] \\
&= \hphantom{+} \big[(2x^3 - 2x) - x(x^2 - 1)\big] \partial_x \\
&\hphantom{=} + \big[(2x^2y - y) - y(x^2 - 1) \big]\partial_y \\
&\hphantom{=} + \big[(2x^2z - z) - z(x^2-1)\big]\partial_z \\
&= (x^3 - x) \partial_x  + x^2y \partial_y  + x^2 z\partial_z \\
\end{split}
\]
\pause
Check:
\[
\begin{split}
\ip{\nabla_X Y}{N} &= \ip{(x^3 - x) \partial_x  + x^2y \partial_y  + x^2 z\partial_z}{x \partial_x + y \partial_y + z\partial_z} \\
&= x^4 - x^2 + x^2 y^2 + x^2z^2 \\
&= x^2(x^2 + y^2 + z^2 - 1) = 0.
\end{split}
\]
\end{example}
#+END_latex

**** Covariant Derivatives on Manifolds

#+BEGIN_definition
A /covariant derivative/ is a map
\[
(X, Y) \mapsto \nabla_X Y
\]
with \(\nabla_X Y\) a vector field, and such that for functions \(f, f^1, f^2 : M \to \RR\),
1. Linearity in \(X\): \(\nabla_{f^1 X_1 + f^2 X_2} Y = f^1 \nabla_{X^1} Y + f^2 \nabla-{X^2} Y\).
2. Additivity in \(Y\): \(\nabla_X (Y_1 + Y_2) = \nabla_X Y_1 + \nabla_X Y_2\).
2. Product (Leibniz) rule: \(\nabla_X (f Y) = df(X) Y + f \nabla_X Y\).
#+END_definition

\pause

- Check directly \(D\) is a covariant derivative on \(\RR^3\). \pause
- On a regular surface (Product Rule. You should check linearity in \(X\)!):
  #+BEGIN_latex
  \[
  \begin{split}
  \nabla_X (f Y) &= D_X (f Y) - \ip{D_X (f Y)}{N}N \\
  &= df(X) Y + f D_X Y - \ip{df(X)Y + f D_X Y}{N}N \\
  &= f(D_X Y - \ip{D_X Y}{N}N) + df(X) Y \\
  &= f \nabla_X Y + df(X) Y.
  \end{split}
  \]
  #+END_latex

**** Coordinate Vector Fields and Christoffel Symbols

In local coordinates \(\varphi : U \subseteq S\to V \subseteq \RR^2\),
\[
X = X^u \partial_u + X^v \partial_v, \quad Y = Y^u \partial_u + Y^v \partial_v.
\]
\pause
Let \(Z = \nabla_X Y\). We want to work out \(Z^u, Z^v\) in terms of \(X^u, X^v, Y^u, Y^v\). \pause
Linearity:
\[
\nabla_X Y = X^u \nabla_{\partial_u} \left(Y^u \partial_u\right) + X^u \nabla_{\partial_u}\left(Y^v \partial_v\right) + X^v \nabla_{\partial_v} \left(Y^u \partial_u\right) + X^v \nabla_{\partial_v} \left(Y^v \partial_v\right)
\]
\pause Product rule:
\[
\nabla_{\partial_u} \left(Y^u \partial_u\right) = (\nabla_u Y^u) \partial_u + Y^u \nabla_u \partial_u
\]
\pause Christoffel Symbols. Write \(\nabla_u \partial_u\) in terms of \(\partial_u, \partial_v\):
\[
\nabla_u \partial_u = \Gamma^u_{uu} \partial_u + \Gamma^v_{uu} \partial_v.
\]
\pause
\[
\nabla_X Y = X^i \nabla_{\partial_i} (Y^j \partial_j) = X^i (\partial_i Y^j) \partial_j + X^i Y^j \Gamma_{ij}^k \partial_k = \left(X^i \partial_i Y^j + X^i Y^k \Gamma_{ik}^j\right) \partial_j
\]
**** Example: Polar Coordinates

Choose local coordinates \((r, \theta)\) for the plane:
\[
\phi(r, \theta) = (r \cos \theta, r \sin \theta), \quad \phi^{-1} (x, y) = (\sqrt{x^2 + y^2}, \arctan(y/x)).
\]
\pause
\begin{align*}
\partial_r &= \cos\theta \partial_x + \sin\theta \partial_y & \partial_x &= \frac{x}{\sqrt{x^2 + y^2}} \partial_r - \frac{y}{x^2 + y^2} \partial_{\theta} \\
\partial_{\theta} &= -r\sin\theta \partial_x + r\cos\theta \partial_y & \partial_y &= \frac{y}{\sqrt{x^2 + y^2}} \partial_r + \frac{x}{x^2 + y^2} \partial_{\theta}
\end{align*}

\pause
#+BEGIN_latex
\[
\begin{split}
D_{\partial_r} \partial_r &= D_{\cos\theta \partial_x + \sin\theta \partial_y} \cos\theta \partial_x + \sin\theta \partial_y \\
&= \Big[(\cos\theta \partial_x + \sin\theta \partial_y) \cos\theta\Big] \partial_x + \Big[(\cos\theta \partial_x + \sin\theta \partial_y) \sin\theta\Big] \partial_y \\
&= \Big[\partial_r \cos \theta\Big]\partial_x + \Big[\partial_r \sin \theta\Big]\partial_y = 0.
\end{split}
\]
#+END_latex
\pause
Therefore
\[
\Gamma^r_{rr} = \Gamma^{\theta}_{rr} = 0.
\]

**** Example: Polar Coordinates

#+BEGIN_latex
\[
\begin{split}
D_{\partial_{\theta}} \partial_{\theta} &= D_{\partial_{\theta}} \Big[-r\sin\theta \partial_x + r\cos\theta \partial_y\Big] \\
&= -\Big[\partial_{\theta} r\sin\theta\Big] \partial_x + \Big[\partial_{\theta} r\cos\theta\Big] \partial_y \\
&= -r\cos\theta \partial_x - r \sin\theta \partial_y \\
&= -r \partial_r.
\end{split}
\]
#+END_latex
\pause
Therefore
\[
\Gamma^r_{\theta\theta} = -r \quad \Gamma^{\theta}_{\theta\theta} = 0.
\]
\pause

*Exercise*: Calculate
\begin{align*}
D_{\partial_r} \partial_{\theta} &= \Gamma^r_{r\theta} \partial_{r} + \Gamma^{\theta}_{r\theta} \partial_{\theta} \\
D_{\partial_{\theta}} \partial_{r} &= \Gamma^r_{\theta r} \partial_{r} + \Gamma^{\theta}_{\theta r} \partial_{\theta}
\end{align*}

**** Notes 							   :noexport:
- Ref: 3.4, 4.4
- We have the Euclidean derivative
- Show by example (even on the sphere or cylinder) that \(D_X Y\) need not be tangent
- Example with local coordinate vector fields
- Invariance under isometry
*** Lecture 11.2: Parallel Transport and Geodesics
**** Dependence of \(\nabla\) along curves

- Let \(\gamma(t) \in S\) be a smooth curve and \(Y\) a smooth vector field. \pause
- Then \(Y \circ \gamma (t)\) is a vector field /along \(\gamma\)/. \pause
- Define \(\frac{D^{\gamma}}{dt} Y = \nabla_{\gamma'(t)} Y(\gamma(t))\) \pause
- When \(\gamma\) is clear from context, we just write \(\frac{D}{dt}\). \pause
- Write
  \[
  Y(\gamma(t)) = Y^u(t) e_u(\gamma(t)) + Y^v(t) e_v(\gamma(t))
  \]
  \pause
- Then
  #+BEGIN_latex
  \[
  \begin{split}
  \frac{D}{dt} Y &= \left(\partial_t Y^u(\gamma(t))\right) e_u + \left(\partial_t Y^v(\gamma(t))\right) e_v \\
  &\quad + Y^u(\gamma(t)) \nabla_{\gamma'(t)} e_u + Y^v(\gamma(t)) \nabla_{\gamma'(t)} e_v
  \end{split}
  \]
  #+END_latex

**** Dependence of \(\nabla\) along curves

- We have
  \[
  \frac{D}{dt} Y = (Y^u \circ \gamma)' e_u + (Y^v \circ \gamma)' e_v + Y^u \nabla_{\gamma'} e_u + Y^v \nabla_{\gamma'} e_v.
  \]
  \pause
- In particular, writing \(\gamma' = \gamma^u e_u + \gamma^v e_v\): \pause
  #+BEGIN_latex
  \[
  \begin{split}
  \nabla_{\gamma'} e_u &= \gamma^u \nabla_{e_u} e_u + \gamma^v \nabla_{e_v} e_u \\
  &= \gamma^u \Gamma^u_{uu} e_u + \gamma^u \Gamma^v_{uu} e_v + \gamma^v \Gamma^u_{vu} e_u + \gamma^v \Gamma^v_{vu} e_v \\
  &= \left(\gamma^u \Gamma^u_{uu} + \gamma^v \Gamma^u_{vu}\right) e_u + \left(\gamma^u \Gamma^v_{uu} + \gamma^v \Gamma^v_{vu}\right) e_v.
  \end{split}
  \]
  #+END_latex
  \pause
  For \(i,j, k \in \{u,v\}\) we have:
  \[
  \gamma^i = \gamma^i(t), \quad \Gamma^i_{jk} = \Gamma^i_{jk} (\gamma(t)), \quad e_i = e_i(\gamma(t))
  \]
  and \(e_i, \Gamma^i_{jk}\) locally defined independently of \(\gamma\).

**** Dependence of \(\nabla\) along curves

- Then \(\frac{D}{dt} Y\) depends on
  \[
  Y^i(\gamma(t)), \quad (Y^i \circ \gamma)'(t), \quad \gamma^i(t), \quad \Gamma^{ij}_k (\gamma(t)), \quad e_i(\gamma(t)), \quad i = u,v.
  \]
  \pause
  That is, if two vector fields, \(Y, Z\) agree along \(\gamma\): \(Y\circ \gamma = Z \circ \gamma\), we have \(\frac{D}{dt} Y = \frac{D}{dt} Z\). \pause
- If two curves define the same tangent vector \(X = \gamma'(t_0) = \sigma'(t_0)\), then
  \[
  \left.\frac{D^{\gamma}}{dt}\right|_{t=t_0} Y = \left.\frac{D^{\sigma}}{dt}\right|_{t=t_0} Y
  \]
  \pause
  Thus at a point \(t_0\), \(\tfrac{D}{dt} Y\) depends on \(Y\) for points along \(\gamma\) (but not in a whole neighbourhood) and only on \(\gamma'(t_0)\) at the point \(t_0\). \pause
- Therefore, covariant differentiation along a curve is well defined.

**** Parallel Transport

#+BEGIN_definition
A vector field \(Y\) is said to be /parallel/ along a curve \(\gamma\) if \(\frac{D^{\gamma}}{dt} Y = 0\).
#+END_definition
\pause

#+BEGIN_latex
\begin{example}[On the plane, \(\RR^2\)]
Let \(Y(x, y) = e_i\) be a coordinate vector field, \(i = 1, 2\). For any \(\gamma\),
\[
\frac{D}{dt} Y = D_{\gamma'} e_i = 0.
\]
\pause

Let \(\gamma(t) = (t, t^2)\) and \(Y(x, y) = x e_1 + y e_2\). Then
\[
Y(\gamma(t)) = t e_1 + t^2 e_2
\]
\pause
and hence
\[
\frac{D^{\gamma}}{dt} Y = (\partial_t t)e_1 + (\partial_t t^2) e_2 = e_1 + 2t e_2 \ne 0.
\]
\end{example}
#+END_latex

**** Parallel Transport

#+BEGIN_latex
\begin{example}[On the sphere, \(\sphere^2\)]
Polar coordinates: \((\cos\theta \sin\varphi, \sin\theta\sin\varphi, \cos\varphi)\). \pause

Let
\[
\begin{split}
Y &= \sin\varphi \partial_{\theta} = -\sin\theta \sin^2\varphi \partial_x + \cos\theta\sin^2\varphi \partial_y \\
&= -\sqrt{1 - z^2} y \partial_x + \sqrt{1-z^2} x \partial_x
\end{split}
\]
\pause

Let \(\gamma(t) = (\cos(t), \sin(t), 0)\) parametrise the equator. Then
\[
Y(\gamma(t)) = -\sin(t) \partial_x + \cos(t) \partial_y.
\]
\pause
Therefore,
\[
\nabla_{\gamma'} Y = \pi_{T\sphere^2} (D_{\gamma'} Y) = -\pi_{T\sphere^2} (\cos(t) \partial_x + \sin t \partial_y) = \pi_{T\sphere^2} (N_{\sphere^2} (\gamma(t))) = 0.
\]
\end{example}
#+END_latex

**** Parallel Transport

#+BEGIN_latex
\begin{example}[On the sphere, \(\sphere^2\)]
Let \(\gamma(t) = (\sqrt{1-z_0^2} \cos(t), \sqrt{1-z_0^2}\sin(t), z_0)\) parametrise the a circle of latitude at height \(z_0\). Then
\[
Y(\gamma(t)) = -(1-z_0^2) \sin(t) \partial_x + (1-z_0^2) \cos(t) \partial_y.
\]
\pause
Therefore,
\[
\begin{split}
\nabla_{\gamma'} Y &= \pi_{T\sphere^2} (D_{\gamma'} Y) = -(1-z_0^2) \pi_{T\sphere^2} (\cos(t) \partial_x + \sin t \partial_y).
\end{split}
\]
\end{example}
#+END_latex

**** Parallel Transport

#+BEGIN_latex
\begin{example}[On the sphere, \(\sphere^2\)]
We obtained \(\nabla_{\gamma'} Y = -(1-z_0^2) \pi_{T\sphere^2} (\cos(t) \partial_x + \sin t \partial_y)\).
\pause

Take the normal \(N(\gamma(t)) = \sqrt{1-z_0^2} \cos(t)\partial_x + \sqrt{1-z_0^2}\sin(t) \partial_y + z_0\partial_z\).
\pause

The projection onto the normal is
\[
\begin{split}
& \ip{\cos(t) \partial_x + \sin t \partial_y}{\sqrt{1-z_0^2} \cos(t)\partial_x + \sqrt{1-z_0^2}\sin(t) \partial_y +  z_0\partial_z} \\
&\quad = \sqrt{1-z_0^2}
\end{split}
\]
\pause
\[
\begin{split}
\nabla_{\gamma'} Y &= -(1-z_0^2) (\cos(t) \partial_x + \sin t \partial_y) \\
&\quad + (1-z_0^2)\sqrt{1-z_0^2}\left(\sqrt{1-z_0^2} \cos(t)\partial_x + \sqrt{1-z_0^2}\sin(t) \partial_y +  z_0\partial_z\right) \\
&= ((1-z_0^2)^2 - (1-z_0^2))\left(\cos(t) \partial_x + \sin(t) \partial_y\right) + z_0(1-z_0^2)^{3/2} \partial_z.
\end{split}
\]
\end{example}
#+END_latex

**** Geodesics

#+BEGIN_definition
A curve \(\gamma\) is a /geodesic/ if \(\nabla_{\gamma'} \gamma' = 0\).
#+END_definition

\pause

- Geodesics are curves with zero /acceleration/. \pause
- On Euclidean space
  \[
  \text{Acceleration} = \gamma'' = D_{\gamma'} \gamma'.
  \]
  \pause
  A curve \(\gamma(t) = (x(t), y(t))\) is thus a geodesic if and only if
  \[
  (x'', y'') = 0 \Leftrightarrow \gamma = (x, y) = (at + b, ct + d) = t(a, c) + (b,d).
  \]
  That is, if and only if \(\gamma\) is a straight line.

**** Existence and Uniqueness of Parallel Transport

#+BEGIN_theorem
Let \(\gamma\) be a curve through \(x \in S\) so \(\gamma(0) = x\). Given \(Y_0 \in T_x S\), there exists a unique parallel vector field \(Y\) along \(\gamma\) such that \(Y(0) = Y_0\).
#+END_theorem

\pause

#+BEGIN_proof
This is an existence/uniqueness result for the ODE
#+BEGIN_latex
\[
\begin{cases}
\nabla_{\gamma'} Y &= 0 \\
Y(0) &= Y_0.
\end{cases}
\]
#+END_latex
\pause
Locally, this is the system of linear ODE's for \(Y^u, Y^v\):
\[
\partial_t Y^i(t) = - \Gamma^i_{jk} (\gamma^j)' Y^k(t).
\]
#+END_proof

**** Existence and Uniqueness of Geodesics

#+BEGIN_theorem
Given any \(x \in S\) and \(Y_0 \in T_x S\), there exists a unique geodesic \(\gamma\) through \(x\) such that \(\gamma'(0) = Y_0\).
#+END_theorem

\pause

#+BEGIN_proof
This time it's a second order ODE for \(\gamma\):
#+BEGIN_latex
\[
\begin{cases}
\nabla_{\gamma'} \gamma' &= 0 \\
\gamma(0) &= x \\
\gamma'(0) &= Y_0.
\end{cases}
\]
#+END_latex
\pause

Locally we see it's non-linear (but solutions still exist and are unique):
\[
(\gamma^i)'' + \Gamma^i_{jk} (\gamma^j)' (\gamma^k)' = 0
\]
#+END_proof

*** Lecture 11.3: Covariant Derivatives as Differential Operators
**** Vector fields as derivations

#+BEGIN_definition
A vector field \(X\) acts as a /derivation/ on smooth functions \(f\):
\[
X(f) (x) = df_x (X(x)).
\]
#+END_definition
\pause
- That, is \(X(f)\) is the smooth function \(x \mapsto df_x (X(x))\). \pause
- Product rule:
  \[
  X(fg) = fX(g) + gX(f).
  \]
  \pause

#+BEGIN_latex
\begin{example}
\[
e_u (f) = \partial_u f, \text{ local partial derivative}.
\]
\pause
\end{example}
#+END_latex

**** Vector fields as derivations

#+BEGIN_latex
\begin{example}
\(X = x \partial_x + y \partial_y = r \partial_r\) \pause
\[
X(f) = x \partial_x f + y \partial_y f.
\]
\pause
\[
X(f) = \partial_r \left[f(r \cos\theta, r\sin\theta)\right] = r \cos \theta \partial_x f + r \sin\theta \partial_y f.
\]
\end{example}
#+END_latex

**** Commutator (The Lie Bracket)

#+BEGIN_definition
The /Lie Bracket/ or /Commutator/ of two vector fields is the derivation,
\[
[X, Y] (f) = X(Y(f)) - Y(X(f)).
\]
#+END_definition

\pause

- This is at first sight a second order operator - i.e. involving two derivatives of \(f\). \pause
- But the second derivative terms all cancel (summation convention!):
  #+BEGIN_latex
  \[
  \begin{split}
  [X, Y] f &= [X^i \partial_i, Y^j \partial_j] f = X^i \partial_i (Y^j \partial_j f) - Y^j \partial_j (X^i \partial_i f) \\
  &= X^i \partial_i Y^j \partial_j f + X^i Y^j \partial_i \partial_j f - Y^j \partial_j X^i \partial_i f - Y^j X^i \partial_j \partial_i f \\
  &= X^i \partial_i Y^j \partial_j f - Y^j \partial_j X^i \partial_i f
  \end{split}
  \]
  #+END_latex

**** Commutator (The Lie Bracket)

- Relabel the indices (swap \(i\) and \(j\) in the second sum)
  \[
  [X, Y] f = X^i \partial_i Y^j \partial_j f - Y^i \partial_i X^j \partial_j f = (X^i \partial_i Y^j - Y^i \partial_i X^j) \partial_j f.
  \]
  \pause
  Thus \([X, Y]\) is the vector field with local components,
  \[
  Z^j = (X^i \partial_i Y^j - Y^i \partial_i X^j).
  \]
  \pause

#+BEGIN_latex
\begin{example}
Let \(X = e_i, Y = e_j\) so that
\[
[e_i, e_j] f = \partial_i \partial_j f - \partial_j \partial_i f = 0.
\]
\pause

Let \(X = y \partial_x, Y = \partial_y\) so that
\[
[X, Y] f = y\partial_x \partial_y f - \partial_y (y \partial_x f) = -\partial_x f = -e_x (f).
\]
\end{example}
#+END_latex
**** Covariant Derivative Again

- Recall that
  \[
  \nabla_X f = df(X).
  \]
  \pause
  That is, rather than computing \(\nabla_X f\) anew for each vector field \(X\), we can compute \(df\) first, then simply apply it to \(X\) for each vector field \(X\). \pause
- In local coordinates,
  \[
  df = \begin{pmatrix} f_u & f_v \end{pmatrix}.
  \]
  \pause
- We can do something similar for covariant derivatives: Given \(Y\), define
  \[
  (\nabla X) (Y) = \nabla_Y X
  \]
  \pause
- \(\nabla X\) is a linear map, taking a vector field \(Y\) as input, and outputting the new vector field \(\nabla_Y X\).

**** Covariant Derivative Again

#+BEGIN_latex
\begin{example}
\begin{itemize}
\item Consider the "height" function \(h : \sphere^2 \to \RR\).  \(h(x, y, z) = z\). \pause
\item In polar coordinates: \(h(\theta, \varphi) = \cos\varphi\) and
\[
dh = -\sin\varphi d\varphi
\]
where
\[
d\varphi(\partial_{\theta}) = 0, \quad d\varphi(\partial_{\varphi}) = 1.
\]
\pause
\item Consider how the height varies along the path \(\gamma(t) = (\tfrac{1}{\sqrt{2}}\sin(t), \tfrac{1}{\sqrt{2}}\sin(t), \cos(t)\) in polar coordinates:
\[
\gamma(t) = (\theta = \pi/4, \varphi = t), \gamma'(t) = \partial_{\varphi}.
\]
\pause
Then
\[
dh (\gamma'(t)) = -\sin\varphi d\varphi(\partial_{\varphi}) = -\sin(t).
\]
\end{itemize}
\end{example}
#+END_latex

**** Covariant Derivative Again

#+BEGIN_latex
\begin{example}
On the other hand,
\[
h (\gamma(t)) = \cos(t)
\]
satisfies
\[
(h \circ \gamma)'(t) = -\sin(t).
\]
\end{example}
#+END_latex

**** Covariant Derivative Again

In the example,
- \(\nabla_Y X\) is analogous to \((h\circ \gamma)'(t)\), while
- \(\nabla X (Y)\) is analogous to \(dh(\gamma'(t))\). \pause

Suppose \(X\) is the vector field (e.g. representing the wind) on the sphere,
\[
X(\theta, \varphi) = \varphi \partial_{\theta}.
\]
Then
#+BEGIN_latex
\[
\begin{split}
(\nabla X) (\partial_{\theta}) &= \nabla_{\partial_{\theta}} (\varphi_{\partial_{\theta}}) = \varphi \Gamma^{\theta}_{\theta\theta} \partial_{\theta} + \varphi \Gamma^{\varphi}_{\theta\theta} \partial_{\varphi} \\
&= -\varphi \sin \varphi \cos \varphi \partial_{\varphi}
\end{split}
\]
#+END_latex
and
#+BEGIN_latex
\[
\begin{split}
(\nabla X) (\partial_{\varphi}) &= \nabla_{\partial_{\varphi}} (\varphi_{\partial_{\theta}}) = \partial_{\theta} + \varphi \Gamma^{\theta}_{\varphi\theta} \partial_{\theta} + \varphi \Gamma^{\varphi}_{\varphi\theta} \partial_{\varphi} \\
&= (1 + \varphi\cot\varphi) \partial_{\theta}
\end{split}
\]
#+END_latex

**** Covariant Derivative Again
Therefore the vector field
\[
X(\theta, \varphi) = \varphi \partial_{\theta}.
\]
has covariant derivative \(\nabla X\) given by the linear map
#+BEGIN_latex
\[
\nabla X = \begin{pmatrix}
0 & (1 + \varphi\cot\varphi) \\
-\varphi \sin \varphi \cos \varphi & 0
\end{pmatrix}
\]
#+END_latex
in the basis \(\{\partial_{\theta}, \partial_{\varphi}\}\). \pause

Along the path \(\gamma(t) = (\theta = \pi/4, \varphi = t)\), the vector field \(X\) varies as
\[
\nabla X (\gamma') = \nabla X (\partial_{\varphi}) = (1 + \varphi \cot \varphi) \partial_{\theta}.
\]
**** Differentiating Linear Maps

- Consider a linear map \(T : TS \to TS\). For example
  \[
  \mathcal{W} = -dN, \quad \text{or} \quad \nabla X.
  \]
  \pause
- For a vector field \(X\), \(T(X)\) is a vector field. \pause
- We can differentiate the vector field \(T(X)\) to get \(\nabla (T(X))\). \pause
- Thus for another vector field \(Y\), we have
  \[
  [\nabla (T(X))] (Y) = \nabla_Y (T(X)).
  \]
  \pause
- We want to isolate the change in \(T\) but \(X\) may also be changing and we don't want to include the change of \(X\). \pause
- Thus we define a new linear map, \(\nabla_Y T\):
  \[
  (\nabla_Y T) (X) = \nabla_Y(T(X)) - T(\nabla_Y X).
  \]

**** Differentiating Linear Maps

#+BEGIN_eg
On \(\RR^2\), let
\[
M(x) = \begin{pmatrix}
xy && \cos(x) \\
0 && x^2 - y
\end{pmatrix}
\]
\pause

Then
\[
D_{\partial_x} M = \begin{pmatrix}
y && -\sin(x) \\
0 && 2x
\end{pmatrix}
\]
\pause

Observe that
#+BEGIN_latex
\[
D_{\partial_x}\left[M(x) (\partial_x) \right] = \partial_x \left[\begin{pmatrix}
xy && \cos(x) \\
0 && x^2 - y
\end{pmatrix}
\begin{pmatrix}
1 \\
0
\end{pmatrix}
\right]
= \partial_x \begin{pmatrix}
xy \\
0
\end{pmatrix}
= \begin{pmatrix}
y \\
0
\end{pmatrix}
\]
#+END_latex
\pause
\[
D_{\partial_x}[M(x) (\partial_x)] = [D_{\partial_x} M(x)] (\partial_x) + M(x) (D_{\partial_x} \partial_x) = [D_{\partial_x} M(x)] (\partial_x).
\]
#+END_eg

**** Differentiating Linear Maps

#+BEGIN_eg
Take the same \(M\) and let \(X(x, y) = x \partial_x\). \pause

\[
D_{\partial_x} X = \partial_x.
\]
\pause
#+BEGIN_latex
\[
D_{\partial_x}\left[M(x) (X) \right] = \partial_x \left[\begin{pmatrix}
xy && \cos(x) \\
0 && x^2 - y
\end{pmatrix}
\begin{pmatrix}
x \\
0
\end{pmatrix}
\right]
= \partial_x \begin{pmatrix}
x^2y \\
0
\end{pmatrix}
= \begin{pmatrix}
2xy \\
0
\end{pmatrix}
\]
#+END_latex
\pause

\[
D_{\partial_x} M = \begin{pmatrix}
y && -\sin(x) \\
0 && 2x
\end{pmatrix}
\]
\pause
\[
\left[D_{\partial_x}M(x)\right] (X) = xy\partial_x
\]
\pause
\[
M(x) (D_{\partial_x} X) = xy \partial_x
\]
\pause
\[
D_{\partial_x}[M(x) (\partial_x)] = [D_{\partial_x} M(x)] (\partial_x) + M(x) (D_{\partial_x} \partial_x).
\]

#+END_eg

**** Notes 							   :noexport:
- Vector fields as derivations
  - simple example on \(\RR^n\)
- Lie bracket: \([X, Y] = \nabla_X Y - \nabla_Y X\)
  - Show actually \([X, Y] = D_X Y - D_Y X\) from symmetry of \(A\)
  - examples (particularly on \(\RR^3\)) of vector fields that don't commute: e.g. \(X = \partial_x\), \(Y = x \partial_y)
  - coordinate fields commute
- Higher derivatives - particularly endomorphisms such as \(dN\) and for fixed \(X\), \(Y \mapsto \nabla_Y X\)
  - examples of where we have to take into account the change in the argument: \(D_X (T(Y)) = (D_X T)(Y) + T(D_X Y)\). Show by example, that we with different \(Y\)'s we get different \(D_X (T(Y))\), so to compute \(D_X T\) we need to subtract off the component \(D_X Y\) corresponding to the change in \(Y\)
- Curvature Tensor
- Ricci identity
** MATH3405 Differential Geometry: Week 12
*** Lecture 12.1: Curvature Tensor
**** Notes							   :noexport:
- Ref: 3.3, 4.3
- Invariance of curvature under isometry
- Gauss equation
- Proof by Curvature tensor and Gauss Equation
  - https://faculty.etsu.edu/gardnerr/5310/5310pdf/dg1-8.pdf sectional curvature of a two plane is exactly the Gauss curvature!
- Alternative proof of Gauss Theorem: Use characterisation as limits of areas of shrinking regions
  -  http://wwwf.imperial.ac.uk/~skdona/lecturenotes/GAUSS.PDF
- https://services.math.duke.edu/~ng/math/papers/curvature.pdf
- Interpretation of Gauss Curvature via infinitessimal area, triangles, Gauss map?
- Try to prove it in a way that matches with the Gauss-Bonnet theorem
**** Commuting Covariant Derivatives
#+BEGIN_lemma
\[
\nabla_X Y - \nabla_Y X = [X, Y].
\]
#+END_lemma

#+BEGIN_proof
\[
\nabla_X Y - \nabla_Y X = D_X Y - A(X, Y) - (D_Y X - A(Y, X)) = D_X Y - D_Y X
\]
by symmetry of \(A\). \pause So we only need to verify the lemma for \(D\).
#+BEGIN_latex
\[
\begin{split}
(D_X Y - D_Y X) f &= \left(D_{X^i \partial_i} Y^j \partial_j - D_{Y^k \partial_k} X^l \partial_l\right) f \\
&= X^i \partial_i(Y^j) \partial_j f + X^i Y^j \partial_i \partial_j f - Y^k \partial_k(X^l) \partial_l f + Y^k X^l \partial_k \partial_l f \\
&= \left(X^i \partial_i(Y^j) - Y^i \partial_i(X^j) \right)\partial_j f \\
&= [X, Y] f.
\end{split}
\]
#+END_latex
#+END_proof
**** Second Covariant Derivative

#+BEGIN_definition
Let \(X\) be a vector field. The second covariant derivative of \(X\) is defined to be the covariant derivative of \(T = \nabla X\)
\[
(\nabla_Y (\nabla X)) (Z) = \nabla_Y(\nabla X (Z)) - \nabla X (\nabla_Y Z) = \nabla_Y(\nabla_Z X) - \nabla_{\nabla_Y Z} X.
\]
#+END_definition

\pause

We also write
\[
\nabla^2 X (Y, Z) = (\nabla_Y (\nabla X)) (Z).
\]
\pause
or
\[
\nabla^2_{Y, Z} X = (\nabla_Y (\nabla X)) (Z).
\]
**** The Curvature Tensor

#+BEGIN_definition
The /curvature tensor/ is the commutator of second derivatives,
#+BEGIN_latex
\[
\begin{split}
\Rm(X, Y) Z &= \nabla^2 Z (X, Y) - \nabla^2 Z (Y, X) \\
&= \nabla_X (\nabla_Y Z) - \nabla_Y(\nabla_X Z) - \nabla_{\nabla_X Y - \nabla_Y X} Z.
\end{split}
\]
#+END_latex
#+END_definition
\pause

We can write \(\Rm\) as a commutator
\[
\Rm(X, Y) = \nabla^2_{X, Y} - \nabla^2_{Y, X}.
\]
\pause

- We may write\(\Rm(X, Y) Z = \nabla_Y (\nabla_X Z) - \nabla_X (\nabla_Y Z) - \nabla_{[X, Y]} Z\). \pause
- The \([X, Y]\) term compensates for the fact that \(\nabla^2_{X, Y}\) and \(\nabla^2_{Y, X}\) might not commute simply because \(X\) and \(Y\) might not commute. \pause

**** Metric Compatibility

#+BEGIN_theorem
The covariant derivative is /metric compatible/. That is, for all tangent vector fields \(X, Y, Z\)
\[
\nabla_X \left[g(Y, Z)\right] = g(\nabla_X Y, Z) + g(Y, \nabla_X Z).
\]
#+END_theorem

\pause

#+BEGIN_proof
First note that the Euclidean directional is metric compatible:

We write
\[
\ip{X}{Y} = \sum_i X^i Y^i = \delta_{ij} X^i Y^j, \quad \delta_{ij} = \begin{cases}
1, & i = j \\
0, & i \ne j
\end{cases}
\]

\pause

#+BEGIN_latex
\[
\begin{split}
D_X \ip{Y}{Z} &= D_X (\delta_{ij} Y^i Z^j) = \delta_{ij} (D_X Y^i) Z^j + \delta_{ij} Y^i (D_X Z^j) \\
&= \ip{D_X Y}{Z} + \ip{Y}{D_X Z}.
\end{split}
\]
#+END_latex
#+END_proof

**** Metric Compatibility

#+BEGIN_proof
Now the covariant derivative
#+BEGIN_latex
\[
\begin{split}
\nabla_X g(Y, Z) &= D_X \ip{Y}{Z} = \ip{D_X Y}{Z} + \ip{Y}{D_X Z} \\
&= \ip{D_X Y - \ip{D_X Y}{N}N}{Z} + \ip{Y}{D_X Z - \ip{D_X Z}{N}N} \\
&= \ip{\nabla_X Y}{Z} + \ip{Y}{\nabla_X Z} \\
&= g(\nabla_X Y, Z) + g(Y, \nabla_X Z).
\end{split}
\]
#+END_latex
#+END_proof

**** Levi-Civita Connection

#+BEGIN_theorem
[Fundamental Theorem of Riemannian Geometry]

On a Riemannian manifold, there exists a unique covariant derivative \(\nabla\) such that
1. \(\nabla\) is /metric compatible/,
2. \(\nabla\) is /symmetric/. That is \(\nabla_X Y - \nabla_Y X = [X, Y]\).
#+END_theorem

\pause

- This covariant derivative is called the Levi-Civita connection. \pause
- On a regular surface, we've just seen that the covariant derivative is metric compatible and we already knew it was symmetric. \pause
- The theorem says moreover, that if \(\bar{\nabla}\) is any other covariant derivative (satisfies linearity and the product rule) that is metric compatible and symmetric, then \(\bar{\nabla} = \nabla\).

**** Covariant Derivative and Curvature are Intrinsic

- We won't prove the theorem here (though it's not difficult). \pause
- The theorem says that we may write \(\nabla = \nabla(g)\). That is \(\nabla\) may be obtained in a *unique* way from \(g\). \pause
- Thus we obtain: \pause
#+BEGIN_corollary
If \((S_1, g_1)\) and \((S_2, g_2)\) are isometric, then \(\nabla_1 = \nabla_2\).
#+END_corollary

\pause

#+BEGIN_corollary
If \((S_1, g_1)\) and \((S_2, g_2)\) are isometric, then \(\Rm_1 = \Rm_2\).
#+END_corollary

**** Symmetries of the Curvature Tensor

#+BEGIN_theorem
For any vectors \(X, Y, Z, W\),
1. \(\Rm(X, Y) Z = - \Rm(Y, X) Z\),
2. \(g(\Rm(X, Y) Z, W) = - g(\Rm(X, Y) W, Z)\),
3. \(\Rm(X, Y) Z + \Rm(Y, Z) X + \Rm(Z, X) Y = 0\) (/Bianchi Identity/),
#+END_theorem

\pause

#+BEGIN_proof
1. Anti-symmetry in the first two slots:
   #+BEGIN_latex
   \[
   \begin{split}
   \Rm(X, Y) Z &= \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X, Y]} Z \\
   &= -\nabla_Y \nabla_Y Z + \nabla_Y \nabla_X Z - \nabla_{-[Y, X]} Z \\
   &= - \Rm(Y, X) Z.
   \end{split}
   \]
   #+END_latex
#+END_proof

**** Symmetries of the Curvature Tensor

#+BEGIN_proof
1. [@2] Anti-symmetry in the last two slots. This is a little more involved:
   We use metric compatability.
   \begin{align*}
   g(\nabla_X \nabla_Y Z, W) &= \nabla_X g(\nabla_Y Z, W) - g(\nabla_Y Z, \nabla_X W) \\
   &= \nabla_X \nabla_Y g(Z, W) - \nabla_X g(Z, \nabla_Y W) \\
   &\quad - \nabla_Y g(Z, \nabla_X W) + g(Z, \nabla_Y \nabla_X W).
   \end{align*}
   \pause
   Similarly,
   \begin{align*}
   g(\nabla_Y \nabla_X Z, W) &= \nabla_Y g(\nabla_X Z, W) - g(\nabla_X Z, \nabla_Y W) \\
   &= \nabla_Y \nabla_X g(Z, W) - \nabla_Y g(Z, \nabla_X W) \\
   &\quad -\nabla_X g(Z, \nabla_Y W) + g(Z, \nabla_X \nabla_Y W).
   \end{align*}

#+END_proof

**** Symmetries of the Curvature Tensor

#+BEGIN_proof

1. [@2]
   Thus,
   #+BEGIN_latex
   \[
   \begin{split}
   g(\nabla_X \nabla_Y Z - \nabla_Y \nabla_X, W) &= (\nabla_X \nabla_Y - \nabla_Y \nabla_X) g(Z, W) \\
   &\quad - g(Z, \nabla_X \nabla_Y W - \nabla_Y \nabla_X W)
   \end{split}
   \]
   #+END_latex
   \pause

   Subtracting,
   \[
   g(\nabla_{[X, Y]} Z, W) = \nabla_{[X, Y]} g(Z, W) - g(Z, \nabla_{[X, Y]} W)
   \]
   we obtain, \pause
   \begin{align*}
   g(\Rm(X, Y) Z, W) &= g(\nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X, Y]} Z, W) \\
   &= (\nabla_X \nabla_Y - \nabla_Y \nabla_X - \nabla_{[X, Y]}) g(Z, W) \\
   &\quad - g(Z, \nabla_X \nabla_Y W - \nabla_Y \nabla_X W - \nabla_{[X, Y]} W) \\
   &= \Rm(X, Y) [g(Z, W)] - g(\Rm(X, Y) W, Z).
   \end{align*}
#+END_proof

**** Symmetries of the Curvature Tensor

#+BEGIN_proof
1. [@2] So far we have
   \[
   g(\Rm(X, Y) Z, W) = R(X, Y) [g(Z, W)] - g(\Rm(X, Y) W, Z)
   \]
   where for the smooth function \(f = g(Z, W)\) we have
   #+BEGIN_latex
   \[
   \begin{split}
   \Rm(X, Y) f &= \nabla_X \nabla_Y f - \nabla_Y \nabla_X f - \nabla_{[X, Y]} f \\
   &= X(Y(f)) - Y(X(f)) - [X, Y] (f) \\
   &= [X,Y] (f) - [X, Y] (f) = 0.
   \end{split}
   \]
   #+END_latex
   \pause

   Thus we have
   \[
   g(\Rm(X, Y) Z, W) = - g(\Rm(X, Y) W, Z)
   \]
#+END_proof

**** Symmetries of the Curvature Tensor

#+BEGIN_proof
1. [@3]

   \begin{align*}
   \Rm(X, Y) Z &= \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X, Y]} Z \\
   \Rm(Y, Z) X &= \nabla_Y \nabla_Z X  - \nabla_Z \nabla_Y X - \nabla_{[Y, Z]} X \\
   \Rm(Z, X) Y &= \nabla_Z \nabla_X Y - \nabla_X \nabla_Z Y - \nabla_{[Z, X]} Y 
   \end{align*}

   \pause
   Then we use the symmetry \(\nabla_Y Z - \nabla_Z Y = [Y, Z]\):
   \[
   \nabla_X (\nabla_Y Z) = \nabla_X(\nabla_Z Y + [Y, Z]) = \nabla_X \nabla_Z Y + \nabla_X [Y, Z].
   \]
   \pause
   Notice that the second term in the last of the three lines above contains a term \(-\nabla_X \nabla_Z Y\) which cancels with the \(\nabla_X \nabla_Z Y\) term here.
#+END_proof

**** Symmetries of the Curvature Tensor

#+BEGIN_proof
1. [@3] Using the same cancelling for the other terms results in
   #+BEGIN_latex
   \[
   \begin{split}
   \Rm(X, Y) Z &+ \Rm(Y, Z) X + \Rm(Z, X) Y \\
   &= \nabla_X [Y, Z] + \nabla_Y [Z, X] + \nabla_Z [X, Y] \\
   &\quad - \nabla_{[Y, Z]} X - \nabla_{[Z, X]} Y - \nabla_{[X, Y]} Z \\
   &= [X, [Y, Z]] + [Y, [Z, X]] + [Z, [X, Y]].
   \end{split}
   \]
   #+END_latex
   again by using symmetry to get the last line.
#+END_proof

**** Symmetries of the Curvature Tensor

#+BEGIN_proof
1. [@3] To proof is completed by showing the /Jacobi Identity/:
   \[
   [X, [Y, Z]] + [Y, [Z, X]] + [Z, [X, Y]] = 0.
   \]
   \pause

   This is little tedious but is easily computed directly
   #+BEGIN_latex
   \[
   \begin{split}
   [X, [Y, Z]] (f) &= X([Y, Z] f) - [Y, Z](X f) \\
   &= XYZf - XZYf - YZXf + ZYXf \\
   [Y, [Z, X]] (f) &= YZXf - YXZ f - ZXYf + XZYf \\
   [Z, [X, Y]] (f) &= ZXYf - ZYXf - XYZf + YXZf.
   \end{split}
   \]
   #+END_latex
   \pause

   Summing the three lines everything cancels.
#+END_proof

**** Multi-linearity of the Curvature Tensor

- The curvature tensor is a /multi-linear/ map. That is, for each fixed \(Y, Z, W\), the map \(X \mapsto g(\Rm(X, Y) Z, W)\) is linear. \pause The same goes for the other three slots. \pause
- Thus for example, writing \(X = X^u \partial_u + X^v \partial_v\),
  #+BEGIN_latex
  \[
  \begin{split}
  &g(\Rm(X^u\partial_u + X^v\partial_v, Y)Z, W) \\
  &\quad = X^u g(\Rm(\partial_u, Y)Z, W) + X^v g(\Rm(\partial_v, Y)Z, W).
  \end{split}
  \]
  #+END_latex
  \pause
- *Note*: The last two terms in the map \(X \mapsto \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X, Y]} Z\) are not linear because of the Leibniz rule. \pause But the extra terms all cancel:
  \[
  \nabla_{fX} \nabla_Y Z = f \nabla_X \nabla_Y Z
  \]
  \pause
  #+BEGIN_latex
  \[
  \begin{split}
  \nabla_Y \nabla_{fX} Z - \nabla_{[Y, fX]} Z &= f \nabla_Y \nabla_X Z + Y(f) \nabla_X Z \\
  &\quad - f\nabla_{[Y, X]} Z - Y(f) \nabla_X Z \\
  &= f(\nabla_Y \nabla_X Z - \nabla_{[Y, X]} Z).
  \end{split}
  \]
  #+END_latex

*** Lecture 12.2: Amazing Facts About the Gauss Curvature
**** Notes							   :noexport:
- Ref: 4.5
- http://wwwf.imperial.ac.uk/~skdona/lecturenotes/GAUSS.PDF
- Parallel postulate!
- Give the interpretation of Gauss curvature as area deformation of Gauss map
- Triangles
- Winding number in the plane and total curvature
**** Curvature Tensor of a Surface
- Multi-linearity means we only need to compute the curvature tensor on basis elements (summation convention!):
  \[
  g(\Rm(X^i \partial_i, Y^j \partial_j), Z^k \partial_k, W^l \partial_l) = X^i Y^j Z^k W^l g(\Rm(\partial_i, \partial_j)\partial_k, \partial_l).
  \]
  \pause
- In two dimensions, we only have \(\partial_u, \partial_v\). \pause
- Then
  \[
  \Rm(\partial_u, \partial_u) \partial_v = -\Rm(\partial_u, \partial_u) \partial_v
  \]
  hence
  \[
  \Rm(\partial_u, \partial_u) \partial_v = 0.
  \]
  \pause
- Applying the other symmetries, we find the only non-zero component is
  \[
  g(\Rm(\partial_u, \partial_v) \partial_u, \partial_v).
  \]

**** Curvature Tensor of a Surface
- All other terms can be obtained from the single term. For example,
  \[
  g(\Rm(\partial_u, \partial_v) \partial_u, \partial_v) = -g(\Rm(\partial_v, \partial_u) \partial_u, \partial_v)
  \]
  etc. \pause
- Thus we may write
  \[
  g(\Rm(\partial_u, \partial_v) \partial_u, \partial_v) = F(\partial_u, \partial_v)
  \]
  for some scalar valued function.
**** The Gauss Equation

We can express the curvature tensor in terms of the second fundamental form (i.e. the curvature we already know about). \pause

#+BEGIN_lemma
\[
g(\Rm(X, Y) X, Y) = - \left(A(X, X)A(Y, Y) - A(X, Y)^2\right) = -\det A(X, Y).
\]
#+END_lemma
\pause

#+BEGIN_proof
Recall that we have
\[
\nabla_X V = D_X V - \ip{D_X V}{N} N.
\]
\pause
Applying this formula to \(V = \nabla_Y Z\), we get
#+BEGIN_latex
\[
\begin{split}
g(\nabla_X \nabla_Y Z, W) &= \ip{\nabla_X \nabla_Y Z}{W} \\
&= \ip{D_X \nabla_Y Z - \ip{D_X \nabla_Y Z}{N}N}{W} \\
&= \ip{D_X \nabla_Y Z}{W}.
\end{split}
\]
#+END_latex
#+END_proof

**** The Gauss Equation

#+BEGIN_proof
From the previous slide:
\[
g(\nabla_X \nabla_Y Z, W) = \ip{D_X \nabla_Y Z}{W}.
\]
\pause

Computing \(D_X \nabla_Y Z\) gives
#+BEGIN_latex
\[
\begin{split}
D_X \nabla_Y Z &= D_X \left(D_Y Z - \ip{D_Y Z}{N} N\right) \\
&= D_X D_Y Z - \ip{D_X D_Y Z}{N}N - \ip{D_Y Z}{D_X N}N - \ip{D_Y Z}{N} D_X N.
\end{split}
\]
#+END_latex
\pause

Since we are taking the inner product with \(W\), we may ignore the middle two (normal) terms. \pause
#+BEGIN_latex
\[
\begin{split}
g(\nabla_X \nabla_Y Z, W) &= \ip{D_X D_Y Z - \ip{D_Y Z}{N} D_X N}{W} \\
&= \ip{D_X D_Y Z}{W} -A(Y, Z) A(X, W).
\end{split}
\]
#+END_latex
#+END_proof

**** The Gauss Equation

#+BEGIN_proof

A similar formula holds for \(g(\nabla_Y \nabla_X Z, W)\) so that\pause
#+BEGIN_latex
\[
\begin{split}
g(\Rm(X, Y)Z, W) &= g(\nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X, Y]} Z, W) \\
&= \ip{D_X D_Y Z}{W} - A(Y, Z) A(X, W) \\
&\quad - \ip{D_Y D_X Z}{W} + A(X, Z) A(Y, W) \\
&\quad - \ip{D_{[X, Y]} Z}{W} \\
&= \ip{\Rm_D(X, Y) Z}{W} \\
&\quad + A(X, Z) A(Y, W) - A(Y, Z) A(X, W).
\end{split}
\]
#+END_latex
\pause

But \(\Rm_D \equiv 0\) (Euclidean space has zero curvature!) since
\[
D_{\partial_i} D_{\partial_j} \partial_k = 0.
\]
#+END_proof

**** Gauss' Theorema Egregium (Remarkable Theorem)

#+BEGIN_theorem
The Gauss curvature is intrinsic. That is, if \((S_1, g_1)\) and \((S_2, g_2)\) are locally isometric, then \(K_1 = K_2\).
#+END_theorem
\pause

#+BEGIN_proof
For any \(X, Y\) linearly independent,
\[
K = \frac{\det A(X, Y)}{\det g(X, Y)} = -\frac{g(\Rm(X, Y)X, Y)}{\det g(X, Y)}.
\]
\pause

That's it! The curvature tensor is intrinsic \(\Rm = \Rm(\nabla) = \Rm(\nabla(g))\).
#+END_proof

**** Non-isometric Surfaces

#+BEGIN_eg
The surfaces
- Sphere: \(K \equiv 1\)
- Torus: \(K\) non-constant but changing sign
- Cylinder: \(K \equiv 0\)
- Paraboloid: \(K\) non-constant and positive
are not locally isometric.\pause
#+END_eg

- Besides the cylinder, none of these surfaces can be flattened out (even locally!) without distorting the geometry - stretching, crumpling etc. \pause
- In particular, all surfaces are locally diffeomorphic to the plane (via the local parametrisations) so they share the Calculus with the plane. \pause
- But typically, they do not share the /Geometry/ with the plane. \pause

/Even though plane calculus may be brought to bear on the study of surface geometry, the geometry itself is not plane geometry/.

**** Corrugation
#+BEGIN_eg
- Folding a sheet of (paper, metal, cardboard) along a line introduces curvature but does not change the geometry provided no stretching occurs. \pause
- Thus one principal curvature is non-zero, but Gauss' theorem forces the other to vanish since \(0 \underset{\text{Gauss Theorem}}{=} K = \kappa_1 \kappa_2\). \pause
- Introduces rigidity in one direction and flexibility in the other.
#+END_eg

#+BEGIN_center
#+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/corrugation.png]]
#+END_center

**** Map Making

#+BEGIN_eg
- No map exists preserving length, angle and area! \pause
- Archimedes Cylinder to Sphere map preserves area: \((x, y, z) \in C \mapsto (\sqrt{1 - z^2} x, \sqrt{1 - z^2} y, z)\). \pause
- The Mercator projection preserves angles. Good for navigation! \pause
#+END_eg

***** Pictures
****** Archimedes
       :PROPERTIES:
       :beamer_col: 0.5
       :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .3\textheight
[[file:img/archimdes_tomb.png]]

#+END_center

****** Mercator
       :PROPERTIES:
       :beamer_col: 0.5
       :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .3\textheight
[[file:img/Mercator-proj.png]]
#+END_center

**** Helicoid and Catenoid

#+BEGIN_eg
- Helicoid: \((v\cos(u), v\sin(u), u)\),
- Catenoid: \((\sinh(v) \cos(u), \sinh(v) \sin(u), u)\). \pause
The Helicoid and Catenoid are locally isometric with Gauss curvature
\[
K = -\frac{1}{(1 + u^2)^2}
\]
#+END_eg
\pause

***** Pictures
****** Catenoid
       :PROPERTIES:
       :beamer_col: 0.5
       :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/catenoid.png]]

#+END_center

****** Helicoid
       :PROPERTIES:
       :beamer_col: 0.5
       :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/helicoid.jpg]]
#+END_center

**** The Converse of Gauss' Theorem is false

#+BEGIN_eg
Here is an example of surfaces \(S_1, S_2\) for which \(K_1 = K_2\) but \(g_1 \ne g_2\). \pause

- \(\varphi(u, v) = (u\cos(v), u\sin(v), \ln(u))\)
- \(\psi(u, v) = (u\cos(v), u\sin(v), v)\) \pause

*Exercise*:
- Check that \(K_{\varphi}(u, v) = K_{\psi}(u, v)\) \\
- Check that \(g_{\varphi} (u, v) \ne g_{\psi} (u, v)\).
\pause

- Thus we have surfaces with the equal Gauss curvature that are not isometric. \pause
- Gauss Theorem: \(g_1 = g_2 \Rightarrow K_1 = K_2\). \pause
- Converse is false: \(K_1 = K_2 \not\Rightarrow g_1 = g_2\).
#+END_eg

*** Lecture 12.3: Gauss-Bonnet Theorem (Local)
**** Euclid's Axioms for Geometry:

The development of Riemannian geometry began with investigations into whether non-Euclidean geometries exist. \pause Euclidean axioms: \pause

1. Through any two points lies a line, \pause
2. Any (finite) line may be extended indefinitely and uniquely a a straight line \pause
3. Through any point and given any positive number, there exists a circle centred on the point with radius the given number \pause
4. Through any point on a line, there is a unique perpendicular line. \pause

***** Euclid's First Four Axioms

****** Axiom 1
       :PROPERTIES:
       :BEAMER_col: 0.25
       :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .3\textheight
[[file:img/euclid1.png]]
#+END_center

****** Axiom 2
       :PROPERTIES:
       :BEAMER_col: 0.25
       :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .3\textheight
[[file:img/euclid2.png]]
#+END_center

****** Axiom 3
       :PROPERTIES:
       :BEAMER_col: 0.25
       :END:
#+BEGIN_center
# #+ATTR_LATEX: :width .4\textwidth :height .5\textheight
[[file:img/euclid3.png]]
#+END_center

****** Axiom 4
       :PROPERTIES:
       :BEAMER_col: 0.25
       :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .3\textheight
[[file:img/euclid4.png]]
#+END_center

**** Parallel Postulate

The first four axioms (or postulates) are relatively self evident and non-controversial. \pause

Of a rather different nature is the famous /fifth postulate/: \pause

5. [@5] Given any line and point not on the line, there /exists a unique/ line through the point not intersecting the original line.

#+BEGIN_center
#+ATTR_LATEX: :width .6\textwidth :height .4\textheight
[[file:img/euclid5.png]]
#+END_center

**** Parallel Postulate and Triangles

The fifth postulate is equivalent to:

- Sum of the interior angles of a triangle: \(\theta_1 + \theta_2 + \theta_3 = \pi\). \pause

#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .8\textheight
[[file:img/euclidean_triangle.png]]
#+END_center

**** Triangles in non-Euclidean Geometry

- Sphere \(K > 0\): \(\theta_1 + \theta_2 + \theta_3 > \pi\)
- Euclidean Space \(K = 0\): \(\theta_1 + \theta_2 + \theta_3 = \pi\)
- Pseudosphere \(K < 0\): \(\theta_1 + \theta_2 + \theta_3 < \pi\)

***** Constant Curvature Geometries

****** Sphere
       :PROPERTIES:
       :BEAMER_col: 0.3
       :END:

#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/sphere_triangle.png]]
#+END_center

****** Euclidean Space
       :PROPERTIES:
       :BEAMER_col: 0.3
       :END:

#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/euclidean_triangle.png]]
#+END_center

****** Pseudosphere
       :PROPERTIES:
       :BEAMER_col: 0.3
       :END:

#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/pseudosphere_triangle.png]]
#+END_center

**** Piecewise Regular Curves

#+BEGIN_definition
A /piecewise/ regular curve \(\gamma : [a, b] \to S\) is a /continuous/ curve such that there exists a partition
\[
a = t_0 < t_1 < \cdots < t_{k-1} < t_k = b
\]
with \(\gamma\) is regular on \([t_i, t_{i+1}]\). The points \(\gamma(t_i)\) are called the vertices.
#+END_definition
\pause

/Regular/ means differentiable and \(\gamma' \ne 0\) with left and right continuous limits: \(\lim_{t\to^+ t_i} \gamma'(t)\) and \(\lim_{t\to^- t_i} \gamma'(t)\) are defined and non-zero.

\pause

We write
\[
\gamma'_-(t_i) = \lim_{t\to^- t_i} \gamma'(t), \quad \gamma'_+(t_i) = \lim_{t\to^+ t_i} \gamma'(t).
\]

**** Simple Closed Curves

#+BEGIN_definition
A /closed curve/ is a continuous curve \(\gamma : [a, b] \to S\) with \(\gamma(a) = \gamma(b)\). A /simple curve/ is a curve with no self intersections: \(\gamma(t) = \gamma(r) \Rightarrow t = r\).
#+END_definition
\pause

We consider piecewise regular, simple, closed curves.

**** Turning Tangents and Total Curvature of Plane Curves

Our first /Global/ result for curves. Generalising this result will lead us to the Gauss-Bonnet theorem. \pause

#+BEGIN_theorem
[Turning Tangents]
Let \(\gamma : [0, L] \to \RR^2\) closed plane curve parametrised by arc-length. Then
\[
I := \frac{1}{2\pi} \int_0^L \kappa(s) ds \in \ZZ.
\]
\pause
The integer, \(I\) is called the /winding number/. In particular, if \(\gamma\) is a simple, closed curve then
\[
\int_0^L \kappa(s) ds = \pm 2\pi.
\]
#+END_theorem
\pause

The sign \(\pm\) is just the orientation.

**** Turning Tangents and Total Curvature of Plane Curves

#+BEGIN_proof
- The function
  \[
  \theta(s) = \int_0^s \kappa(\tilde{s}) d\tilde{s}
  \]
  satisfies
  \[
  \partial_s \theta = \kappa.
  \]
  \pause
- Since \(\partial_s \theta = \kappa\) we have
  \[
  \theta(L) - \theta(0) = \int_0^L \kappa(s) ds.
  \]
#+END_proof

**** Turning Tangents and Total Curvature of Plane Curves

#+BEGIN_proof
- On the other hand, since \(T(s) = \gamma'(s)\) is unit length,
  \[
  T(s) = (\cos(\varphi(s)), \sin(\varphi(s)))
  \]
  for a differentiable (by the implicit function theorem) function \(\varphi: [0, L] \to \RR\). \pause
- But \(T(L) = T(0)\) and hence
  \[
  \varphi(L) = \varphi(0) + 2\pi I
  \]
  for an integer \(I\). \pause
- We also have
  \[
  \kappa = \ip{\partial_s T}{N} = \ip{\partial_s \varphi(-\sin\varphi, \cos\varphi)}{(-\sin\varphi, \cos\varphi)} = \partial_s \varphi.
  \]
#+END_proof

**** Turning Tangents and Total Curvature of Plane Curves

#+BEGIN_proof
- We have
  \[
  \partial_s \varphi = \partial_s \theta \Rightarrow \varphi(s) = \theta(s) + C
  \]
  for some constant \(C\). \pause

- Therefore,
  \[
  \varphi(L) - \varphi(0) = (\theta(L) + C) - (\theta(0) + C) = \theta(L) - \theta(0)
  \]
  \pause
- Putting it all together, we have
  \[
  2\pi I = \varphi(L) - \varphi(0) = \theta(L) - \theta(0) = \int_0^L \kappa ds.
  \]
  \pause
-  Note \(\theta\) is just the angle of \(T\) with a fixed vector (such as the x-axis).
#+END_proof

**** Angle in General

Define the angle \(\theta_i\) between \(\gamma'_-(t_i)\) and \(\gamma'_+(t_1)\) as follows:
1. \[
   \abs{\theta} = \abs{\arccos g(T_i^-, T_i^+)} \in (0, \pi).
   \]
   where \(T = \gamma'/\abs{\gamma'}\) is the unit tangent. \pause
2. We take \(\theta \in (-\pi, \pi)\) by choosing the sign so that \(\theta > 0\) whenever
   \[
   \{T_i^-, T_i^+\}
   \]
   is positively oriented and \(\theta < 0\) otherwise.
3. The case of a /cusp/ is when \(\theta = \pi\) in which case it's possibly to choose the sign so that \(\theta\) varies continuously.

**** Gauss-Bonnet Theorem (Local)

#+BEGIN_theorem
Let \(D \subseteq S\) be homeomorphic to a disc with boundary a piecewise regular, simple, closed curve, \(\gamma\). Then
\[
\int_D K dA + \int_{\gamma} \kappa ds = 2\pi - \sum_{i=1}^k \theta_i.
\]
#+END_theorem
\pause

- Since \(\gamma\) is only piecewise regular, the curvature is not defined at the vertices \(t_i\) so we make the definition,
  \[
  \int_{\gamma} \kappa ds = \sum_{i=1}^k \int_{t_{i-1}}^{t_i} \kappa ds.
  \]

**** Proof in the Plane

- In the plane \(K \equiv 0\) so Gauss-Bonnet becomes
  \[
  \int_{\gamma} \kappa ds = 2\pi - \sum_{i=1}^k \theta_i.
  \]
  \pause
- For \(\gamma\) regular (no vertices) Turning Tangents gives
  \[
  \int_{\gamma} \kappa ds = 2\pi.
  \]
  \pause
- For piecewise regular, break up the integral at the vertices:
  #+BEGIN_latex
  \[
  \begin{split}
  \int_{\gamma} \kappa ds &= \sum \int_{t_{i-1}}^{t_i} \kappa ds = \sum \int_{t_{i-1}}^{t_i} \partial_s \theta ds = \sum \theta^-(t_i) - \theta^+(t_{i-1}) \\
  &= \theta(t_k)^- - \theta(t_0)^+ + \sum \theta^-(t_i) - \theta^+(t_i) \\
  &= 2\pi - \sum \theta_i.
  \end{split}
  \]
  #+END_latex

**** Proof of Gauss-Bonnet

#+BEGIN_proof
[sketch in the case \(D\) is contained in a local parametrisation]

- On a surface, we may change coordinates so that
  \[
  g = \begin{pmatrix}
  g_{uu} & 0 \\
  0 & g_{vv}
  \end{pmatrix}.
  \]
  \pause
- The geodesic curvature of \(\gamma(s) = (u(s), v(s))\) may be expressed as
  \[
  \kappa = \frac{1}{2\sqrt{g_{uu}g_{vv}}} \left(\partial_v g_{vv} \partial_s v - \partial_u g_{uu} \partial_s u\right) + \partial_s \theta.
  \]
  \pause
  *Note*: In the plane, \(g_{uu} = g_{vv} = 1\) and so the first term vanishes recovering the plane case.
#+END_proof

**** Proof of Gauss-Bonnet

#+BEGIN_proof
- Integrating the geodesic curvature,
  #+BEGIN_latex
  \[
  \begin{split}
  \int_{t_{i-1}}^{t_i} \kappa ds &= \int_{t_{i-1}}^{t_i} \frac{1}{2\sqrt{g_{uu}g_{vv}}} \left(\partial_v g_{vv} \partial_s v - \partial_u g_{uu} \partial_s u \right) ds + \int_{t_{i-1}}^{t_i} \partial_s \theta ds \\
  &= \int_{t_{i-1}}^{t_i} \left(\frac{1}{2\sqrt{g_{uu}g_{vv}}} \partial_v g_{vv}\right) \partial_s v - \left(\frac{1}{2\sqrt{g_{uu}g_{vv}}} \partial_u g_{uu}\right) \partial_s u ds \\
  &\quad + \theta(t_i) - \theta(t_{i-1})
  \end{split}
  \]
  #+END_latex
#+END_proof

**** Proof of Gauss-Bonnet

#+BEGIN_proof
Apply the Gauss-Green Theorem:
\[
\int_{\gamma} P \partial_u s + Q \partial_v s ds = \int_D \partial_u Q - \partial_v P dA
\]
\pause
to
#+BEGIN_latex
\[
\begin{split}
\int_{\gamma} \kappa ds &= \sum \int_{t_{i-1}}^{t_i} \kappa ds \\
&= \int_{t_{i-1}}^{t_i} \left(\frac{1}{2\sqrt{g_{uu}g_{vv}}} \partial_v g_{vv}\right) \partial_s v - \left(\frac{1}{2\sqrt{g_{uu}g_{vv}}} \partial_u g_{uu}\right) \partial_s u ds \\
&\quad + \sum \theta(t_i) - \theta(t_{i-1})
\end{split}
\]
#+END_latex
#+END_proof

**** Proof of Gauss-Bonnet

#+BEGIN_proof
By Gauss-Green with
\[
P = - \frac{1}{2\sqrt{g_{uu}g_{vv}}} \partial_u g_{uu}, \quad Q = \frac{1}{2\sqrt{g_{uu}g_{vv}}} \partial_v g_{vv}
\]
\pause we get

#+BEGIN_latex
\[
\begin{split}
\int_{\gamma} \kappa ds &= \int_D \partial_u \left(\frac{1}{2\sqrt{g_{uu}g_{vv}}} \partial_v g_{vv}\right) + \partial_v \left(\frac{1}{2\sqrt{g_{uu}g_{vv}}} \partial_u g_{uu}\right) dA \\
&\quad  + \sum \theta(t_i) - \theta(t_{i-1})
\end{split}
\]
#+END_latex
#+END_proof

**** Proof of Gauss-Bonnet

#+BEGIN_proof
In our coordinate system with (\(g_{uv} = g_{vu} = 0\)) the integrand just so happens to be the Gauss curvature:
\[
K = \partial_u \left(\frac{1}{2\sqrt{g_{uu}g_{vv}}} \partial_v g_{vv}\right) + \partial_v \left(\frac{1}{2\sqrt{g_{uu}g_{vv}}} \partial_u g_{uu}\right)
\]
\pause

Thus
\[
\int_{\gamma} \kappa ds = \int_D K + \sum \theta(t_i) - \theta(t_{i-1}) = \int_D K + 2\pi - \sum \theta_i
\]
as required. \pause
#+END_proof

**** Remarks

- The desired coordinate system (\(g_{uv} = 0\)) is called orthogonal and exists on surfaces locally \pause
- We used a form of the Turning Tangents theorem without proof. \pause
- The formula for \(\kappa\) can be obtained by a similar manner to the plane case \(\partial_s \theta = \kappa\) but taking into account the changing metric. \pause
- The formula for \(K\) can be obtained from expressing \(\Rm\) in terms of \(g\) and using the Gauss equation. \pause
- The entire proof may be re-written (in a coordinate free way) using the language of /differential forms/ where the Gauss-Green theorem appears as Stokes' theorem for differential forms.

**** Triangles Again

#+BEGIN_definition
A /geodesic triangle/ is a piecewise regular, simple closed curve with precisely three vertices that is the boundary of a region \(D\) homeomorphic to a disc and such that each regular arc is a geodesic.
#+END_definition
\pause

Let \(\varphi_i = \pi - \theta_i \in (0, 2\pi)\) be the /interior angles/. \pause Then
\[
2\pi - (\theta_1 + \theta_2 + \theta_3) = 2\pi - (\pi - \varphi_1 + \pi - \varphi_2 + \pi - \varphi_3) = \varphi_1 + \varphi_2 + \varphi_3 - \pi.
\]
\pause

By Gauss-Bonnet
\[
\int_D K dA = 2\pi - (\theta_1 + \theta_2 + \theta_3) = \varphi_1 + \varphi_2 + \varphi_3 - \pi.
\]

**** Triangles in Constant Curvature

#+BEGIN_eg
- Sphere \(K \equiv 1\): \(0 < \operatorname{Area} (D) = \int_D K dA = \varphi_1 + \varphi_2 + \varphi_3 - \pi.\) \pause
- Plane \(K \equiv 0\): \(0 = \int_D K dA = \varphi_1 + \varphi_2 + \varphi_3 - \pi.\) \pause
- Pseudosphere \(K \equiv -1\): \(0 > -\operatorname{Area} (D) = \int_D K dA = \varphi_1 + \varphi_2 + \varphi_3 - \pi.\)
#+END_eg

- On the sphere and pseudosphere, the angles determine the area of the triangle!
- On the plane, congruent triangles have the same angles but not generally the same area.

**** Triangles in non-Euclidean Geometry

- Sphere \(K > 0\): \(\varphi_1 + \varphi_2 + \varphi_3 = \operatorname{Area}(D) +  \pi > \pi\)
- Euclidean Space \(K = 0\): \(\varphi_1 + \varphi_2 + \varphi_3 = \pi\)
- Pseudosphere \(K < 0\): \(\varphi_1 + \varphi_2 + \varphi_3 = -\operatorname{Area}(D) + \pi < \pi\)

***** Constant Curvature Geometries

****** Sphere
       :PROPERTIES:
       :BEAMER_col: 0.3
       :END:

#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/sphere_triangle.png]]
#+END_center

****** Euclidean Space
       :PROPERTIES:
       :BEAMER_col: 0.3
       :END:

#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/euclidean_triangle.png]]
#+END_center

****** Pseudosphere
       :PROPERTIES:
       :BEAMER_col: 0.3
       :END:

#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/pseudosphere_triangle.png]]
#+END_center

**** Regular Tilings

#+BEGIN_definition
A /regular \(n\)-gon/ of \(S\) is a piecewise regular, simple, closed curved with \(n\) vertices, bounding a disc whose arcs are all geodesics of the same length meeting at the same angle \(\theta\).
#+END_definition

\pause

Let \(P_i\) denote a regular \(n\)-gon including the boundary curve and the interior.

\pause

#+BEGIN_definition
A /regular tiling/ of \(S\) is a set of regular \(n\)-gons \(P_i\) all of the same area such that
1. \(S = \union_i P_i\)
2. For \(i \ne j\), \(P_i \intersect P_j\) is either empty, a vertex, or an entire arc.
#+END_definition

**** Planar Regular Tilings

- In the plane, the interior angle of a regular \(n\)-gon is
  \[
  \theta = \pi - 2\pi/n.
  \]
  \pause
- Let \(k\) be the number of \(n\)-gons meeting at a vertex so that adding \(k\) copies of \(\theta\) gives \(2\pi\):
  \[
  2\pi = k \theta = k(\pi - 2\pi/n) = \frac{kn - 2k}{n} \pi
  \]
  \pause
- Therefore
  \[
  2n = kn - 2k
  \]
  \pause
- That is
  \[
  0 = kn - 2k - 2n = k(n-2) - 2(n-2) - 4 = (k-2)(n-2) - 4
  \]

**** Planar Regular Tilings
- The only solutions \((k, n)\) to
  \[
  (k-2)(n-2) = 4
  \]
  are
  \[
  (k, n) = (6, 3), (4, 4), (3, 6).
  \]
  \pause

***** Picture
      :PROPERTIES:
      :BEAMER_col: 0.3
      :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/1-uniform_n11.png]]
#+END_center

***** Picture
      :PROPERTIES:
      :BEAMER_col: 0.3
      :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/1-uniform_n5.png]]
#+END_center

***** Picture
      :PROPERTIES:
      :BEAMER_col: 0.3
      :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/1-uniform_n1.png]]
#+END_center

**** Spherical Regular Tilings

#+BEGIN_eg
On the sphere:
  \[
  2\pi > \frac{kn - 2k}{n} \pi.
  \]
  Hence
  \[
  (k - 2)(n - 2) < 4
  \]
  \pause
  Not many solutions...
#+END_eg
\pause

- /Congruent/ but not regular polygons allows more possibilities:

***** Picture
      :PROPERTIES:
      :BEAMER_col: 0.3
      :END:
#+BEGIN_center
#+ATTR_LATEX: :width .8\textwidth :height .4\textheight
[[file:img/sphere_tiling.png]]
#+END_center

**** Hyperbolic Tiling

The \poincare{} disc is the unit disc \(D = \{x^2 + y^2 < 1\}\) equipped with a metric \(g\) such that \(K \equiv -1\). \pause Gauss-Bonnet applies. \pause

#+BEGIN_eg
- Now we have
  \[
  (k - 2)(n - 2) > 4
  \]
  Infinitely many solutions! \pause
#+END_eg

***** Picture
      :PROPERTIES:
      :BEAMER_col: 0.3
      :END:
#+BEGIN_center
#+ATTR_LATEX: :width 1.2\textwidth :height .4\textheight
[[file:img/tess_5_4.png]]
#+END_center

**** Notes 							   :noexport:
- Ref: 4.5
** MATH3405 Differential Geometry: Week 13
*** Lecture 13.1: Gauss-Bonnet Theorem (Global)
**** Triangulations

#+BEGIN_definition
A /triangulation/ of a regular surface \(S\) is a finite set of triangles, \(\{T_i\}_{i=1}^n\) such that
1. \(S = \union_{i=1}^n T_i\), \pause
2. Each intersection \(T_i \cap T_j\) is either empty, a common edge of \(T_i\) and \(T_j\) or a common vertex of \(T_i\) and \(T_j\).
#+END_definition
\pause

A fundamental fact we use (without proof) is that there always exists triangulations of surfaces. \pause

Let
\begin{align*}
F &= \text{number of triangles (faces)} \\
E &= \text{number of edges} \\
V &= \text{number of vertices}.
\end{align*}

**** Euler Characteristic

#+BEGIN_definition
The Euler characteristic, \(\chi\) of \(\{T_i\}_{i=1}^n\) is defined be
\[
\chi = V - E + F.
\]
#+END_definition
\pause

#+BEGIN_theorem
[without proof]
The Euler characteristic is independent of the choice of triangulation. Thus we may define the Euler characteristic of a surface, \(\chi(S)\) to be equal to the (common) Euler characteristic of any triangulation.
#+END_theorem
\pause

The Euler characteristic is a /complete topological invariant/ for compact surfaces \(S_1, S_2\):
#+BEGIN_theorem
[without proof]
If \(\varphi : S_1 \to S_1\) is a homeomorphism, then \(\chi(S_1) = \chi(S_1)\). Conversely, if \(\chi(S_1) = \chi(S_2)\), then there exists a homeomorphism \(S_1 \to S_2\).
#+END_theorem

**** Examples
- disc
- square
- annulis
**** Examples
- sphere
- torus
- \(g\) handles
**** Classification of Closed Surfaces (compact, no boundary)

#+BEGIN_definition
A genus \(g \in \NN = \{0, 1, 2, \dots\}\) surface \(S_g\) is homeomorphic to a sphere with \(g\) handles attached.
#+END_definition
\pause

For every \(g \in \NN\), there exists such a surface.
\pause

#+BEGIN_theorem
[without proof]
1. \(\chi(S_g) = 2(1-g)\) \pause
2. Every compact surface has \(\chi(S) \in \{-2, 0, -2, -4, \dots, -2k, \dots\}\). \pause
Therefore every compact surface is homeomorphic to \(S_g\) for some \(g\).
#+END_theorem
\pause

The proof follows by first showing that \(\chi(\sphere^2) = 2\), and then \(\chi(S + \text{handle}) = \chi(S) - 2\).

**** Classification of Closed Surfaces

- Some pictures of genus \(g\) surfaces.

**** Global Gauss-Bonnet

Let \(R \subseteq S\) be a /regular region/. That is, \(R\) is a region bounded by finitely many piecewise regular, simple, closed curves \(\{C_i\}_{i=1}^k\).

#+BEGIN_theorem
[Global Gauss-Bonnet]
\[
\int_R K dA + \sum_{i=1}^k \left(\int_{C_i} \kappa ds + \sum_{j=1}^{N_i} \theta_{ij}\right) = 2\pi\chi(R).
\]
#+END_theorem
\pause

- We define
  \[
  \int_R K dA = \sum_n \int_{T_n} K du dv
  \]
  where \(\{T_n\}\) is a triangulation of \(R\) with each triangle contained in a local parametrisation. \pause
- For each \(i\), \(\{\theta_{ij}\}_{j=1}^{N_i}\) denotes the exterior angles of \(C_i\) at the vertices.
**** Global Gauss-Bonnet Corollaries

#+BEGIN_corollary
Let \(S\) be a compact, orientable, regular surface. Then
\[
\int_S K dA = 2\pi\chi(S).
\]
#+END_corollary
\pause

- This is quite an amazing result! Compare all the possible /topological/ sphere with widely varying geometry. No matter what, the Gauss curvature distributes itself in such a way that the total Gauss curvature \(K\) (i.e. \(\int_S K dA\)) is the same.

**** Global Gauss-Bonnet Corollaries

- The standard torus and coffee cup are homeomorphic hence have the same total Gauss curvature. \pause
- A \(g\) holed torus and the sphere with \(g\) handles attached are homeomorphic, hence have the same total Gauss curvature. \pause
- The Gauss-Bonnet theorem holds also for compact two-dimensional Riemannian manifolds without boundary (closed Riemannian surface). In each homeomorphism class (all surfaces with the same Euler characterstic), there exists a unique (up to scale) closed Riemannian surface, \(M\) with constant Gauss curvature given by
  \[
  K \equiv \frac{2\pi\chi(M)}{\operatorname{Area}(M)}.
  \]

**** Global Gauss-Bonnet Corollaries

#+BEGIN_corollary
Any compact, regular surface, \(S\) with \(K > 0\) is homeomorphic to the sphere.
#+END_corollary
\pause

#+BEGIN_proof
Gauss-Bonnet implies
\[
\chi(S) = \int K dA > 0
\]
and hence \(\chi(S) = 2\), hence \(S\) is homeomorphic to the sphere since \(\chi\) is a complete invariant.
#+END_proof

**** Global Gauss-Bonnet Corollaries

- In fact, every compact, regular surface \(S\) has an elliptic point (a point where \(K > 0\)).\pause
- This follows in a similar manner to the proof of the surjectivity of the Gauss map, but rather than taking a plane and moving it until it touches \(S\), one takes a sphere containing \(S\) and shrinks it until it touches \(S\). The second derivative test applied to the same function as in the Gauss map proof shows \(K > 0\).
\pause

#+BEGIN_corollary
Every compact, regular surface with \(\chi \leq 0\) has points of positive /and/ negative Gauss curvature.
#+END_corollary
\pause

#+BEGIN_theorem
[A variant of Hilbert's Theorem]
There are no compact, regular surfaces with /everywhere/ negative Gauss curvature.
#+END_theorem

**** Proof of Global Gauss-Bonnet Theorem

- Applying the local Gauss-Bonnet Theorem to each triangle \(T_n\) with boundary arcs \(\gamma_n^1, \gamma_n^2, \gamma_n^3\) in a triangulation,
  \[
  \int_{T_n} K dA + \sum_{m=1}^3 \left(\int_{\gamma_n^m} \kappa ds + \alpha_{nm}\right) = 2\pi.
  \]
  where \(\alpha_{j1}, \alpha_{j2}, \alpha_{j3}\) are the external angles of the   triangle \(T_j\). \pause

- Summing over the number \(F\) of triangles, all /interior/ arcs appear exactly twice with opposite orientation hence cancel and all that is left are the boundary arcs \(C_i\) (see figure). Therefore,
  \[
  \int_R K dA + \sum_{i=1}^k \int_{C_i} \kappa ds + \sum_{n=1}^{F}\sum_{m=1}^3 \alpha_{nm} = 2\pi F.
  \]

**** Proof of Global Gauss-Bonnet Theorem

- We have
  \[
  \int_R K dA + \sum_{i=1}^k \int_{C_i} \kappa ds + \sum_{n=1}^{F}\sum_{m=1}^3 \alpha_{nm} = 2\pi F.
  \]
  \pause

- Recall the theorem states that
  \[
  \int_R K dA + \sum_{i=1}^k \left(\int_{C_i} \kappa ds + \sum_{j=1}^{N_i} \theta_{ij}\right) = 2\pi\chi(R) = 2\pi(F - E + V).
  \]
  \pause

- Thus to prove the theorem we need to prove that
  \[
  \sum_{n=1}^{F}\sum_{m=1}^3 \alpha_{nm} = \sum_{i=1}^k \sum_{j=1}^{N_i} \theta_{ij} + 2\pi(E - V)
  \]

**** Proof of Global Gauss-Bonnet Theorem

- Let \(\beta_{nm} = \pi - \alpha_{nm}\) be the /internal/ angles of the triangle \(T_n\). \pause

- Recall the sum is over \(1 \leq n \leq F\) and \(1 \leq m \leq 3\). \pause

- Then
  \[
  \sum \alpha_{nm} = \sum \pi - \beta_{nm} = 3\pi F - \sum \beta_{nm}.
  \]
  \pause

- Thus we now want to show that
  \[
  3\pi F - \sum \beta_{nm} = \sum \theta_{ij} + 2\pi(E - V)
  \]

**** Proof of Global Gauss-Bonnet Theorem

- The idea is now to keep track of the edges that lie on a boundary curve \(C_i\) (/exterior edges/) and those that lie in the interior of \(R\) (/interior edges/). \pause
- Thus we define
  \begin{align*}
  E_{\text{ext}} &= \text{number of exterior edges} \\
  E_{\text{int}} &= \text{number of interior edges} \\
  V_{\text{ext}} &= \text{number of exterior vertices} \\
  V_{\text{int}} &= \text{number of interior vertices} \\
  \end{align*}

**** Proof of Global Gauss-Bonnet Theorem

- Because the \(C_i\) are simple, closed curves, we have \(V_{\text{ext}} = E_{\text{ext}}\). \pause
- By induction on the number of triangles: \(3F = 2E_{\text{int}} + E_{\text{ext}}\). \pause

- Thus we have
  #+BEGIN_latex
  \[
  \begin{split}
  3\pi F - \sum \beta_{nm} &= 2\pi E_{\text{int}} + \pi E_{\text{ext}} - \sum \beta_{nm} + 2\pi E_{\text{ext}} - 2\pi V_{\text{ext}} \\
  &= 2\pi E_{\text{int}} + 2\pi E_{\text{ext}} + \pi E_{\text{ext}} - 2\pi V_{\text{ext}} - \sum \beta_{nm} \\
  &= 2\pi E - \pi V_{\text{ext}} - \sum \beta_{nm}.
  \end{split}
  \]
  #+END_latex
  \pause

- To finally finish we need to show that
  #+BEGIN_latex
  \[
  - \pi V_{\text{ext}} - \sum \beta_{nm} = -2\pi V + \sum \theta_{ij}.
  \]
  #+END_latex

**** Proof of Global Gauss-Bonnet Theorem

- Divide the \(\beta_{nm}\) into internal and external vertices
  \[
  \sum \beta_{mn} = \sum_a \beta_{\text{int}, a} + \sum_b \beta_{\text{ext}, b}
  \]
  \pause

- For the internal vertices, the sum of the angles equals to \(2\pi\), hence
  \[
  \sum_a \beta_{\text{int}, a} = 2\pi V_{\text{int}}.
  \]
  \pause

- For the external vertices, let \(V_{\text{ext},C}\) denote the number of vertices of the triangulation that are also vertices of a boundary arc \(C_i\). \pause
- Let \(V_{\text{ext,T}}\) denote the number of external vertices of the triangulation that are not also vertices of any boundary arc \(C_i\). \pause
- Thus
  \[
  V_{\text{ext}} = V_{\text{ext}, C} + V_{\text{ext}, T}.
  \]
**** Proof of Global Gauss-Bonnet Theorem

- Divide the external vertices of the triangulation into those from the arcs \(C_i\) and those from the triangulation alone so that
  \[
  \sum_b \beta_{\text{ext}, b} = \sum_c \beta_{\text{ext}, C, c} + \sum_d \beta_{\text{ext}, T, d}.
  \]
  \pause

- For vertices \(\beta_{\text{ext}, T, d}\) of the triangulation but not of of an arc \(C_i\), each vertex is a regular point of the curve \(C_i\) so that the sum of the two angles equals \(\pi\). Thus
  \[
  \sum_d \beta_{\text{ext}, T, d} = \pi V_{\text{ext},T}.
  \]
  \pause

- The remaining angles are /internal/ angles at vertices of some \(C_i\) so that
  \[
  \sum_c \beta_{\text{ext}, C, d} = \sum_{ij} \varphi_{ij} = \sum_{ij} \pi - \theta_{ij} = \pi V_{\text{ext}, C} - \sum_{ij} \theta_{ij}.
  \]

**** Proof of Global Gauss-Bonnet Theorem

- Thus we come to the end of the proof: we need to show
  #+BEGIN_latex
  \[
  - \pi V_{\text{ext}} - \sum \beta_{nm} = -2\pi V + \sum \theta_{ij}.
  \]
  #+END_latex
  \pause
- Summing up all our group of angles (internal, external and part of a \(C_i\), external and not part of a \(C_i\)):
  #+BEGIN_latex
  \[
  \begin{split}
  - \pi V_{\text{ext}} - \sum \beta_{nm} &= -\pi V_{\text{ext}} - 2\pi V_{\text{int}} - \pi V_{\text{ext},T} - \left(\pi V_{\text{ext}, C} - \sum_{ij} \theta_{ij}\right) \\
  &= -\pi V_{\text{ext}} - \pi(V_{\text{ext},T} + \pi V_{\text{ext}, C}) - 2\pi V_{\text{int}} + \sum_{ij} \theta_{ij} \\
  &= -2\pi V_{\text{ext}} - 2\pi V_{\text{int}} + \sum_{ij} \theta_{ij} \\
  &= -2\pi V + \sum_{ij} \theta_{ij}.
  \end{split}
  \]
  #+END_latex
**** Notes							   :noexport:
- Ref: 4.5
- Euler characteristic etc.
- Constant curvature spaces
- Uniformisation Theorem
*** Lecture 13.2: Applications of Gauss-Bonnet
**** Notes							   :noexport:
- Ref: 4.5
- Applications of Gauss-Bonnet
*** Lecture 13.3: Review
* Supplements
** Covariant Derivative and Curvature in Coordinates
*** Covariant Derivative
\label{sec:coord_covariant_derivative}

Let \(\partial_u, \partial_v\) be coordinate vector fields. For \(i, j \in \{u, v\}\), \(\nabla_{\partial_i} \partial_j\) is a vector field and hence we may write it in terms of the coordinate vector fields:
\[
\nabla_{\partial_i} \partial_j = \Gamma_{ij}^k \partial_k
\]
for some scalar valued functions \(\Gamma_{ij}^k\). Note the Einstein summation convention - there is a sum over \(k\). That is fixing \(i\) and \(j\),
\[
\nabla_{\partial_i} \partial_j = \Gamma_{ij}^u \partial_u + \Gamma_{ij}^v \partial_v
\]
so that \(\Gamma_{ij}^u\) is the \(\partial_u\) component of \(\nabla_{\partial_i} \partial_j\) while \(\Gamma_{ij}^v\) is the \(\partial_v\) component.

The scalar functions \(\Gamma_{ij}^k\) are known as the /Christoffel symbols/.

In full,
\begin{align*}
\nabla_{\partial_u} \partial_u &= \Gamma_{uu}^u \partial_u + \Gamma_{uu}^v \partial_v \\
\nabla_{\partial_v} \partial_v &= \Gamma_{vv}^u \partial_u + \Gamma_{vv}^v \partial_v \\
\nabla_{\partial_u} \partial_v &= \Gamma_{uv}^u \partial_u + \Gamma_{uv}^v \partial_v \\
\nabla_{\partial_v} \partial_u &= \Gamma_{vu}^u \partial_u + \Gamma_{vu}^v \partial_v.
\end{align*}

By symmetry of the connection and since \([\partial_u, \partial_v] = 0\) we have
\[
\nabla_{\partial_u} \partial_v = \nabla_{\partial_v} \partial_v.
\]
In other words, the last two rows of the full list of Christoffel symbols above are equal and hence the Christoffel symbols are symmetric in the lower two indices:
\[
\Gamma_{ij}^k = \Gamma_{ji}^k.
\]
Thus there are precisely \(6\) independent Christoffel symbols determined by the covariant derivative.

*** The Curvature Tensor

Recall the curvature tensor is defined to be
\[
\Rm(X, Y) Z = \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X, Y]} Z.
\]

In coordinates
\[
\Rm(\partial_i, \partial_j) \partial_k = {\Rm_{ijk}}^l \partial_l.
\]
That is, fixing \(i,j,k\) \({\Rm_{ijk}}^l\) is the \(\partial_l\) component of \(\Rm(\partial_i, \partial_j) \partial_k\). Again the Einstein summation convention applies so there is a sum over \(l\):
\[
\Rm(\partial_i, \partial_j) \partial_k = {\Rm_{ijk}}^u \partial_u + {\Rm_{ijk}}^v \partial_v.
\]

Now, there are \(2^3 = 8\) possible choices for \(i,j,k\) with each choice \(\Rm(\partial_i, \partial_j) \partial_k\) being a sum over \(2\) two terms giving a total of \(16\) possible components. However, as with the Christoffel symbols, the symmetries of the curvature tensor reduces the number of independent components.

First of all we use anti-symmetry in the first two slots
\[
\Rm(Y, X) Z = - \Rm(X, Y) Z.
\]
This yields
\[
{\Rm_{iik}}^l = 0
\]
since
\[
{\Rm_{iik}}^l \partial_l = \Rm(\partial_i, \partial_i)\partial_k = 0
\]
and thus each of the components \({\Rm_{iik}}^l\) must vanish since \(\{\partial_l\}\) is a basis. By similar reasoning, we also have
\[
{\Rm_{jik}}^l \partial_l = \Rm(\partial_j, \partial_i)\partial_k = - \Rm(\partial_i, \partial_j)\partial_k = -{\Rm_{ijk}}^l \partial_l.
\]
and hence for each fixed \(k,l\)
\[
{\Rm_{jik}}^l = -{\Rm_{ijk}}^l
\]

Therefore, for each of the four possible choices of fixed \(k,l\), we have
\[
{\Rm_{uuk}}^l = {\Rm_{vvk}}^l = 0
\]
and
\[
{\Rm_{vuk}}^l = - {\Rm_{uvk}}^l.
\]
So for each fixed \(k, l\) we can recover all components of the curvature tensor from just \({\Rm_{uvk}}^l\). In other words, we have reduced the \(2^4 = 16\) components down to only \(4\) independent components corresponding to each fixed \(k,l\)!

But we are not done since there are further symmetries of the curvature tensor. We also have anti-symmetry in the last two slots
\[
g(\Rm(X, Y)Z, W) = - g(\Rm(X, Y)W, Z).
\]
Let us now write
\[
\Rm_{ijkl} = g(\Rm(\partial_i) \partial_j) \partial_k, \partial_l)
\]
From the previous reduction, we can take \(i=u\), \(j=v\), leaving four possible combinations of \(k,l\). The anti-symmetry in the last two slots gives
\[
\Rm_{uvuu} = \Rm_{uvvv} = 0
\]
and
\[
\Rm_{uvvu} = -\Rm_{uvuv}.
\]

Thus we may compute \(\Rm_{ijkl}\) from the single component
\[
\Rm_{uvuv}.
\]
Down from \(16\) possible components to just a single independent component!

To recover \({\Rm_{ijk}}^l\) from \(\Rm_{ijkl}\) we do the following: Write
\[
g_{ij} = g(\partial_i, \partial_j)
\]
so that
\[
\Rm_{ijkl} = g({\Rm_{ijk}}^m \partial_m, \partial_l) = {\Rm_{ijk}}^m g(\partial_m, \partial_l) = {\Rm_{ijk}}^m g(\partial_l, \partial_m) = g_{lm} {\Rm_{ijk}}^m.
\]
This is known as /lowering an index/ (with the metric).

If we keep \(i,j,k\) fixed, we can write this in matrix form
#+BEGIN_latex
\[
\begin{pmatrix}
\Rm_{ijku} \\
\Rm_{ijkv}
\end{pmatrix}
=
\begin{pmatrix}
g_{uu} & g_{uv} \\
g_{vu} & g_{vv}
\end{pmatrix}
\begin{pmatrix}
{\Rm_{ijk}}^u \\
{\Rm_{ijk}}^v
\end{pmatrix}
\]
#+END_latex

Since \(g\) is a metric, the matrix is positive definite and hence invertible. Thus we obtain
#+BEGIN_latex
\[
\begin{pmatrix}
{\Rm_{ijk}}^u \\
{\Rm_{ijk}}^v
\end{pmatrix}
=
\frac{1}{g_{uu}g_{vv} - g_{uv}^2}
\begin{pmatrix}
g_{vv} & -g_{uv} \\
-g_{vu} & g_{uu}
\end{pmatrix}
\begin{pmatrix}
\Rm_{ijku} \\
\Rm_{ijkv}
\end{pmatrix}
\]
#+END_latex

Explicitly, for example,
\[
{\Rm_{uvu}}^u = \frac{1}{g_{uu}g_{vv} - g_{uv}^2} (g_{vv}\Rm_{uvuu} - g_{uv} \Rm_{uvuv}) = -\frac{g_{uv} \Rm_{uvuv}}{g_{uu}g_{vv} - g_{uv}^2}
\]
Notice in particular, that while \(\Rm_{uvuu} = 0\), it is not true in general that \({\Rm_{uvu}}^u = 0\). That is a repeated index in the last two slots, \({\Rm_{ijk}}^k\) need not vanish in general. If we had, \(\partial_u,\partial_v\) orthogonal, then \(g_{uv} = 0\) and in this case we do indeed have \({\Rm_{uvu}}^u = 0\).

The \(v\) component is
\[
{\Rm_{uvu}}^v = \frac{g_{uu} \Rm_{uvuv}}{g_{uu}g_{vv} - g_{uv}^2}.
\]

Similarly we obtain expressions for \({\Rm_{uvv}}^u\) and \({\Rm_{uvv}}^v\). In summary
\begin{align*}
-{\Rm_{vuu}}^u &= {\Rm_{uvu}}^u = -\frac{g_{uv} \Rm_{uvuv}}{g_{uu}g_{vv} - g_{uv}^2} \\
-{\Rm_{vuu}}^v &= {\Rm_{uvu}}^v = \frac{g_{vv} \Rm_{uvuv}}{g_{uu}g_{vv} - g_{uv}^2} \\
-{\Rm_{vuv}}^u &= {\Rm_{uvv}}^u = \frac{g_{vv} \Rm_{uvvu}}{g_{uu}g_{vv} - g_{uv}^2} = -\frac{g_{vv} \Rm_{uvuv}}{g_{uu}g_{vv} - g_{uv}^2} \\
-{\Rm_{vuv}}^v &= {\Rm_{uvv}}^v = -\frac{g_{vu} \Rm_{uvvu}}{g_{uu}g_{vv} - g_{uv}^2} = \frac{g_{vu} \Rm_{uvuv}}{g_{uu}g_{vv} - g_{uv}^2}.
\end{align*}
Notice that everything is expressed in terms of \(g\) and the single component \(\Rm_{uvuv}\) on the right hand side. All other components vanish involve a repeated index in the first two slots and hence vanish.

*** The Gauss Equation

Recall we have
\[
g(\Rm(X, Y) Z, W) = A(X, W) A(Y, Z) - A(X, Z) A(Y, W).
\]
Writing
\[
A_{ij} = A(\partial_i, \partial_j)
\]
we obtain the Gauss equation in coordinates
\[
\Rm_{ijkl} = A_{il}A_{jk} - A_{ik} A_{jl}.
\]
In terms of our single component of the curvature tensor,
\[
\Rm_{uvuv} = A_{uv}^2 - A_{uu} A_{vv}.
\]
since \(A_{vu} = A_{uv}\).

Recalling also that
\[
K = \frac{\det A}{\det g} = \frac{A_{uu} A_{vv} - A_{uv}^2}{g_{uu}g_{vv} - g_{uv}^2}
\]
we obtain the Gauss curvature
\[
K = - \frac{\Rm_{uvuv}}{g_{uu}g_{vv} - g_{uv}^2}
\]
in terms of the metric and the curvature tensor.

*** The Covariant Derivative in Terms of the Metric

Using metric compatibility
\[
\nabla_X [g(Y, Z)] = g(\nabla_X Y, Z) + g(Y, \nabla_X Z),
\]
and symmetry
\[
\nabla_X Y - \nabla_Y X = [X, Y],
\]
we can write the Christoffel symbols in terms of the metric. First
#+BEGIN_latex
\[
\begin{split}
\partial_i g_{jk} &= \partial_i [g(\partial_j, \partial_k)] = g(\nabla_{\partial_i} \partial_j, \partial_k) + g(\partial_j, \nabla_{\partial_i} \partial_k) \\
&= g(\Gamma_{ij}^l \partial_l, \partial_k) + g(\partial_j, \Gamma_{ik}^l \partial_l) \\
&= \Gamma_{ij}^l g_{lk} + \Gamma_{ik}^l g_{jl}.
\end{split}
\]
#+END_latex
and similarly for cyclic permutations of \(i,j,k\). Thus we have
\begin{align*}
\partial_i g_{jk} &= \Gamma_{ij}^l g_{lk} + \Gamma_{ik}^l g_{jl}, \\
\partial_j g_{ki} &= \Gamma_{jk}^l g_{li} + \Gamma_{ji}^l g_{kl}, \\
\partial_k g_{ij} &= \Gamma_{ki}^l g_{lj} + \Gamma_{kj}^l g_{il}.
\end{align*}

As already observed in section \ref{sec:coord_covariant_derivative}, from the symmetry of the connection, the Christoffel symbols are symmetric in the lower two indices
\[
\Gamma_{ij}^k = \Gamma_{ji}^k.
\]

Now we take an alternating sum to isolate a single Christoffel symbol
#+BEGIN_latex
\[
\begin{split}
\partial_i g_{jk} - \partial_j g_{ki} + \partial_k g_{ij} &= (\Gamma_{ij}^l g_{lk} + \Gamma_{ik}^l g_{jl}) - (\Gamma_{jk}^l g_{li} + \Gamma_{ji}^l g_{kl}) + (\Gamma_{ki}^l g_{lj} + \Gamma_{kj}^l g_{il}) \\
&= (\Gamma_{ik}^l g_{jl} + \Gamma_{ki}^l g_{lj}) + (\Gamma_{ij}^l g_{lk} - \Gamma_{ji}^l g_{kl}) + (\Gamma_{kj}^l g_{il} - \Gamma_{jk}^l g_{li}) \\
&= 2 \Gamma_{ik}^l g_{jl}
\end{split}
\]
#+END_latex

Thus
\[
g_{jl} \Gamma_{ik}^l = \frac{1}{2}(\partial_i g_{jk} - \partial_j g_{ki} + \partial_k g_{ij})
\]
determines \(\Gamma_{ik}^l\) in terms of the metric.

Note that \(g_{jl}\) is an invertible matrix so once can solve for \(\Gamma_{ik}^l\). To keep the notation from getting too out of hand, it is traditional to write
\[
g^{ij}
\]
for the components of the inverse matrix of \(g\).

Recall that writing matrix multiplication in components one has
\[
(AB)_i^j = A_{ik} B^{kj}.
\]
The placement of upper and lower indices is chosen here in just such a way to allow us to use Einstein summation. In other words, the \({}_i^j\) component of the product \(AB\) is given by the \(\sum_k A_{ik} B^{kj}\).

Thus by definition of the inverse, \(g g^{-1} = \operatorname{Id}\) we obtain
\[
\delta_i^j = \operatorname{Id}_i^j = (g g^{-1})_i^j = g_{ik} g^{kj}
\]
where \(\delta_i^j\) equals \(1\) when \(i=j\) and \(0\) otherwise. Likewise
\[
\delta_i^j = g^{jk}g_{ki}.
\]

Applying this to the Christoffel symbols gives
\[
\Gamma_{ik}^m = \delta^m_l \Gamma_{ik}^l = g^{mj} g_{jl} \Gamma_{ik}^l = \frac{1}{2} g^{mj} (\partial_i g_{jk} - \partial_j g_{ki} + \partial_k g_{ij}).
\]

*** The Curvature in Terms of the Metric

Recall the curvature tensor is defined to be
\[
\Rm(X, Y) Z = \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X, Y]} Z
\]
and it is completely determined by
\[
\Rm_{uvuv} = g(\Rm(\partial_u, \partial_v)\partial_u, \partial_v) = g(\nabla_{\partial_u} \nabla_{\partial_v} \partial_u - \nabla_{\partial_v} \nabla_{\partial_u} \partial_u, \partial_v).
\]
Note that the commutator term \([\partial_u, \partial_v]\) vanishes for coordinate vector fields.

Now we compute
#+BEGIN_latex
\[
\begin{split}
\nabla_{\partial_u} \nabla_{\partial_v} \partial_u &= \nabla_{\partial_u} (\Gamma_{vu}^k \partial_k) \\
&= (\partial_u \Gamma_{vu}^k) \partial_k + \Gamma_{vu}^k \Gamma_{uk}^l \partial_l \\
&= (\partial_u \Gamma_{vu}^k + \Gamma_{vu}^m \Gamma_{um}^k) \partial_k.
\end{split}
\]
#+END_latex

Likewise
\[
\nabla_{\partial_v} \nabla_{\partial_u} \partial_u = (\partial_v \Gamma_{uu}^k + \Gamma_{uu}^m \Gamma_{vm}^k) \partial_k.
\]

Thus
#+BEGIN_latex
\[
\begin{split}
{\Rm_{uvu}}^k &= \partial_u \Gamma_{vu}^k + \Gamma_{vu}^m \Gamma_{um}^k - \partial_v \Gamma_{uu}^k - \Gamma_{uu}^m \Gamma_{vm}^k \\
&= \partial_u \Gamma_{vu}^k - \partial_v \Gamma_{uu}^k + \Gamma_{vu}^m \Gamma_{um}^k - \Gamma_{uu}^m \Gamma_{vm}^k
\end{split}
\]
#+END_latex
and
\[
\Rm_{uvuv} = g_{vk} {\Rm_{uvu}}^k = g_{vk} \left(\partial_u \Gamma_{vu}^k - \partial_v \Gamma_{uu}^k + \Gamma_{vu}^m \Gamma_{um}^k - \Gamma_{uu}^m \Gamma_{vm}^k\right).
\]

Finally, one can substitute the expression for \(\Gamma_{ij}^k\) in terms of the expression to obtain an expression for \(\Rm\) in terms of the metric only. This is rather more tedious than the preceding tedious computations so we omit it. In principle, we can obtain an expression for \(\Rm\) involving only \(g\) thus showing it is intrinsic.

Let us just note that \(\Gamma_{ij}^k\) involves derivatives of the metric and the curvature tensor involves derivatives of \(\Gamma_{ij}^k\) so the curvature tensor expression will contain terms such as
\[
\partial_i \partial_j g_{kl}.
\]
That is, \(\Rm\) involves \(g\), it's first derivatives \(\partial_i g\), and it's second derivatives \(\partial_i \partial_j g\). /Curvature is second order/.

** Covariant Derivative and Curvature of the Sphere

We work in polar coordinates
\[
F(\theta, \varphi) = (\sin\varphi\cos\theta, \sin\varphi\sin\theta, \cos\varphi).
\]

The outer, unit normal is
\[
N(\theta, \varphi) = \sin\varphi\cos\theta \partial_x + \sin\varphi\sin\theta \partial_y + \cos\varphi\partial_z.
\]

The coordinate vectors are
\[
\partial_{\theta} = -\sin\varphi \sin\theta \partial_x + \sin\varphi\cos\theta \partial_y
\]
and
\[
\partial_{\varphi} = \cos\varphi\cos\theta \partial_x + \cos\varphi\sin\theta \partial_y - \sin\varphi \partial_z.
\]

The metric is
\[
g_{\theta\theta} = \sin^2 \varphi, \quad g_{\theta\varphi} = 0, \quad g_{\varphi\varphi} = 1.
\]

*** Covariant derivative by tangential projection

The Christoffel symbols may now be computed. For example,
#+BEGIN_latex
\[
\begin{split}
D_{\partial_{\theta}} \partial_{\theta} &= D_{\partial_{\theta}} (-\sin\varphi \sin\theta \partial_x + \sin\varphi\cos\theta \partial_y) \\
&= \partial_{\theta} (-\sin\varphi \sin\theta) \partial_x + \partial_{\theta}(\sin\varphi\cos\theta) \partial_y \\
&= -\sin\varphi \cos\theta \partial_x - \sin\varphi\sin\theta \partial_y.
\end{split}
\]
#+END_latex

Projecting onto the normal (and using that \(\{\partial_x, \partial_y, \partial_z\}\) are othonormal),
#+BEGIN_latex
\[
\begin{split}
\ip{D_{\partial_{\theta}} \partial_{\theta}}{N} &= \ip{-\sin\varphi \cos\theta \partial_x - \sin\varphi\sin\theta \partial_y}{\sin\varphi\cos\theta \partial_x + \sin\varphi\sin\theta \partial_y + \cos\varphi\partial_z} \\
&= -\sin\varphi \cos\theta\sin\varphi\cos\theta - \sin\varphi\sin\theta \sin\varphi\sin\theta \\
&= -\sin^2\varphi
\end{split}
\]
#+END_latex

Therefore
#+BEGIN_latex
\[
\begin{split}
\nabla_{\partial_{\theta}} \partial_{\theta} &= D_{\partial_{\theta}} \partial_{\theta} - \ip{D_{\partial_{\theta}} \partial_{\theta}}{N} N \\
&= -\sin\varphi \cos\theta \partial_x - \sin\varphi\sin\theta \partial_y + \sin^2\varphi \left(\sin\varphi\cos\theta \partial_x + \sin\varphi\sin\theta \partial_y + \cos\varphi\partial_z\right) \\
&= (\sin^2\varphi -1) \sin\varphi\cos\theta \partial_x + (\sin^2\varphi -1) \sin\varphi\sin\theta \partial_y + \sin^2\varphi \cos\varphi \partial_z \\
&= -\cos^2\varphi \sin\varphi\cos\theta \partial_x -\cos^2\varphi \sin\varphi\sin\theta \partial_y + \sin^2\varphi \cos\varphi \partial_z \\
&= -\cos\varphi\sin\varphi\left(\cos\varphi\cos\theta \partial_x + \cos\varphi\sin\theta \partial_y - \sin\varphi \partial_z\right) \\
&= -\cos\varphi\sin\varphi \partial_{\varphi}.
\end{split}
\]
#+END_latex

Thus
\begin{align*}
\Gamma_{\theta\theta}^{\theta} &= 0 \\
\Gamma_{\theta\theta}^{\varphi} &= -\cos\varphi\sin\varphi.
\end{align*}

The other Christoffel symbols are computed similarly.

*** Covariant derivative from the metric

Alternatively, one may use the expression for the Christoffel symbols in terms of the metric
\[
\Gamma_{ij}^k = \frac{1}{2} g^{kl} (\partial_i g_{jl} + \partial_j g_{il} - \partial_l g_{ij}).
\]

For this we require the inverse metric
\[
g^{\theta\theta} = \frac{1}{\sin^2\varphi}, \quad g^{\theta\varphi} = 0, \quad g^{\varphi\varphi} = 1.
\]

For example,
\[
\Gamma_{\varphi\varphi}^{\theta} = \frac{1}{2} g^{\theta l} (\partial_{\varphi} g_{\varphi l} + \partial_{\varphi} g_{\varphi l} - \partial_l g_{\varphi\varphi}).
\]

There is a sum over \(l = \varphi, \theta\) but \(g^{\theta \varphi} = 0\) and so
\[
\Gamma_{\varphi\varphi}^{\theta} = \frac{1}{2} g^{\theta\theta} (\partial_{\varphi} g_{\varphi\theta} + \partial_{\varphi} g_{\varphi\theta} - \partial_{\theta} g_{\varphi\varphi}) = 0
\]
since \(g_{\varphi\theta} = 0\) and \(g_{\varphi\varphi} = 1\).

More interestingly
#+BEGIN_latex
\[
\begin{split}
\Gamma_{\varphi\theta}^{\theta} &= \frac{1}{2} g^{\theta\theta} (\partial_{\varphi} g_{\theta\theta} + \partial_{\theta} g_{\varphi\theta} - \partial_{\theta} g_{\varphi\theta}) \\
&= \frac{1}{2} \sin^{-2}\varphi (\partial_{\varphi} \sin^2 \varphi) \\
&= \frac{1}{2} \sin^{-2}\varphi 2\sin \varphi\cos\varphi) \\
&= \frac{\cos\varphi}{\sin\varphi} \\
&= \cot \varphi
\end{split}
\]
#+END_latex

*** Curvature from the Covariant Derivative

It's now possible to compute the curvature from the Christoffel symbols. We only need compute
\[
\Rm(\partial_{\theta}, \partial_{\varphi}) \partial_{\theta} = \nabla_{\partial_{\theta}} \nabla_{\partial_{\varphi}} \partial_{\theta} - \nabla_{\partial_{\varphi}} \nabla_{\partial_{\theta}} \partial_{\theta}
\]

Our Christoffel symbols are
\begin{align*}
\Gamma_{\theta\theta}^{\varphi} &= -\cos\varphi\sin\varphi \\
\Gamma_{\theta\varphi}^{\theta} &= \Gamma_{\varphi\theta}^{\theta} = \cot \varphi.
\end{align*}
All remaining Christoffel symbols vanish.

Then we have
#+BEGIN_latex
\[
\begin{split}
\nabla_{\partial_{\theta}} \nabla_{\partial_{\varphi}} \partial_{\theta} &= \nabla_{\partial_{\theta}}  \left(\Gamma_{\varphi\theta}^{\theta} \partial_{\theta} + \Gamma_{\varphi\theta}^{\varphi} \partial_{\varphi}\right) \\
&= \nabla_{\partial_{\theta}}  \left(\cot\varphi\partial_{\theta}\right) \\
&= -\cot\varphi\cos\varphi\sin\varphi \partial_{\varphi} \\
&= -\cos^2 \varphi \partial_{\varphi}
\end{split}
\]
#+END_latex

The other term is
#+BEGIN_latex
\[
\begin{split}
\nabla_{\partial_{\varphi}} \nabla_{\partial_{\theta}} \partial_{\theta} &= \nabla_{\partial_{\varphi}} \left(\Gamma_{\theta\theta}^{\theta} \partial_{\theta} + \Gamma_{\theta\theta}^{\varphi} \partial_{\varphi}\right) \\
&= -\nabla_{\partial_{\varphi}}  \left(\cos\varphi\sin\varphi\partial_{\varphi}\right) \\
&= -\left(-\sin^2\varphi + \cos^2\varphi\right)\partial_{\varphi}
\end{split}
\]
#+END_latex

Therefore
\[
\Rm(\partial_{\theta}, \partial_{\varphi}) \partial_{\theta} = -\cos^2 \varphi \partial_{\varphi} + \left(-\sin^2\varphi + \cos^2\varphi\right)\partial_{\varphi} = - \sin^2\varphi \partial_{\varphi}
\]
and
\[
g(\Rm(\partial_{\theta}, \partial_{\varphi}) \partial_{\theta}, \partial_{\varphi}) = -\sin^2\varphi g(\partial_{\varphi}, \partial_{\varphi}) = -\sin^2 \varphi.
\]

The Gauss curvature is
\[
K = \frac{g(\Rm(\partial_{\theta}, \partial_{\varphi}) \partial_{\theta}, \partial_{\varphi})}{g_{\theta\varphi}^2 - g_{\theta\theta}g_{\varphi\varphi}} = \frac{-\sin^2\varphi}{-\sin^2\varphi} = 1.
\]

*** Curvature From the Gauss Equation

It's considerably easier to compute the curvature tensor of the sphere from the Gauss equation. Recall that for \(x \in \sphere^2\),
\[
N(x) = -x
\]
and hence
\[
\mathcal{W} = -dN = \operatorname{Id}
\]
as well as
\[
A(X, Y) = g(\mathcal{W}(X), Y) = g(X, Y).
\]
That is,
\[
A = g.
\]

The Gauss curvature can be computed easily in terms of \(A\) and \(g\)
\[
K = \frac{\det A}{\det g} = \frac{\det g}{\det g} = 1.
\]
Even better is to compute directly
\[
K = \det \mathcal{W} = \det\operatorname{Id} = 1.
\]

For the curvature tensor, by using the Gauss equation we obtain
#+BEGIN_latex
\[
\begin{split}
g(\Rm(X, Y) Z, W) &= A(X, W) A(Y, Z) - A(X, Z) A(Y, W) \\
&= g(X, W) g(Y, Z) - g(X, Z) g(Y, W).
\end{split}
\]
#+END_latex

In coordinates
#+BEGIN_latex
\[
\begin{split}
g(\Rm(\partial_{\theta}, \partial_{\varphi}) \partial_{\theta}, \partial_{\varphi}) &= g(\partial_{\theta}, \partial_{\varphi}) g(\partial_{\varphi}, \partial_{\theta}) - g(\partial_{\theta}, \partial_{\theta}) g(\partial_{\varphi}, \partial_{\varphi}) \\
&= -\sin^2\varphi
\end{split}
\]
#+END_latex
exactly as we obtained by computing with Christoffel symbols, but with considerably more ease!

*** Comparing the methods

Let us remark that the calculations given above actually work in arbitrary dimension to compute the curvature of the \(n\)-dimensional sphere:
\[
\sphere^n = \{(x_1, \dots, x_{n+1}) : x_1^2 + \cdots + x_{n+1}^2 = 1\}.
\]
In fact, no change is required when using the Gauss equation since once again \(N(x) = -x\) and we may repeat the entire argument - nothing required that we were working in \(2\) dimensions.

Computing with the Christoffel symbols however, becomes a daunting prospect in \(n\) dimensions when one considers that the Christoffel symbols have three indices each with \(n\) numbers giving \(n^3\) components! But we don't need to compute all \(n^3\) components. The symmetries of the Christoffel symbols allow us to determine the number of independent components:

For each index \(k\) there are a total of \(n^2\) pairs \(i,j\). But since \(\Gamma_{ij}^k = \Gamma_{ji}^k\) we need only count the diagonal entries \(\Gamma_{ii}^i\) (there are \(n\) of these) and half of the off diagonal entries (with \(i\ne j\)). There are \(n^2 - n = n(n-1)\) total indices with \(i\ne j\) since we just subtract the number, \(n\) of indices with \(j=i\) from the total number \(n^2\) of all indices. Adding the number of diagonal entries to half the number of off-diagonal entries, for each fixed \(k\), there are
\[
n + \frac{1}{2}n(n-1) = \frac{1}{2}n(n+1)
\]
total independent components.

This is for each \(k\), and there are \(n\) possible indices for \(k\) giving the total number of independent components as
\[
n \times \frac{1}{2}n(n+1) = \frac{1}{2}n^2(n+1) = \frac{1}{2}(n^3 + n^2).
\]
For \(n=2\) we get
\[
\frac{1}{2}(2^3 + 2^2) = \frac{1}{2}(8 + 4) = 6
\]
independent components.

The number of components grows cubically and for example, if \(n=3\) we obtain
\[
\frac{1}{2}(3^3 + 3^2) = \frac{1}{2}(27 + 9) = 18
\]
components to compute! If \(n = 4\) we obtain
\[
\frac{1}{2}(4^3 + 4^2) = \frac{1}{2}(64 + 16) = 40
\]
components to compute!

In the particular case of the sphere however, it turns out we can bootstrap the \(2\) dimensional case by use the symmetry of the sphere under rotations to compute all the components from just the two-dimensional case.

/Nevertheless, the Gauss equation is still much easier/!

Finally, let us note that similar analysis may be employed to show that the curvature tensor has
\[
\frac{1}{12}n^2(n^2 - 1)
\]
independent components. This is more involved than the Christoffel symbols computation because the symmetries are more complex.

For \(n=2\) we get
\[
\frac{1}{12}n^2(n^2 - 1) = \frac{1}{12}4(4-1) = 1.
\]
This recovers what we saw earlier - the symmetries of the curvature tensor imply that for surfaces, we only need to compute one component. This makes surfaces very special.

For \(n=3\) we get
\[
\frac{1}{12}n^2(n^2 - 1) = \frac{1}{12}9(9-1) = 6.
\]
For \(n=4\) we get
\[
\frac{1}{12}n^2(n^2 - 1) = \frac{1}{12}16(16-1) = 20.
\]

** Symmetry of the Second Fundamental Form

#+BEGIN_prop
The second fundamental form is symmetric. That is for any tangent vectors \(X, Y\),
\[
A(X, Y) = A(Y, X).
\]
#+END_prop

#+BEGIN_proof
By definition
\[
A(X, Y) = g(\mathcal{W}(X), Y) = \ip{\mathcal{W} (X)}{Y} = \ip{-dN(X)}{Y}.
\]

Using metric compatibility
\[
A(X, Y) = \ip{-dN(X)}{Y} = -\ip{D_X N}{Y} = -D_X \ip{N}{Y} + \ip{N}{D_X Y} = \ip{N}{D_X Y}.
\]
Similarly
\[
A(Y, X) = \ip{N}{D_Y X}.
\]

Thus
\[
A(X, Y) - A(Y, X) = \ip{N}{D_X Y - D_Y X} = \ip{N}{[X, Y]} = \ip{N}{\nabla_X Y - \nabla_Y X} = 0
\]
with the last equality following since both \(\nabla_X Y\) and \(\nabla_Y X\) are tangential.
#+END_proof

#+BEGIN_remark
Notice that in the proof we obtained the formula
\[
A(X, Y) = \ip{D_X Y}{N}.
\]
Recall that \(\nabla_X Y\) is the tangential projection of \(D_X Y\):
\[
\nabla_X Y = D_X Y - \ip{D_X Y}{N} N.
\]
Thus we see that
\[
\nabla_X Y = D_X Y - A(X, Y) N.
\]
In other words,
\[
D_X Y = \nabla_X Y + A(X, Y) N
\]
with \(\nabla_X Y\) the tangential part of \(D_X Y\) and \(A(X, Y)\) the normal part. Thus we could make the equivalent definition of the second fundamental form to be the normal component of \(D_X Y\).
#+END_remark

** MATH3405 Course Summary
*** Curves
- Regular curves.
- Arc-length
- Frenet frame: - curvature, torsion, normal, bi-normal
- Plane curves: orientation allows curvature to have a sign
*** Surfaces
- Parametrised surfaces
- Graphs, surfaces of revolution, regular values
- Smooth maps
- Tangent plane
- Differential of smooth maps
- Metric (first fundamental form)
- Area, length, angle
*** Curvature of Surfaces
- Orientation and Gauss map
- Second fundamental form/Weingarten shape operator
- Principal curvatures
- Normal and geodesic curvature of curves
- Mean curvature and Gauss curvature
- Umbilic points
- Elliptic, hyperbolic, parabolic, planar points
*** Intrinsic Geometry
- Isometries
- Vector fields
- Covariant Differentiation
- Parallel Transport and Geodesics
- Gauss Theorema Egregium
  - You won't be examined on the curvature tensor or on how to prove the theorem. But you should understand what it means and the implications. For the purposes of assessment, the important thing is the applications.
- Gauss-Bonnet Theorem
  - You won't be examined on how to prove this theorem either. You should understand the statements of the theorems (local and global) however, and be able to apply them. For the purposes of assessment, the important thing is the applications.
* Assignments 							   :noexport:
*** MATH3405: Assignment 3

#+BEGIN_latex
\begin{center}
\textbf{Due: 3 Oct 2017, 15:00}
\end{center}
#+END_latex

**** Notes							   :noexport:
- Due Tuesday 3rd Oct, Week 10
- Topics Weeks 7-9
  - Orientation
  - SFF and Shape
  - Various curvatures
  - Local Taylor Approximation
**** The Gauss Map of a Closed Surface
\label{q:gauss_map}

A closed surface \(S \subseteq \RR^3\) is a regular surface such that
1. $S$ is a closed subset of \(\RR^3\),
2. $S$ is bounded: there exists an \(R > 0\) such that
\[
S \subseteq B_R(0) = \{x^2 + y^2 + z^2 \leq R^2\}.
\]

Prove that the Gauss map of a closed, oriented surface (compact, no boundary) $S$ is surjective as follows:

a. Suppose there is a plane $P$ intersecting $S$ at $x_0$ such that in an open neighbourhood $V\subset S$ of $x_0$, $S$ lies on one side of $P$, i.e. for $x\in V$ we have $\ip{x - x_0}{\nor} \geq 0$ where $\nor$ is the normal vector to $P$. Prove that $P$ is the tangent plane to $S$ at $x_0$. \label{itm:GM_a}

   \hfill\textbf{[5]}

   /Hint/: In a local parametrisation $\phi: U \to V$, the function $f(u,v) = \ip{\phi(u,v)-x_0}{\nor}$ has a local minimum at $(u_0, v_0) = \phi^{-1}(x_0)$.  Hence the first derivative test implies that $\pd{u} f = \pd{v} f = 0$. Now what are the coordinate tangent vectors at $(u_0,v_0)$?

   #+BEGIN_tcolorbox
   *Solution*

   We have
   \[
   0 = \partial_u f = \ip{\phi_u}{\nor} \text{ and } 0 = \partial_v f = \ip{\phi_v}{\nor}.
   \]
   \hfill\textbf{[3]}

   Therefore \(\phi_u, \phi_v \in P\). But \(\phi_u, \phi_v\) span \(T_{x_0} S\), and hence \(T_{x_0} S = P\).    \hfill\textbf{[2]}
   #+END_tcolorbox

b. Using the definition of closed surface above, show that for any unit vector $\nor\in \RR^3$, there exists a plane $P$ with unit normal vector $\nor$ such that $P \cap S = \emptyset$. \label{itm:GM_b}

   \hfill\textbf{[3]}

   #+BEGIN_tcolorbox
   *Solution*

   We can take for example the tangent plane to \(\sphere^2(R) = \partial B_R(0)\) at the point \(R\nor \in \sphere^2(R)\).

   \hfill\textbf{[3]}
   #+END_tcolorbox

c. Let \(P\) be the plane from part \ref{itm:GM_b}. Consider the map
   \[
   \Phi(t, Z) = Z + t \nor, t \in \RR, Z \in P.
   \]
   Then for each \(t_0 \in \RR\), \(P(t) = \{\Phi(t_0, Z) : Z \in P\}\) is a plane and \(P(0) = P\).

   Show that there exists a \(t_0 \in \RR\) such that $P(t_0) \cap S \ne \emptyset$ and $S$ lies on one side of $P(t_0)$. That is, letting \(x_0 \in P(t_0) \cap S\), either for every \(x \in S\), \(\ip{x - x_0}{\nor} \geq 0\) or for every \(x \in S\), \(\ip{x - x_0}{\nor} \leq 0\). \label{itm:GM_c}

   \hfill\textbf{[5]}

   #+BEGIN_tcolorbox
   *Solution*

   We have \(P(0) \intersect S = \emptyset\) and \(\RR^3 = \union_{t \in \RR} P(t)\) so that \(\{t : P(t) \intersect S \neq \emptyset\} \neq \emptyset\). \hfill\textbf{[1]}

   Without loss of generality, assume that \(P(t) \intersect S \neq \emptyset\) for some \(t > 0\). Let \(t_0 = \inf\{t > 0 : P(t) \neq \emptyset\}\).

   Then \(t_0\) will be our desired \(t\) provided the set \(X = \{t: P(t) = \emptyset\}\) is open: in that case \(t_0 \notin X\) because otherwise we would have \((t - \epsilon, t + \epsilon) \subseteq X\) contradicting the definition of the infimum. Moreover, by definition of the infimum, \(P(t) \cap S = \emptyset\) for \(0 < t < t_0\). But then \(S\) lies on the side of \(P(t_0)\) with \(t > t_0\).

   To get openness, just observe that if \(S \cap P(t_1) = \emptyset\), then \(|x - Z| \geq \epsilon > 0\) for all \(x \in S\) and \(Z \in P(t_1)\) and some \(\epsilon > 0\). Therefore, \(\|x - Z| \geq \epsilon/2\) for all \(x \in S\) and all \(Z \in P(t)\) for \(t \in (t_1 -\delta, t_1 + \delta)\) and some \(\delta > 0\) depending on \(\epsilon\) and \(S\).

   \hfill\textbf{[3]}
   #+END_tcolorbox


d. Using part \ref{itm:GM_a} conclude that the plane from part \ref{itm:GM_c}. is the tangent plane at \(x_0\) and hence \(N(x_0) = \nor\), and hence the Gauss map is surjective. \label{itm:GM_d}

   \hfill\textbf{[3]}

   #+BEGIN_tcolorbox
   *Solution*

   The plane from part \ref{itm:GM_c} satisfies the requirements of part \ref{itm:GM_a} hence is the tangent plane. \hfill\textbf{[1]}

   But then the unit normal to \(S\) at \(x_0\) is by definition the normal to the tangent plane which equals the plane from part \ref{itm:GM_c}. Thus the unit normal at \(x_0\) is the normal to the plane. That is, for any \(\nor\), there exists an \(x_0\) such that \(N(x_0) = \nor\) as required.

   \hfill\textbf{[2]}
   #+END_tcolorbox


e. Prove that the Gauss curvature $\gausscurv \geq 0$ at the point of intersection \(x_0\) of $P$ with $S$ from part \ref{itm:GM_a}. /Hint/: Show it's not a hyperbolic point. \label{itm:GM_e}

   \hfill\textbf{[4]}


   #+BEGIN_tcolorbox
   *Solution*

   By construction the surface \(S\) lies on one side of the tangent plane \(T_{x_0} S\). \hfill\textbf{[2]}

   If \(K < 0\), we have a hyperbolic point, but at such points \(S\) does not lie on one side of \(T_{x_0} S\). Thus \(K \geq 0\). \hfill\textbf{[2]}
   #+END_tcolorbox

**** Surfaces of Revolution
\label{q:surf_rev}

Let $f: \RR \to \RR$ be a strictly positive function with continuous second derivative and let $S$ be the surface of revolution parameterized locally by
   \[
   x(z,\theta) = (f(z) \cos\theta, f(z) \sin\theta, z).
   \]

For all the following calculations, leave your answer in terms of $f,f',f''$.

a. Show that the matrix representation of $g$ in these coordinates is
   \[
   g = \begin{pmatrix}
   1 + (f')^2 & 0 \\
   0 & f^2
   \end{pmatrix}.
   \]

   \hfill\textbf{[4]}

   #+BEGIN_tcolorbox
   *Solution*

   We have
   \[
   x_z = (f'(z) \cos\theta, f'(z) \sin\theta, 1), \quad x_{\theta} = (-f(z) \sin\theta, f(z) \cos\theta, 0).
   \]
   \hfill\textbf{[1]}

   Then we just compute
   \[
   g_{zz} = \ip{x_z}{x_z} = (f')^2 \cos^2\theta + (f')^2 \sin^2 \theta + 1 = 1 + (f')^2
   \]
   \hfill\textbf{[1]}
   \[
   g_{z\theta} = \ip{x_z}{x_{\theta}} = -ff' \cos\theta \sin\theta + ff' \sin\theta\cos\theta = 0.
   \]
   \hfill\textbf{[1]}
   \[
   g_{\theta\theta} = \ip{x_{\theta}}{x_{\theta}} = f^2 \sin^2\theta + f^2 \cos^2\theta = f^2
   \]
   \hfill\textbf{[1]}
   #+END_tcolorbox

b. Show that the matrix representation and $A$ in these coordinates is
   \[
   A = \pm \frac{1}{\sqrt{1 + (f')^2}} \begin{pmatrix}
   -f'' & 0 \\
   0 & f
   \end{pmatrix}
   \]
   and that the matrix representation of $dN$ is
   \[
   dN = \pm \frac{1}{\sqrt{1+(f')^2}} \begin{pmatrix}
   \frac{f''}{1+(f')^2} & 0 \\
   0 & \frac{-1}{f}
   \end{pmatrix}.
   \]
   where \(\pm\) depends on your chosen orientation.

   \hfill\textbf{[4]}

   #+BEGIN_tcolorbox
   *Solution*

   We have
   \[
   N = \pm \frac{1}{\sqrt{1 + (f')^2}} (-\cos\theta, -\sin\theta, f')
   \]
   \hfill\textbf{[1]}

   Then
   #+BEGIN_latex
   \[
   \begin{split}
   N_z &= \pm \left[\frac{f'f''}{(1 + (f')^2)^{3/2}} (\cos\theta, \sin\theta, -f') \right. \\
   &\quad + \left.\frac{1}{\sqrt{1 + (f')^2}} (0, 0, f'')\right] \\
   &= \pm \frac{f''}{\sqrt{1 + (f')^2}} x_z
   \end{split}
   \]
   #+END_latex
   \[
   N_{\theta} = \pm \frac{1}{\sqrt{1 + (f')^2}} (-\sin\theta, \cos\theta, 0) = \mp \frac{1}{\sqrt{1 + (f')^2}} \frac{1}{f} x_{\theta}
   \]
   \hfill\textbf{[1.5]}

   \[
   A(x_z, x_z) = -g(N_z, x_z) = \pm \frac{-f''}{(1 + (f')^2)^{3/2}} g_{zz} = \pm \frac{-f''}{\sqrt{1 + (f')^2}}
   \]
   \[
   A(x_z, x_{\theta}) = -g(N_{\theta}, x_z) = \mp \frac{1}{\sqrt{1 + (f')^2}} \frac{1}{f} x_{\theta} g_{z\theta} = 0.
   \]
   \[
   A(x_{\theta}, x_{\theta}) = -g(N_{\theta}, x_{\theta}) = \pm \frac{1}{\sqrt{1 + (f')^2}} \frac{1}{f} x_{\theta}g_{\theta\theta} = \pm \frac{f}{\sqrt{1 + (f')^2}}.
   \]

   \hfill\textbf{[1.5]}
   #+END_tcolorbox


c. Show that $(1,0)$ and $(0,1)$ are eigenvectors of $dN$ and show that the corresponding eigenvalues are
   \[
   k_1 = \tfrac{f''}{(1+(f')^2)^{3/2}}, \quad k_2 = \tfrac{-1}{f\sqrt{1+(f')^2}}.
   \]

   \hfill\textbf{[2]}

   #+BEGIN_tcolorbox
   *Solution*

   The matrix \(dN\) is diagonal so the eigenvalues are precisely the diagonal entries of \(dN\).
   \hfill\textbf{[2]}
   #+END_tcolorbox

d. Calculate $H,K$.

   \hfill\textbf{[4]}

   #+BEGIN_tcolorbox
   *Solution*

   \[
   H = \frac{1}{2} (\kappa_1 + \kappa_2) = \frac{1}{2}\left(\tfrac{f''}{(1+(f')^2)^{3/2}} + \tfrac{-1}{f\sqrt{1+(f')^2}}\right) = \frac{ff'' - (f')^2 - 1}{2f(1 + (f')^2)^{3/2}}
   \]

   \hfill\textbf{[2]}

   \[
   K = \kappa_1 \kappa_2) = \tfrac{f''}{(1+(f')^2)^{3/2}} \tfrac{-1}{f\sqrt{1+(f')^2}} = \tfrac{-f''}{f(1+(f')^2)^2}.
   \]

   \hfill\textbf{[2]}

   #+END_tcolorbox


e. Show that $K \equiv 0$ if and only if $f(z) = az + b$ for some $a,b\in\RR$.

   \hfill\textbf{[2]}

   #+BEGIN_tcolorbox
   *Solution*

   From the formula for \(K\), \(K \equiv 0\) if and only if \(f'' = 0\) if and only if \(f(z) = a z + b\).
   \hfill\textbf{[2]}
   #+END_tcolorbox

**** Constant Curvature Spaces

1. Let \(P \subset \RR^3\) be a plane. Show that \(dN \equiv 0\) and conclude that \(K \equiv 0\).

   \hfill\textbf{[2]}

   #+BEGIN_tcolorbox
   *Solution*

   A plane always has \(N(x) \equiv N_0\) is constant, hence \(dN \equiv 0\) hence \(K = \det 0 = 0\).

   \hfill\textbf{[2]}
   #+END_tcolorbox


2. The sphere is the surface of revolution given by
   \[
   f(z) = \sqrt{1 - z^2}.
   \]
   Using the formulae from \ref{q:surf_rev}, show that \(K \equiv 1\).

   \hfill\textbf{[8]}

   #+BEGIN_tcolorbox
   *Solution*

   \[
   f'(z) = \frac{-z}{\sqrt{1-z^2}}
   \]   
   \hfill\textbf{[1]}

   \[
   f''(z) = \frac{-1}{\sqrt{(1-z^2}} - \frac{z^2}{(1-z^2)^{3/2}} = \frac{-1}{(1-z^2)^{3/2}}
   \]
   \hfill\textbf{[1]}

   The formula for \(K\) is:
   \[
   K = \tfrac{-f''}{f(1+(f')^2)^2}.
   \]
   \hfill\textbf{[2]}

   \[
   f(1 + (f')^2)^2 = \sqrt{1-z^2} \frac{1}{(1-z^2)^2} = \frac{1}{(1-z^2)^{3/2}}.
   \]
   \hfill\textbf{[2]}

   \[
   K = \frac{-f''}{f(1+(f')^2)^2} = \frac{1}{(1-z^2)^{3/2}} (1-z^2)^{3/2} = 1.
   \]

   \hfill\textbf{[2]}
   #+END_tcolorbox


3. The psuedo-sphere is more easily expressed as the surface of revolution given by
   \[
   \varphi(z, \theta) = (\sech (z) \cos(\theta), \sech(z) \sin(\theta), z - \tanh(z)), \quad 0 \leq \theta < 2\pi, -\infty < z < \infty
   \]
   Adapting the formulae from \ref{q:surf_rev}, show that \(K \equiv -1\).

   \hfill\textbf{[10]}

   #+BEGIN_tcolorbox
   *Solution*

   We have
   \begin{align*}
   \varphi_z &= \left(-\cos(\theta) \sech (z) \tanh (z),\, -\sech(z) \sin(\theta) \tanh(z),\, \tanh(z)^2\right) \\
   \varphi_{\theta} &= \left(-\sech(z) \sin(\theta),\, \cos(\theta) \operatorname{sech}(z), \,0\right)
   \end{align*}
   and
   \begin{align*}
   \varphi_{zz} &= \left(\cos\left(\theta\right) \sech\left(z\right)(\tanh^2(z) - \sech^2(z)),\right. \\
   &\quad \left.\sin(\theta) \sech\left(z\right)(\tanh^2(z) - \sech^2(z)),\, 2 \sech^2(z) \tanh\left(z\right)\right) \\
   \varphi_{z\theta} &= \left(\operatorname{sech}\left(z\right) \sin\left(\theta\right) \tanh\left(z\right),\,-\cos\left(\theta\right) \operatorname{sech}\left(z\right) \tanh\left(z\right),\,0\right) \\
   \varphi_{\theta\theta} &= \left(-\cos\left(\theta\right) \operatorname{sech}\left(z\right),\,-\operatorname{sech}\left(z\right) \sin\left(\theta\right),\,0\right)
   \end{align*}
   \hfill\textbf{[2]}

   The metric is
   \[
   g = \begin{pmatrix}
   \tanh(z)^2 & 0 \\
   0 & \sech(z)^2
   \end{pmatrix}
   \]

   \hfill\textbf{[2]}

   The normal is
   \[
   N = \frac{\varphi_z \times \varphi_{\theta}}{\|\varphi_z \times \varphi_{\theta}\|} = \left(-\cos\left(\theta\right) \tanh\left(z\right),\,-\sin\left(\theta\right) \tanh\left(z\right),\,-\operatorname{sech}\left(z\right)\right)
   \]

   \hfill\textbf{[2]}

   The second fundamental form (e.g. by the formula \(A_{ij} = g(\partial^2_{ij} \varphi, N)\)) is
   \[
   A = \begin{pmatrix}
   -\operatorname{sech}\left(z\right) \tanh\left(z\right) & 0 \\
   0 & \operatorname{sech}\left(z\right) \tanh\left(z\right)
   \end{pmatrix}
   \]

   \hfill\textbf{[2]}

   The Gauss curvature is
   \[
   K = \det (g^{-1} A) = \frac{\det A}{\det g} = \frac{-\sech^2(z) \tanh^2(z)}{\tanh^2(z) \sech^2(z)} = -1
   \]

   \hfill\textbf{[2]}
   #+END_tcolorbox

*** MATH3405: Assignment 4

#+BEGIN_latex
\begin{center}
\textbf{Due: 26 Oct 2017, 15:00}
\end{center}
#+END_latex

**** Frenet-Serret Equations on an Oriented Surface

Let \(S\) be an oriented, regular surface with unit normal \(\nu\), metric \(g\), and covariant derivative \(\nabla\). Let \(\gamma : (a, b) \to S\) be a /regular curve/. That is \(\gamma'(t) \ne 0\) for all \(t \in (a, b)\). Let \(T = \tfrac{\gamma'}{\abs{\gamma'}_g}\) be the unit tangent vector to \(\gamma\).


a. Show that \(N = \nu \times T\) is tangent to \(S\) and \(g\) orthogonal to \(T\). Thus \(N\) is the intrinsic, oriented unit normal to \(\gamma\).

   #+BEGIN_soln
   \(\nu \times T\) is orthogonal in \(\RR^3\) to \(\nu\) hence is tangent.

   \(\nu \times T\) is orthogonal in \(\RR^3\) to \(T\) and hence (since \(\nu \times T\) is tangent) \(g(\nu \times T, T) = \ip{\nu \times T}{T} = 0\).
   #+END_soln

   \hfill\textbf{[2]}

b. Show that \(\{T, N, \nu\}\) is positively oriented - that is, it satisfies the right hand rule, \(\nu = T \times N\).

   #+BEGIN_soln
   For arbitrary linearly independent vectors \(T, \nu\), we always have \(\{T, \nu \times T, \nu\}\) is right handed since \(\{\nu, T, \nu \times T\}\) is right handed.
   #+END_soln

   \hfill\textbf{[2]}

c. Using metric compatibility and the fact that \(\abs{T}_g = 1\) show that
   \[
   g(\nabla_T T, T) = 0.
   \]

   #+BEGIN_soln
   \[
   0 = \nabla_T 1 = \nabla_T g(T, T) = 2 g(\nabla_T T, T).
   \]
   #+END_soln

   \hfill\textbf{[2]}

d. Define the /geodesic curvature/ \(\kappa = g(\nabla_T T, N)\). Verify the Frenet-Serret equations
   #+BEGIN_latex
   \[
   \begin{pmatrix}
   \nabla_T T \\
   \nabla_T N
   \end{pmatrix}
   =
   \begin{pmatrix}
   0 & \kappa \\
   -\kappa & 0
   \end{pmatrix}
   \begin{pmatrix}
   T \\
   N
   \end{pmatrix}.
   \]
   #+END_latex

   #+BEGIN_soln
   From the previous question, \(\nabla_T T = \kappa N\).

   Next,
   \[
   0 = \nabla_T 1 = \nabla_T g(N, N) = 2 g(\nabla_T N, N)
   \]
   so that \(\nabla_T N = \lambda T\) for some \(\lambda\).
   \hfill\textbf{[2]}

   To compute \(\lambda\) we have
   #+BEGIN_latex
   \[
   \begin{split}
   0 &= \nabla_T 0 = \nabla_T g(T, N) = g(\nabla_T T, N) + g(T, \nabla_T N) \\
   &= g(\kappa N, N) + g(T, \lambda T) = \kappa + \lambda.
   \end{split}
   \]
   #+END_latex
   \hfill\textbf{[2]}
   #+END_soln

   \hfill\textbf{[4]}

e. Let \(\kappa_{\RR^3}\) be the curvature of \(\gamma\) though of as a curve in \(\RR^3\) and let \(\kappa_{\nu} = A(T, T)\) be the normal curvature of \(\gamma\). Show that
   \[
   \kappa_{\RR^3}^2 = \kappa^2 + \kappa_{\nu}^2.
   \]

   /Hint/: Use the definition of \(\nabla\): \(\nabla_X Y = D_X Y - \ip{D_X Y}{\nu}\nu\).

   #+BEGIN_soln
   Since \(g(T, T) = \ip{T}{T} = 1\) we have
   \[
   D_T T = \kappa N_{\RR^3}.
   \]
   \hfill\textbf{[1]}

   We have
   \[
   \kappa_{\RR^3} N_{\RR^3} = D_T T = \nabla_T T + A(T, T) \nu = \kappa N + \kappa_{\nu} \nu.
   \]
   \hfill\textbf{[2]}

   To finish, observe that since \(\nu \perp N\) and all of \(N_{\RR^3}, \nu, N\) are unit length we have,
   \[
   \kappa_{\RR^3}^2 = \abs{\kappa_{\RR^3} N_{\RR^3}}^2 + \abs{\kappa N}^2 + \abs{\kappa_{\nu} \nu}^2 = \kappa^2 + \kappa_{\nu}^2.
   \]

   \hfill\textbf{[2]}
   #+END_soln

   \hfill\textbf{[5]}

**** Geodesics

Retain the notation of the Frenet-Serret question for \(S, \nu, \gamma, T, N, \kappa\). Recall a geodesic is a curve with zero acceleration \(\nabla_{\gamma'} \gamma' \equiv 0\).

1. Using metric compatibility, show that if \(Y\) is a parallel vector field along a geodesic \(\gamma\), then
   \[
   g(\gamma', Y) \text{ and } \abs{Y}_g
   \]
   are constant.

   #+BEGIN_soln
   We have
   \[
   \nabla_{\gamma'} g(\gamma', Y) = g(\nabla_{\gamma'} \gamma', Y) + g(\gamma', \nabla_{\gamma'} Y) = 0
   \]
   so \(g(\gamma', Y)\) is constant. Likewise
   \[
   \nabla_{\gamma'} g(Y, Y) = 2g(\nabla_{\gamma'} Y, Y) = 0.
   \]
   #+END_soln

   \hfill\textbf{[2]}

   Conclude that geodesics always have constant speed \(\abs{\gamma'}_g\).

   #+BEGIN_soln
   Along a geodesic \(Y = \gamma'\) is parallel and the previous part applies.
   #+END_soln

   \hfill\textbf{[2]}

2. Prove that \(\gamma\) is a geodesic if and only if \(D_T T\) is normal to \(S\) if and only if \(\kappa \equiv 0\).

   #+BEGIN_soln
   \(\gamma\) is a geodesic if and only if
   \[
   0 = \nabla_{\gamma'} \gamma' = D_{\gamma'} \gamma' - \ip{D_{\gamma'} \gamma'}{\nu} \nu
   \]
   if and only if
   \[
   D_{\gamma'} \gamma' = \ip{D_{\gamma'} \gamma'}{\nu}\nu
   \]
   if and only if \(D_{\gamma'} \gamma'\) is normal.

   The equivalence with \(\kappa = 0\) follows from
   \[
   \nabla_T T = \kappa N.
   \]
   #+END_soln

   \hfill\textbf{[2]}

3. Let \(\gamma = P \cap \sphere^2\) where \(P\) is a plane in \(\RR^3\) through the origin. Prove that \(\gamma\) is a geodesic.

   #+BEGIN_soln
   \(\gamma\) is equal to the unit circle in the plane \(P\). In that case \(D_T T = \nu\) and so the previous question applies.
   #+END_soln

   \hfill\textbf{[2]}

   Conversely, let \(\gamma\) be a geodesic on the sphere \(\sphere^2\). Prove that \(\gamma\) is the intersection of \(\sphere^2\) with a plane through the origin.

   /Hint/: Use the existence and uniqueness theorem.

   #+BEGIN_soln
   Pick any \(t_0\) and let \(V = \gamma'(t_0)\). Let \(P\) be the plane through the origin spanned by \(\gamma(t_0)\) and \(\gamma'(t_0)\). Note this is indeed a plane since \(\gamma(t_0)\) is a point on the sphere, and hence normal to the sphere while \(\gamma'(t_0)\) is tangent to the sphere. Then from the previous part, \(P \cap \sphere^2\) is also a geodesic through \(\gamma(t_0)\) and with tangent vector \(\gamma'(t_0)\). Uniqueness ensures that \(\gamma = P \cap \sphere^2\).
   #+END_soln

   \hfill\textbf{[2]}

**** Geodesics and Length					   :noexport:

Let \(\gamma\) be a curve on a regular surface \(S\) defined for \(t \in (a, b)\). Suppose there exists a function \(\varphi = \varphi(t, s) : (a, b) \times (-\epsilon, \epsilon) \to S\) for some \(\epsilon > 0\) and such that
\[
\varphi(t, 0) = \gamma(t), \quad \forall t \in (a, b).
\]
Such a function is called a /variation/ of \(\gamma\). Write \(T = d\varphi(\partial_t) = \partial_t \varphi\), \(V = d\varphi(\partial_s) = \partial_s \varphi\). Assume that \(\gamma\) is parametrised by arc length so that \(1 = \abs{\gamma'(t)} = \abs{T(t, 0)}\). We /don't/ assume that \(\abs{T(t, s)} = 1\) for \(s \ne 0\).

1. Show that
   \[
   \nabla_T V = \nabla_V T.
   \]

   /Hint/: Use the formula \(\nabla_T V - \nabla_V T = [T, V]\) and that effectively \(T = \partial_t\) and \(V = \partial_s\).

   #+BEGIN_soln
   Let \(f : S \to \RR\) be  a smooth function. Then
   \[
   Tf = df(T) = \partial_t f \circ \varphi.
   \]
   Likewise for \(Vf\).

   Then
   \[
   [T, V] = T(V(f)) - V(T(f)) = \partial_t \partial_s f \circ \varphi - \partial_s \partial_t f\circ\varphi = 0.
   \]

   Therefore,
   \[
   \nabla_T V - \nabla_V T = [T, V] = 0.
   \]
   #+END_soln

   \hfill\textbf{[2]}

2. Show that for \(s = 0\),
   \[
   \nabla_{V_0} \abs{T_0} = \frac{\partial}{\partial t} g(V_0, T_0) - \kappa g(V_0, N)
   \]
   where \(T_0(t) = T(t, 0)\) is the unit tangent vector to \(\gamma\) and \(V_0(t) = V(t, 0)\) is the variation vector \(V\) restricted to \(s = 0\) - i.e. along \(\gamma\).

   #+BEGIN_soln
   #+BEGIN_latex
   \[
   \begin{split}
   \nabla_V \abs{T} &= \partial_s \sqrt{g(T, T)} = \frac{1}{\sqrt{g(T, T)}} g(\nabla_V T, T) \\
   &= \frac{1}{\sqrt{g(T, T)}} g(\nabla_T V, T)
   \end{split}
   \]
   #+END_latex
   by the previous part.

   \hfill\textbf{[2]}

   Now we just reverse the process and use that \(\abs{T_0} = 1\). At \(s=0\),
   #+BEGIN_latex
   \[
   \begin{split}
   \nabla_{V_0} \abs{T_0} &= g(\nabla_{T_0} V_0, T_0) \\
   &= \partial_t g(V_0, T_0) - g(T_0, \nabla_{T_0} T_0) \\
   &= \partial_t g(V_0, T_0) - \kappa g(V_0, N_0).
   \end{split}
   \]
   #+END_latex

   \hfill\textbf{[2]}
   #+END_soln

   \hfill\textbf{[4]}

3. Integrate the previous formula to conclude that
   \[
   \partial_s|_{s=0} L[\gamma_s] = g(T_0, V_0)|_{t=a}^{t=b} - \int_a^b \kappa g(V_0, N_0) dt
   \]
   where for each fixed \(s\), \(\gamma_s\) is the curve
   \[
   \gamma_s(t) = \varphi(t, s).
   \]

   /Hint/: You may freely differentiate under the integral sign since we are integrating over a closed and bounded interval.

   #+BEGIN_soln
   \[
   \partial_s L[\gamma_s] = \partial_s \int_a^b \abs{T} dt = \int_a^b \partial_s \abs{T} dt
   \]

   \hfill\textbf{[2]}

   Applying the previous part,
   #+BEGIN_latex
   \[
   \begin{split}
   \partial_s L[\gamma_s] &= \int_a^b \partial_s \abs{T} dt \\
   &= \int_a^b \partial_t g(V_0, T_0) - \kappa g(V_0, N_0) dt \\
   &= g(V_0, T_0)|_a^b - \int_a^b \kappa g(V_0, N_0) dt \\
   \end{split}
   \]
   #+END_latex

   \hfill\textbf{[2]}
   #+END_soln

   \hfill\textbf{[4]}

4. Suppose that \(\varphi(a, s) = \varphi(a, 0) = \gamma(a)\) and \(\varphi(b, s) = \varphi(b, 0) = \gamma(0)\) for all \(s\). That is \(\gamma_s(a) = \gamma(a), \gamma(b) = \gamma_s(b)\). We say \(\varphi\) fixes the endpoints of \(\gamma\).

   Show that in this case,
   \[
   \partial_s|_{s=0} L[\gamma_s] = - \int_a^b g(V_0, \nabla_{T_0} T_0) dt
   \]

   #+BEGIN_soln
   If \(\varphi(a, s) = \varphi(a, 0)\) for all \(s\), then
   \[
   V(a, s) = \partial_s \varphi(a, s) = 0
   \]
   and like wise \(V(b, s) = 0\).

   So the boundary term in the previous part vanishes.
   #+END_soln

   \hfill\textbf{[2]}

5. Conclude that the critical points of the length functional with fixed end points - i.e. those curves \(\gamma\) such that \(\partial_s|_{s=0} L[\gamma_s] = 0\) for all variations \(\varphi\) - must be geodesics.

   /Hint/: You may assume that given any \(V_0\) a vector field along \(\gamma\), there exists a variation \(\varphi\) such that \(\partial_s|_{s=0} \varphi = V_0\).

   #+BEGIN_soln
   Suppose that \(\gamma\) is a critical point so that
   \[
   0 = \partial_s L[\gamma_s] = - \int_a^b \kappa g(V_0, N_0) dt
   \]
   for every \(V_0\). Then for any smooth function \(\rho\) and \(V_0 = \rho N_0\) we get
   \[
   \int_a^b \kappa \rho dt = 0
   \]

   and hence \(\kappa \equiv 0\) (e.g. by choosing bump functions \(\rho\) that vanish outside of \((t_0-\delta, t_0 + \delta)\) for each \(t_0 \in (a, b)\) and \(\delta > 0\)).
   #+END_soln

   \hfill\textbf{[2]}

**** Curvature of Surfaces of Revolution

Let \(S = (f(r) \cos \theta, f(r) \sin(\theta), r)\) be a surface of revolution for \(\theta \in (0, 2\pi), r \in (a, b)\).

Recall that
\[
g = \begin{pmatrix}
1 + (f')^2 & 0 \\
0 & f^2
\end{pmatrix},
\]
\[
N = \frac{1}{\sqrt{1 + (f')^2}} (-\cos\theta\partial_x -\sin\theta \partial_y +  f'\partial_z),
\]
\[
A = \frac{1}{\sqrt{1 + (f')^2}} \begin{pmatrix}
-f'' & 0 \\
0 & f
\end{pmatrix}
\]
and that the matrix representation of $dN$ is
\[
dN = \frac{1}{\sqrt{1+(f')^2}} \begin{pmatrix}
\frac{f''}{1+(f')^2} & 0 \\
0 & \frac{-1}{f}
\end{pmatrix}.
\]
The Gauss curvature is
\[
K = \tfrac{-f''}{f(1+(f')^2)^2}.
\]

1. Show that
   \begin{align*}
   \nabla_{\partial_{\theta}} \partial_{\theta} &= -\frac{ff'}{1 + (f')^2} \partial_r \\
   \nabla_{\partial_{\theta}} \partial_r &= \frac{f'}{f} \partial_{\theta} \\
   \nabla_{\partial_r} \partial_{\theta} &= \frac{f'}{f} \partial_{\theta} \\
   \nabla_{\partial_r} \partial_r &= \frac{f'f''}{1 + (f')^2} \partial_r
   \end{align*}

   #+BEGIN_soln
   We have
   \[
   \partial_r = f'\cos\theta \partial_x + f' \sin\theta \partial_y + \partial_z
   \]
   and
   \[
   \partial_{\theta} = -f \sin\theta \partial_x + f \cos\theta \partial_y.
   \]

   Then
   #+BEGIN_latex
   \[
   \begin{split}
   D_{\partial_r} \partial_r &= \partial_r \big(f' \cos\theta\big) \partial_x + \partial_r \big(f' \sin\theta\big) \partial_y + \partial_r \big(1\big)\partial_z \\
   &= f'' \cos\theta \partial_x + f'' \sin\theta \partial_y.
   \end{split}
   \]
   #+END_latex
   Projecting onto the normal
   #+BEGIN_latex
   \[
   \begin{split}
   \ip{D_{\partial_r} \partial_r}{N} &= \Big\langle f''\big(\cos\theta \partial_x + \sin\theta \partial_y\big), \\
   &\quad \frac{1}{\sqrt{1 + (f')^2}} \big(-\cos\theta\partial_x -\sin\theta \partial_y +  f'\partial_z\big)\Big\rangle \\
   &= -\frac{f''}{\sqrt{1 + (f')^2}}.
   \end{split}
   \]
   #+END_latex
   Then
   #+BEGIN_latex
   \[
   \begin{split}
   \nabla_{\partial_r} \partial_r &= D_{\partial_r} \partial_r - \ip{D_{\partial_r} \partial_r}{N} N \\
   &=f'' \cos\theta \partial_x + f'' \sin\theta \partial_y \\
   &\quad + \frac{f''}{\sqrt{1 + (f')^2}} \frac{1}{\sqrt{1 + (f')^2}} \big(-\cos\theta\partial_x -\sin\theta \partial_y +  f'\partial_z\big) \\
   &= f''\left(1 - \frac{1}{1 + (f')^2}\right) \left(\cos\theta\partial_x + \sin\theta\partial_y\right) + \frac{ff''}{1 + (f')^2} \partial_z \\
   &= \frac{f'f''}{1 + (f')^2} \left(f'\cos\theta\partial_x + f'\sin\theta\partial_y\right) + \frac{ff''}{1 + (f')^2} \partial_z \\
   &= \frac{ff''}{1 + (f')^2} \partial_r.
   \end{split}
   \]
   #+END_latex

   \hfill\textbf{[2]}

   The remaining parts are similar and worth \textbf{[2]} points each.
   #+END_soln

   \hfill\textbf{[8]}

2. Show that the curvature tensor is given by
   \[
   g(\Rm(\partial_z, \partial_{\theta}) \partial_z, \partial_{\theta}) = \frac{ff''}{1 + (f')^2}
   \]

   /Hint/: It's not too difficult to compute directly, or you could just use the Gauss equation...

   #+BEGIN_soln
   Using the Gauss equation:
   \[
   g(\Rm(\partial_r, \partial_{\theta}) \partial_r, \partial_{\theta}) = A(\partial_r, \partial_{\theta}) A(\partial_{\theta}, \partial_r) - A(\partial_r, \partial_r) A(\partial_{\theta},\partial_{\theta})
   \]
   \hfill\textbf{[2]}

   From the expression
   \[
   A = \frac{1}{\sqrt{1 + (f')^2}} \begin{pmatrix}
   -f'' & 0 \\
   0 & f
   \end{pmatrix}
   \]
   we get
   \[
   g(\Rm(\partial_r, \partial_{\theta}) \partial_r, \partial_{\theta}) = -\frac{-f''}{\sqrt{1 + (f')^2}} \frac{f}{{\sqrt{1 + (f')^2}}} = \frac{ff''}{1 + (f')^2}.
   \]

   \hfill\textbf{[2]}
   #+END_soln

   #+BEGIN_soln
   Using the curvature tensor definition
   \[
   \Rm(\partial_r, \partial_{\theta}) \partial_r = \nabla_{\partial_r} (\nabla_{\partial_{\theta}} \partial_r) - \nabla_{\partial_{\theta}}(\nabla_{\partial_r} \partial_r)
   \]
   since \([\partial_r, \partial_{\theta}] = 0\).

   \hfill\textbf{[1]}

   Then we can use the previous part to compute
   #+BEGIN_latex
   \[
   \begin{split}
   \nabla_{\partial_r} (\nabla_{\partial_{\theta}} \partial_r) &= \nabla_{\partial_r} \left(\frac{f'}{f} \partial_{\theta}\right) \\
   &= \left(\frac{f''}{f} - \frac{(f')^2}{f^2}\right) \partial_{\theta} + \frac{f'}{f} \frac{f'}{f} \partial_{\theta} \\
   &= \frac{f''}{f} \partial_{\theta}
   \end{split}
   \]
   #+END_latex
   \hfill\textbf{[1]}

   and
   #+BEGIN_latex
   \[
   \begin{split}
   \nabla_{\partial_{\theta}} (\nabla_{\partial_r} \partial_r) &= \nabla_{\partial_{\theta}} \left(\frac{f'f''}{1 + (f')^2} \partial_r\right) \\
   &= \frac{f'f''}{1 + (f')^2} \nabla_{\partial_{\theta}} \partial_{\theta} \\
   &= -\frac{f'f''}{1 + (f')^2} \frac{ff'}{1 + (f')^2} \partial_{\theta}
   \end{split}
   \]
   #+END_latex
   \hfill\textbf{[1]}

   To finish, put them together
   #+BEGIN_latex
   \[
   \begin{split}
   \Rm(\partial_r, \partial_{\theta}) \partial_r &= \left(\frac{f''}{f} + \frac{f(f')^2f''}{(1 + (f')^2)^2} \right)\partial_{\theta} \\
   &= -\frac{f''}{f(1 + (f')^2)^2} \partial_{\theta}
   \end{split}
   \]
   #+END_latex

   and take the inner-product with \(\partial_{\theta}\) to get
   #+BEGIN_latex
   \[
   \begin{split}
   g(\Rm(\partial_r, \partial_{\theta}) \partial_r, \partial_{\theta}) &= g(-\frac{ff''}{(1 + (f')^2)^2} \partial_{\theta}, \partial_{\theta}) \\
   &= -\frac{f''}{f(1 + (f')^2)^2} g_{\theta\theta} \\
   &= -\frac{ff''}{(1 + (f')^2)^2}
   \end{split}
   \]
   \hfill\textbf{[1]}
   #+END_latex
   #+END_soln

   \hfill\textbf{[4]}

3. Verify explicitly that
   \[
   g(\Rm(\partial_z, \partial_{\theta}) \partial_z, \partial_{\theta}) = K\left[g(\partial_z, \partial_{\theta})^2 - g(\partial_z, \partial_z) g(\partial_{\theta}\partial_{\theta})\right].
   \]

   #+BEGIN_soln
   From the previous part we have
   \[
   g(\Rm(\partial_z, \partial_{\theta}) \partial_z, \partial_{\theta}) = \frac{ff''}{1 + (f')^2}
   \]

   We also have
   \[
   K = \tfrac{-f''}{f(1+(f')^2)^2}.
   \]
   and
   \[
   g = \begin{pmatrix}
   1 + (f')^2 & 0 \\
   0 & f^2
   \end{pmatrix}
   \].
   \hfill\textbf{[2]}

   Then
   #+BEGIN_latex
   \[
   \begin{split}
   K\left[g(\partial_z, \partial_{\theta})^2 - g(\partial_z, \partial_z) g(\partial_{\theta}\partial_{\theta})\right] &= \tfrac{-f''}{f(1+(f')^2)^2} \left[-f^2(1 + (f')^2)\right] \\
   &= \frac{ff''}{1 + (f')^2}.
   \end{split}
   \]
   #+END_latex
   \hfill\textbf{[2]}
   #+END_soln

   \hfill\textbf{[4]}

4. Let \(\lambda > 0\),
   \[
   S_{\lambda} = \{\lambda (f\cos\theta, f\sin\theta, z)\}.
   \]
   Show that
   \[
   \operatorname{Area}(S_{\lambda}) = \lambda^2 \operatorname{Area}(S).
   \]

   #+BEGIN_soln
   We get
   \[
   g_{\lambda} = \begin{pmatrix}
   \lambda^2 + (\lambda f')^2 & 0 \\
   0 & (\lambda f)^2
   \end{pmatrix}
   = \lambda^2 g
   \]

   Then
   \[
   \sqrt{\det g_{\lambda}} = \sqrt{\det(\lambda^2 g)} = \sqrt{\lambda^4 \det g} = \lambda^2 \sqrt{\det g}.
   \]

   Now just integrate.
   #+END_soln

   \hfill\textbf{[2]}

5. In the same notation as the previous question show directly that
   \[
   \int_S K dA = \int_{S_{\lambda}} K dA
   \]
   as predicted by the Gauss-Bonnet theorem.

   #+BEGIN_soln
   We have
   \[
   K_{\lambda} = \tfrac{-\lambda f''}{\lambda f(\lambda^2+(\lambda f')^2)^2} = \frac{1}{\lambda^2} K.
   \]

   Therefore
   \[
   K_{\lambda} \sqrt{\det g_{\lambda}} = K \sqrt{\det g}
   \]
   and integrating completes the proof.
   #+END_soln


   \hfill\textbf{[2]}

**** Notes 							   :noexport:
- Due Thursday 26th Oct, Week 13
- Topics Weeks 10-13
  - Isometries
  - Intrinsic geometry
  - Gauss Theorem
  - Covariant derivatives, parallel transport and geodesics
  - Gauss-Bonnet (local)

* Exam 								   :noexport:
** Study Guide
*** Parametrised Curves
*** Regular Surfaces
*** Curvature of Surfaces
*** Intrinsic Geometry
* Notes 							   :noexport:
** General
- Make use of Ximera?

- SageMath resources:
  - SageManifolds: http://sagemanifolds.obspm.fr/ and  http://doc.sagemath.org/html/en/reference/manifolds/index.html
  - Parametrised Surfaces: http://doc.sagemath.org/html/en/reference/riemannian_geometry/sage/geometry/riemannian_manifolds/parametrized_surface3d.html

- Use this Lewis Carol quote:
  https://medium.com/@awoodruff/your-maps-are-not-lying-to-you-9c8c31c5991f

- In relation to Gauss' Theorema Egregium and map making:
  https://en.wikipedia.org/wiki/Theorema_Egregium#Elementary_applications

** Course Material
*** Review
**** Curves
**** Regular Surfaces
***** Curvature (The Gauss Map)
*** Orientation
- do Carmo, Sections 2.6, 3.2
*** Gauss Map
- do Carmo, Section 3.2
*** Second Fundamental Form
- do Carmo, Section 3.2
*** Principle Curvatures
- do Carmo, Sections 3.2, 3.3
- Classification of points (elliptic, parabolic,..., umbilic, saddle points, convex points, ...)
- Gauss and Mean Curvatures
*** Minimal Surfaces

**** Global Geometry
*** Isometries
**** Textbook reference
- do Carmo, Section
*** Gauss' Theorem
**** Textbook reference
- do Carmo, Section
*** Vector Fields and Covariant Differentiation
**** Textbook reference
- do Carmo, Section
*** Gauss-Bonnet Theorem
**** Textbook reference
- do Carmo, Section

** Alt Course Material
*** Schedule
| Week | Mon                | Wed                               | Fri                               |
|------+--------------------+-----------------------------------+-----------------------------------|
|    7 |                    | Orientation and Gauss Map         | SFF                               |
|    8 | SFF                | Curvature                         | Principal Curvatures              |
|    9 | MC and GC          | Taylor Approximation              | *Bonus*: Minimal Surfaces         |
|   10 | *Holiday*          | Isometries and Intrinsic Geometry | Isometries and Intrinsic Geometry |
|   11 | Conformal Geometry | Theorema Egregium                 | Theorema Egregium                 |
|   12 | Parallel Transport | Geodesics                         | Gauss-Bonnet                      |
|   13 | Gauss-Bonnet       | Gauss-Bonnet                      | *Catch Up*                        |
|      |                    |                                   |                                   |

*** Recap
**** Regular Curves
**** Regular Surfaces
*** Curvature
**** Orientation and Gauss Map
- Orientation
- Gauss Map
- Local Coordinates
**** Second Fundamental Form and Weingarten Shape Operator
- Shape Operator
- Shape Operator is Self-Adjoint
- Second Fundamental Form
- Local Coordinates
- Geodesic Curvature of Curves
- Normal Curvature
**** Principal Curvatures, Mean Curvature and Gauss Curvature
- Principal Curvatures as Eigenvalues and as Min/Max curvatures
- Principal Directions and Lines of Curvature
- Mean Curvature and Gauss Curvature
- Interpretation of Mean Curvature
- Interpretation of Gauss Curvature
**** Local Taylor Approximation
- Classification of Points (Elliptic, hyperbolic, parabolic, planar)
- Umbilical Points
- Taylor Approximation Over Tangent Plane
- Image of Gauss Map for Closed Surfaces
**** Bonus: Minimal Surfaces
- Variations
- Minimal Surface Equation
*** Intrinsic Geometry
**** Isometries and Intrinsic Geometry
- Isometries
- Length, Angles and Area are Local Invariants
**** Conformal Geometry
- Conformal maps
- Map Making Examples
**** Theorema Egregium
**** Vector Fields and Parallel Transport
- Vector Fields
- Flows
- Covariant Derivative
- Parallel Transport
***** Bonus: Dynamical Systems
- Mechanics Example
  - Motion Constrained to a Regular Surface
  - Conservation of Energy

**** Geodesics
- Defn
- Length Minimisation
- Curvature
**** Gauss-Bonnet
***** Local Gauss-Bonnet
- Piecewise Curves
- Turning Tangents
- Local Gauss-Bonnet
***** Global Gauss-Bonnet
- Triangulation
- Euler Characteristic
- Handle Bodies
- Global Gauss-Bonnet
***** Applications

